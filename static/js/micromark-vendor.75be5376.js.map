{"version":3,"file":"static/js/micromark-vendor.75be5376.js","mappings":"wFAEAA,OAAOC,eAAeC,EAAS,aAA/BF,CAA8CG,OAAO,IAErD,IAAIC,EAAqBC,EAAQ,OAC7BC,EAAeD,EAAQ,OACvBE,EAAmBF,EAAQ,OAE3BG,EAQJ,SAA4BC,GAC1B,IAOIC,EACAC,EACAC,EATAC,EAAOC,KACPC,EAAQ,GACRC,EAAY,EACZC,EAAmB,CACrBT,SAoHF,SAAyBC,EAASS,GAChC,IAAIC,EAAe,EAEnB,OADAT,EAAgB,CAAC,EACVU,EAEP,SAASA,EAAaC,GACpB,OAAIF,EAAeJ,EAAMO,QACvBT,EAAKU,eAAiBR,EAAMI,GAAc,GACnCV,EAAQe,QACbT,EAAMI,GAAc,GAAGM,aACvBC,EACAC,EAHKlB,CAILY,IAIAV,EAAUiB,kBAAoBjB,EAAUiB,iBAAiBC,UAC3DnB,EAAcoB,cAAe,EACtBC,EAAYV,KAGrBR,EAAKmB,UACHrB,EAAUiB,kBAAoBjB,EAAUiB,iBAAiBK,cAC3DpB,EAAKU,eAAiB,CAAC,EAChBd,EAAQe,QACbU,EACAC,EACAJ,EAHKtB,CAILY,GACJ,CAEA,SAASK,EAAgBL,GAEvB,OADAF,IACON,EAAKU,eAAea,WACvBD,EAAed,GACfD,EAAaC,EACnB,CAEA,SAASM,EAAYN,GACnB,OAAIV,EAAUiB,kBAAoBjB,EAAUiB,iBAAiBS,MAE3DxB,EAAKU,eAAiB,CAAC,EAChBd,EAAQe,QACbU,EACAC,EACA1B,EAAQe,QACNc,EACAH,EACA1B,EAAQ8B,MAAMhC,EAAkB4B,EAAgBK,IAN7C/B,CAQLY,IAGGc,EAAed,EACxB,CAEA,SAASmB,EAAYnB,GAKnB,OAHAF,EAAeJ,EAAMO,OACrBZ,EAAc2B,MAAO,EACrB3B,EAAcoB,cAAe,EACtBC,EAAYV,EACrB,CAEA,SAASc,EAAed,GAEtB,OADAX,EAAc+B,SAAU,EACjBV,EAAYV,EACrB,CAEA,SAASU,EAAYV,GAGnB,OAFAX,EAAcM,UAAYG,EAC1BN,EAAKmB,UAAYnB,EAAKU,oBAAiBmB,EAChCxB,EAAGG,EACZ,CACF,EA7LEsB,SAAS,GAKX,OAAOC,EAEP,SAASA,EAAMvB,GACb,OAAIL,EAAYD,EAAMO,QACpBT,EAAKU,eAAiBR,EAAMC,GAAW,GAChCP,EAAQe,QACbT,EAAMC,GAAW,GAAGS,aACpBoB,EACAC,EAHKrC,CAILY,IAGGyB,EAAkBzB,EAC3B,CAEA,SAASwB,EAAiBxB,GAExB,OADAL,IACO4B,EAAMvB,EACf,CAEA,SAASyB,EAAkBzB,GAGzB,OAAIX,GAAiBA,EAAcoB,aAC1BiB,EAAU1B,IAGnBR,EAAKmB,UACHrB,GACAA,EAAUiB,kBACVjB,EAAUiB,iBAAiBK,cAC7BpB,EAAKU,eAAiB,CAAC,EAChBd,EAAQe,QACbU,EACAc,EACAD,EAHKtC,CAILY,GACJ,CAEA,SAAS2B,EAAkB3B,GAGzB,OAFAN,EAAMkC,KAAK,CAACpC,EAAKe,iBAAkBf,EAAKU,iBACxCV,EAAKU,oBAAiBmB,EACfI,EAAkBzB,EAC3B,CAEA,SAAS0B,EAAU1B,GACjB,OAAa,OAATA,GACF6B,EAAe,GAAG,QAClBzC,EAAQ0C,QAAQ9B,KAIlBV,EAAYA,GAAaE,EAAKuC,OAAOC,KAAKxC,EAAKyC,OAC/C7C,EAAQ8C,MAAM,YAAa,CACzBC,YAAa,OACbC,SAAU7C,EACV8C,WAAY/C,IAEPmB,EAAaT,GACtB,CAEA,SAASS,EAAaT,GACpB,OAAa,OAATA,GACFsC,EAAalD,EAAQmD,KAAK,cACnBb,EAAU1B,IAGfjB,EAAmBiB,IACrBZ,EAAQ0C,QAAQ9B,GAChBsC,EAAalD,EAAQmD,KAAK,cACnBnD,EAAQ8B,MAAMtB,EAAkB4C,KAGzCpD,EAAQ0C,QAAQ9B,GACTS,EACT,CAEA,SAAS+B,EAAkBxC,GAMzB,OALA6B,EACExC,EAAcM,UACdN,GAAiBA,EAAc+B,SAEjCzB,EAAY,EACL4B,EAAMvB,EACf,CAEA,SAASsC,EAAaG,GAChBlD,IAAYA,EAAWmD,KAAOD,GAClClD,EAAakD,EACbnD,EAAU0B,KAAO3B,GAAiBA,EAAc2B,KAChD1B,EAAUqD,WAAWF,EAAMlB,OAC3BjC,EAAUsD,MAAMpD,EAAKqD,YAAYJ,GACnC,CAEA,SAASZ,EAAeiB,EAAMC,GAC5B,IAAIC,EAAQtD,EAAMO,OAOlB,IALIX,GAAayD,IACfzD,EAAUsD,MAAM,CAAC,OACjBrD,EAAaD,OAAY+B,GAGpB2B,KAAUF,GACftD,EAAKU,eAAiBR,EAAMsD,GAAO,GACnCtD,EAAMsD,GAAO,GAAGT,KAAKU,KAAKzD,EAAMJ,GAGlCM,EAAMO,OAAS6C,CACjB,CA6EF,EA3MIjC,EAAqB,CACvB1B,SA4MF,SAA2BC,EAASS,EAAIqD,GACtC,OAAOjE,EACLG,EACAA,EAAQe,QAAQV,KAAKsC,OAAOoB,WAAWC,SAAUvD,EAAIqD,GACrD,aACAzD,KAAKsC,OAAOoB,WAAWE,QAAQC,KAAKC,QAAQ,iBAAmB,OAC3DlC,EACA,EAER,GAnNIJ,EAAoB,CACtB9B,SAoNF,SAA0BC,EAASS,EAAIqD,GACrC,OAAOjE,EACLG,EACAA,EAAQ4B,KAAKvB,KAAKsC,OAAOoB,WAAWnB,KAAMnC,EAAIqD,GAC9C,aACAzD,KAAKsC,OAAOoB,WAAWE,QAAQC,KAAKC,QAAQ,iBAAmB,OAC3DlC,EACA,EAER,GAEAxC,EAAQM,SAAWA,C,kCC3NnB,MAAMqE,EAAS,cAMR,SAASC,IACd,IAKIC,EALAC,EAAS,EACTC,EAAS,GAETrC,GAAQ,EAGZ,OAIA,SAAsBzC,EAAO+E,EAAUd,GAErC,MAAMe,EAAS,GAEf,IAAIC,EAEArB,EAEAsB,EAEAC,EAEAjE,EACJlB,EAAQ8E,GAA2B,kBAAV9E,EAAqBA,EAAMoF,WAAa,IAAIC,YAAYN,QAAYxC,GAAW+C,OAAOtF,IAC/GkF,EAAgB,EAChBJ,EAAS,GACLrC,IAE0B,QAAxBzC,EAAMuF,WAAW,IACnBL,IAEFzC,OAAQF,GAEV,KAAO2C,EAAgBlF,EAAMmB,QAAQ,CAKnC,GAJAuD,EAAOc,UAAYN,EACnBD,EAAQP,EAAOe,KAAKzF,GACpBmF,EAAcF,QAAyB1C,IAAhB0C,EAAMf,MAAsBe,EAAMf,MAAQlE,EAAMmB,OACvED,EAAOlB,EAAMuF,WAAWJ,IACnBF,EAAO,CACVH,EAAS9E,EAAM0F,MAAMR,GACrB,KACF,CACA,GAAa,KAAThE,GAAegE,IAAkBC,GAAeP,EAClDI,EAAOlC,MAAM,GACb8B,OAAmBrC,OAUnB,OARIqC,IACFI,EAAOlC,MAAM,GACb8B,OAAmBrC,GAEjB2C,EAAgBC,IAClBH,EAAOlC,KAAK9C,EAAM0F,MAAMR,EAAeC,IACvCN,GAAUM,EAAcD,GAElBhE,GACN,KAAK,EAED8D,EAAOlC,KAAK,OACZ+B,IACA,MAEJ,KAAK,EAID,IAFAjB,EAA+B,EAAxB+B,KAAKC,KAAKf,EAAS,GAC1BG,EAAOlC,MAAM,GACN+B,IAAWjB,GAAMoB,EAAOlC,MAAM,GACrC,MAEJ,KAAK,GAEDkC,EAAOlC,MAAM,GACb+B,EAAS,EACT,MAEJ,QAEID,GAAmB,EACnBC,EAAS,EAIjBK,EAAgBC,EAAc,CAChC,CACIlB,IACEW,GAAkBI,EAAOlC,MAAM,GAC/BgC,GAAQE,EAAOlC,KAAKgC,GACxBE,EAAOlC,KAAK,OAEd,OAAOkC,CACT,CACF,C,iBChHA,IAAIa,EAA0B3F,EAAQ,OAKlC4F,EAJa5F,EAAQ,MAIA6F,CAAWF,GAEpCG,EAAOjG,QAAU+F,C,iBCPjB,IAAIG,EAAa/F,EAAQ,OACrBgG,EAAoBhG,EAAQ,OAC5BD,EAAqBC,EAAQ,OAC7BiG,EAA4BjG,EAAQ,OACpCkG,EAAgBlG,EAAQ,OACxBmG,EAAenG,EAAQ,MACvBoG,EAAiBpG,EAAQ,OACzBqG,EAAerG,EAAQ,MACvBE,EAAmBF,EAAQ,OAE3BsG,EAAW,CACbC,KAAM,WACNpG,SA8BF,SAA0BC,EAASS,EAAIqD,GACrC,IACIsC,EACAC,EACA7B,EACAZ,EACA0C,EALAlG,EAAOC,KAMX,OAEA,SAAeO,GAIb,OAHAZ,EAAQ8C,MAAM,YACd9C,EAAQ8C,MAAM,gBACd9C,EAAQ0C,QAAQ9B,GACT2F,CACT,EAEA,SAASA,EAAK3F,GACZ,OAAa,KAATA,GACFZ,EAAQ0C,QAAQ9B,GACT4F,GAGI,KAAT5F,GACFZ,EAAQ0C,QAAQ9B,GACT6F,GAGI,KAAT7F,GACFZ,EAAQ0C,QAAQ9B,GAChBwF,EAAO,EAGAhG,EAAKmB,UAAYd,EAAKiG,GAG3Bf,EAAW/E,IACbZ,EAAQ0C,QAAQ9B,GAChB4D,EAASuB,EAAanF,GACtByF,GAAW,EACJM,GAGF7C,EAAIlD,EACb,CAEA,SAAS4F,EAAiB5F,GACxB,OAAa,KAATA,GACFZ,EAAQ0C,QAAQ9B,GAChBwF,EAAO,EACAQ,GAGI,KAAThG,GACFZ,EAAQ0C,QAAQ9B,GAChBwF,EAAO,EACP5B,EAAS,SACTZ,EAAQ,EACDiD,GAGLlB,EAAW/E,IACbZ,EAAQ0C,QAAQ9B,GAChBwF,EAAO,EACAhG,EAAKmB,UAAYd,EAAKiG,GAGxB5C,EAAIlD,EACb,CAEA,SAASgG,EAAkBhG,GACzB,OAAa,KAATA,GACFZ,EAAQ0C,QAAQ9B,GACTR,EAAKmB,UAAYd,EAAKiG,GAGxB5C,EAAIlD,EACb,CAEA,SAASiG,EAAgBjG,GACvB,OAAIA,IAAS4D,EAAOS,WAAWrB,MAC7B5D,EAAQ0C,QAAQ9B,GACTgD,IAAUY,EAAO3D,OACpBT,EAAKmB,UACHd,EACAO,EACF6F,GAGC/C,EAAIlD,EACb,CAEA,SAAS6F,EAAc7F,GACrB,OAAI+E,EAAW/E,IACbZ,EAAQ0C,QAAQ9B,GAChB4D,EAASuB,EAAanF,GACf+F,GAGF7C,EAAIlD,EACb,CAEA,SAAS+F,EAAQ/F,GACf,OACW,OAATA,GACS,KAATA,GACS,KAATA,GACAiF,EAA0BjF,GAGf,KAATA,GACAyF,GACAJ,EAAa9B,QAAQK,EAAOsC,gBAAkB,GAE9CV,EAAO,EACAhG,EAAKmB,UAAYd,EAAGG,GAAQI,EAAaJ,IAG9CoF,EAAe7B,QAAQK,EAAOsC,gBAAkB,GAClDV,EAAO,EAEM,KAATxF,GACFZ,EAAQ0C,QAAQ9B,GACTmG,GAGF3G,EAAKmB,UAAYd,EAAGG,GAAQI,EAAaJ,KAGlDwF,EAAO,EAEAhG,EAAKmB,UACRuC,EAAIlD,GACJyF,EACAW,EAA4BpG,GAC5BqG,EAAwBrG,IAGjB,KAATA,GAAegF,EAAkBhF,IACnCZ,EAAQ0C,QAAQ9B,GAChB4D,GAAUuB,EAAanF,GAChB+F,GAGF7C,EAAIlD,EACb,CAEA,SAASmG,EAAiBnG,GACxB,OAAa,KAATA,GACFZ,EAAQ0C,QAAQ9B,GACTR,EAAKmB,UAAYd,EAAKO,GAGxB8C,EAAIlD,EACb,CAEA,SAASqG,EAAwBrG,GAC/B,OAAIkF,EAAclF,IAChBZ,EAAQ0C,QAAQ9B,GACTqG,GAGFC,EAAYtG,EACrB,CAEA,SAASoG,EAA4BpG,GACnC,OAAa,KAATA,GACFZ,EAAQ0C,QAAQ9B,GACTsG,GAGI,KAATtG,GAAwB,KAATA,GAAe+E,EAAW/E,IAC3CZ,EAAQ0C,QAAQ9B,GACTuG,GAGLrB,EAAclF,IAChBZ,EAAQ0C,QAAQ9B,GACToG,GAGFE,EAAYtG,EACrB,CAEA,SAASuG,EAAsBvG,GAC7B,OACW,KAATA,GACS,KAATA,GACS,KAATA,GACS,KAATA,GACAgF,EAAkBhF,IAElBZ,EAAQ0C,QAAQ9B,GACTuG,GAGFC,EAA2BxG,EACpC,CAEA,SAASwG,EAA2BxG,GAClC,OAAa,KAATA,GACFZ,EAAQ0C,QAAQ9B,GACTyG,GAGLvB,EAAclF,IAChBZ,EAAQ0C,QAAQ9B,GACTwG,GAGFJ,EAA4BpG,EACrC,CAEA,SAASyG,EAA6BzG,GACpC,OACW,OAATA,GACS,KAATA,GACS,KAATA,GACS,KAATA,GACS,KAATA,EAEOkD,EAAIlD,GAGA,KAATA,GAAwB,KAATA,GACjBZ,EAAQ0C,QAAQ9B,GAChB0F,EAAS1F,EACF0G,GAGLxB,EAAclF,IAChBZ,EAAQ0C,QAAQ9B,GACTyG,IAGTf,OAASrE,EACFsF,EAA+B3G,GACxC,CAEA,SAAS0G,EAA6B1G,GACpC,OAAIA,IAAS0F,GACXtG,EAAQ0C,QAAQ9B,GACT4G,GAGI,OAAT5G,GAAiBjB,EAAmBiB,GAC/BkD,EAAIlD,IAGbZ,EAAQ0C,QAAQ9B,GACT0G,EACT,CAEA,SAASC,EAA+B3G,GACtC,OACW,OAATA,GACS,KAATA,GACS,KAATA,GACS,KAATA,GACS,KAATA,GACS,KAATA,GACS,KAATA,GACAiF,EAA0BjF,GAEnBwG,EAA2BxG,IAGpCZ,EAAQ0C,QAAQ9B,GACT2G,EACT,CAEA,SAASC,EAAkC5G,GACzC,OAAa,KAATA,GAAwB,KAATA,GAAekF,EAAclF,GACvCoG,EAA4BpG,GAG9BkD,EAAIlD,EACb,CAEA,SAASsG,EAAYtG,GACnB,OAAa,KAATA,GACFZ,EAAQ0C,QAAQ9B,GACT6G,GAGF3D,EAAIlD,EACb,CAEA,SAAS6G,EAAc7G,GACrB,OAAIkF,EAAclF,IAChBZ,EAAQ0C,QAAQ9B,GACT6G,GAGO,OAAT7G,GAAiBjB,EAAmBiB,GACvCI,EAAaJ,GACbkD,EAAIlD,EACV,CAEA,SAASI,EAAaJ,GACpB,OAAa,KAATA,GAAwB,IAATwF,GACjBpG,EAAQ0C,QAAQ9B,GACT8G,GAGI,KAAT9G,GAAwB,IAATwF,GACjBpG,EAAQ0C,QAAQ9B,GACT+G,GAGI,KAAT/G,GAAwB,IAATwF,GACjBpG,EAAQ0C,QAAQ9B,GACTgH,GAGI,KAAThH,GAAwB,IAATwF,GACjBpG,EAAQ0C,QAAQ9B,GACT8F,GAGI,KAAT9F,GAAwB,IAATwF,GACjBpG,EAAQ0C,QAAQ9B,GACTiH,IAGLlI,EAAmBiB,IAAmB,IAATwF,GAAuB,IAATA,EAQlC,OAATxF,GAAiBjB,EAAmBiB,GAC/BkH,EAAyBlH,IAGlCZ,EAAQ0C,QAAQ9B,GACTI,GAZEhB,EAAQ8B,MACbiG,EACAH,EACAE,EAHK9H,CAILY,EASN,CAEA,SAASkH,EAAyBlH,GAEhC,OADAZ,EAAQmD,KAAK,gBACN6E,EAAkBpH,EAC3B,CAEA,SAASoH,EAAkBpH,GACzB,OAAa,OAATA,EACKqH,EAAKrH,GAGVjB,EAAmBiB,IACrBZ,EAAQ8C,MAAM,cACd9C,EAAQ0C,QAAQ9B,GAChBZ,EAAQmD,KAAK,cACN6E,IAGThI,EAAQ8C,MAAM,gBACP9B,EAAaJ,GACtB,CAEA,SAAS8G,EAA0B9G,GACjC,OAAa,KAATA,GACFZ,EAAQ0C,QAAQ9B,GACT8F,GAGF1F,EAAaJ,EACtB,CAEA,SAAS+G,EAAuB/G,GAC9B,OAAa,KAATA,GACFZ,EAAQ0C,QAAQ9B,GAChB4D,EAAS,GACF0D,GAGFlH,EAAaJ,EACtB,CAEA,SAASsH,EAAsBtH,GAC7B,OAAa,KAATA,GAAeqF,EAAa9B,QAAQK,EAAOsC,gBAAkB,GAC/D9G,EAAQ0C,QAAQ9B,GACTgH,GAGLjC,EAAW/E,IAAS4D,EAAO3D,OAAS,GACtCb,EAAQ0C,QAAQ9B,GAChB4D,GAAUuB,EAAanF,GAChBsH,GAGFlH,EAAaJ,EACtB,CAEA,SAASiH,EAAgCjH,GACvC,OAAa,KAATA,GACFZ,EAAQ0C,QAAQ9B,GACT8F,GAGF1F,EAAaJ,EACtB,CAEA,SAAS8F,EAA8B9F,GACrC,OAAa,KAATA,GACFZ,EAAQ0C,QAAQ9B,GACTgH,GAGF5G,EAAaJ,EACtB,CAEA,SAASgH,EAAkBhH,GACzB,OAAa,OAATA,GAAiBjB,EAAmBiB,IACtCZ,EAAQmD,KAAK,gBACN8E,EAAKrH,KAGdZ,EAAQ0C,QAAQ9B,GACTgH,EACT,CAEA,SAASK,EAAKrH,GAEZ,OADAZ,EAAQmD,KAAK,YACN1C,EAAGG,EACZ,CACF,EAxcEuH,UAQF,SAA2BC,GACzB,IAAIxE,EAAQwE,EAAOvH,OAEnB,KAAO+C,MACoB,UAArBwE,EAAOxE,GAAO,IAA4C,aAA1BwE,EAAOxE,GAAO,GAAGyE,QAKnDzE,EAAQ,GAAmC,eAA9BwE,EAAOxE,EAAQ,GAAG,GAAGyE,OAEpCD,EAAOxE,GAAO,GAAGzB,MAAQiG,EAAOxE,EAAQ,GAAG,GAAGzB,MAE9CiG,EAAOxE,EAAQ,GAAG,GAAGzB,MAAQiG,EAAOxE,EAAQ,GAAG,GAAGzB,MAElDiG,EAAOE,OAAO1E,EAAQ,EAAG,IAG3B,OAAOwE,CACT,EA1BEhH,UAAU,GAER2G,EAAqB,CACvBhI,SAscF,SAA2BC,EAASS,EAAIqD,GACtC,OAEA,SAAelD,GAKb,OAJAZ,EAAQmD,KAAK,gBACbnD,EAAQ8C,MAAM,mBACd9C,EAAQ0C,QAAQ9B,GAChBZ,EAAQmD,KAAK,mBACNnD,EAAQe,QAAQjB,EAAkBW,EAAIqD,EAC/C,CACF,EA/cE5B,SAAS,GAidXwD,EAAOjG,QAAUyG,C,iBCnejB,IAAIP,EAAa/F,EAAQ,OACrBgG,EAAoBhG,EAAQ,OAC5B2I,EAAa3I,EAAQ,OACrB4I,EAAe5I,EAAQ,OAEvB6I,EAAW,CACbtC,KAAM,WACNpG,SAGF,SAA0BC,EAASS,EAAIqD,GACrC,IAAIJ,EAAO,EACX,OAEA,SAAe9C,GAMb,OALAZ,EAAQ8C,MAAM,YACd9C,EAAQ8C,MAAM,kBACd9C,EAAQ0C,QAAQ9B,GAChBZ,EAAQmD,KAAK,kBACbnD,EAAQ8C,MAAM,oBACPyD,CACT,EAEA,SAASA,EAAK3F,GACZ,OAAI+E,EAAW/E,IACbZ,EAAQ0C,QAAQ9B,GACT8H,GAGFH,EAAW3H,GAAQ+H,EAAW/H,GAAQkD,EAAIlD,EACnD,CAEA,SAAS8H,EAAmB9H,GAC1B,OAAgB,KAATA,GAAwB,KAATA,GAAwB,KAATA,GAAegF,EAAkBhF,GAClEgI,EAAyBhI,GACzB+H,EAAW/H,EACjB,CAEA,SAASgI,EAAyBhI,GAChC,OAAa,KAATA,GACFZ,EAAQ0C,QAAQ9B,GACTiI,IAIG,KAATjI,GAAwB,KAATA,GAAwB,KAATA,GAAegF,EAAkBhF,KAChE8C,IAAS,IAET1D,EAAQ0C,QAAQ9B,GACTgI,GAGFD,EAAW/H,EACpB,CAEA,SAASiI,EAAUjI,GACjB,OAAa,KAATA,GACFZ,EAAQmD,KAAK,oBACNQ,EAAI/C,IAGA,KAATA,GAAwB,KAATA,GAAe4H,EAAa5H,GACtCkD,EAAIlD,IAGbZ,EAAQ0C,QAAQ9B,GACTiI,EACT,CAEA,SAASF,EAAW/H,GAClB,OAAa,KAATA,GACFZ,EAAQ0C,QAAQ9B,GAChB8C,EAAO,EACAoF,GAGLP,EAAW3H,IACbZ,EAAQ0C,QAAQ9B,GACT+H,GAGF7E,EAAIlD,EACb,CAEA,SAASkI,EAAiBlI,GACxB,OAAOgF,EAAkBhF,GAAQmI,EAAWnI,GAAQkD,EAAIlD,EAC1D,CAEA,SAASmI,EAAWnI,GAClB,OAAa,KAATA,GACFZ,EAAQ0C,QAAQ9B,GAChB8C,EAAO,EACAoF,GAGI,KAATlI,GAEFZ,EAAQmD,KAAK,oBAAoBkF,KAAO,gBACjC1E,EAAI/C,IAGNoI,EAAWpI,EACpB,CAEA,SAASoI,EAAWpI,GAClB,OAAc,KAATA,GAAegF,EAAkBhF,KAAU8C,IAAS,IACvD1D,EAAQ0C,QAAQ9B,GACA,KAATA,EAAcoI,EAAaD,GAG7BjF,EAAIlD,EACb,CAEA,SAAS+C,EAAI/C,GAKX,OAJAZ,EAAQ8C,MAAM,kBACd9C,EAAQ0C,QAAQ9B,GAChBZ,EAAQmD,KAAK,kBACbnD,EAAQmD,KAAK,YACN1C,CACT,CACF,GAEAiF,EAAOjG,QAAUgJ,C,iBC1HjBlJ,OAAOC,eAAeC,EAAS,aAA/BF,CAA8CG,OAAO,IAErD,IAAIuJ,EAAUrJ,EAAQ,OAClBC,EAAeD,EAAQ,OACvBE,EAAmBF,EAAQ,OAE3BG,EAEJ,SAAwBC,GACtB,IAAII,EAAOC,KACP6I,EAAUlJ,EAAQe,QAEpBjB,GAkBF,SAAuBc,GACrB,GAAa,OAATA,EAEF,YADAZ,EAAQ0C,QAAQ9B,GAQlB,OAJAZ,EAAQ8C,MAAM,mBACd9C,EAAQ0C,QAAQ9B,GAChBZ,EAAQmD,KAAK,mBACb/C,EAAKe,sBAAmBc,EACjBiH,CACT,GA3BElJ,EAAQe,QACNV,KAAKsC,OAAOoB,WAAWoF,YACvBC,EACAvJ,EACEG,EACAA,EAAQe,QACNV,KAAKsC,OAAOoB,WAAWnB,KACvBwG,EACApJ,EAAQe,QAAQkI,EAASG,IAE3B,gBAIN,OAAOF,EAeP,SAASE,EAAexI,GACtB,GAAa,OAATA,EASJ,OAJAZ,EAAQ8C,MAAM,cACd9C,EAAQ0C,QAAQ9B,GAChBZ,EAAQmD,KAAK,cACb/C,EAAKe,sBAAmBc,EACjBiH,EARLlJ,EAAQ0C,QAAQ9B,EASpB,CACF,EAEAnB,EAAQM,SAAWA,C,WCzDnB,IAAIgG,EAAesD,OAAOtD,aAE1BL,EAAOjG,QAAUsG,C,WCCjBL,EAAOjG,QAFI,CAAC,MAAO,SAAU,QAAS,W,iDCS/B,SAAS6J,EAAYlB,GAC1B,OAAQmB,EAAAA,EAAAA,GAAYnB,KAGpB,OAAOA,CACT,C,YCXA1C,EAAOjG,QAJP,SAAuBmB,GACrB,OAAiB,IAAVA,IAAyB,IAAVA,GAAwB,KAATA,CACvC,C,kBCFA,IAAIjB,EAAqBC,EAAQ,OAC7BkG,EAAgBlG,EAAQ,OACxBC,EAAeD,EAAQ,OAEvB4J,EAAgB,CAClBrD,KAAM,gBACNpG,SAGF,SAA+BC,EAASS,EAAIqD,GAC1C,IACIwC,EADA5C,EAAO,EAEX,OAEA,SAAe9C,GAGb,OAFAZ,EAAQ8C,MAAM,iBACdwD,EAAS1F,EACF6I,EAAQ7I,EACjB,EAEA,SAAS6I,EAAQ7I,GACf,OAAIA,IAAS0F,GACXtG,EAAQ8C,MAAM,yBACP4G,EAAS9I,IAGdkF,EAAclF,GACTf,EAAaG,EAASyJ,EAAS,aAA/B5J,CAA6Ce,GAGlD8C,EAAO,GAAe,OAAT9C,IAAkBjB,EAAmBiB,GAC7CkD,EAAIlD,IAGbZ,EAAQmD,KAAK,iBACN1C,EAAGG,GACZ,CAEA,SAAS8I,EAAS9I,GAChB,OAAIA,IAAS0F,GACXtG,EAAQ0C,QAAQ9B,GAChB8C,IACOgG,IAGT1J,EAAQmD,KAAK,yBACNsG,EAAQ7I,GACjB,CACF,GAEA8E,EAAOjG,QAAU+J,C,YCjCjB9D,EAAOjG,QAjBP,SAAoBsE,EAAYqE,EAAQuB,GAKtC,IAJA,IAEIC,EAFAC,EAAS,GACTjG,GAAS,IAGJA,EAAQG,EAAWlD,SAC1B+I,EAAU7F,EAAWH,GAAOkG,aAEbD,EAAO1F,QAAQyF,GAAW,IACvCxB,EAASwB,EAAQxB,EAAQuB,GACzBE,EAAOrH,KAAKoH,IAIhB,OAAOxB,CACT,C,YCfA,IAAI2B,EAASxK,OAAOwK,OAEpBrE,EAAOjG,QAAUsK,C,kBCFjB,IAAIpE,EAAa/F,EAAQ,OACrBgG,EAAoBhG,EAAQ,OAC5BD,EAAqBC,EAAQ,OAC7BiG,EAA4BjG,EAAQ,OACpCkG,EAAgBlG,EAAQ,OACxBC,EAAeD,EAAQ,OAEvBoK,EAAW,CACb7D,KAAM,WACNpG,SAGF,SAA0BC,EAASS,EAAIqD,GACrC,IACIwC,EACA9B,EACAZ,EACAqG,EAJA7J,EAAOC,KAKX,OAEA,SAAeO,GAIb,OAHAZ,EAAQ8C,MAAM,YACd9C,EAAQ8C,MAAM,gBACd9C,EAAQ0C,QAAQ9B,GACT2F,CACT,EAEA,SAASA,EAAK3F,GACZ,OAAa,KAATA,GACFZ,EAAQ0C,QAAQ9B,GACTsJ,GAGI,KAATtJ,GACFZ,EAAQ0C,QAAQ9B,GACT6F,GAGI,KAAT7F,GACFZ,EAAQ0C,QAAQ9B,GACTuJ,GAGLxE,EAAW/E,IACbZ,EAAQ0C,QAAQ9B,GACTwJ,GAGFtG,EAAIlD,EACb,CAEA,SAASsJ,EAAgBtJ,GACvB,OAAa,KAATA,GACFZ,EAAQ0C,QAAQ9B,GACTyJ,GAGI,KAATzJ,GACFZ,EAAQ0C,QAAQ9B,GAChB4D,EAAS,SACTZ,EAAQ,EACD0G,GAGL3E,EAAW/E,IACbZ,EAAQ0C,QAAQ9B,GACT2J,GAGFzG,EAAIlD,EACb,CAEA,SAASyJ,EAAYzJ,GACnB,OAAa,KAATA,GACFZ,EAAQ0C,QAAQ9B,GACT4J,GAGF1G,EAAIlD,EACb,CAEA,SAAS4J,EAAa5J,GACpB,OAAa,OAATA,GAA0B,KAATA,EACZkD,EAAIlD,GAGA,KAATA,GACFZ,EAAQ0C,QAAQ9B,GACT6J,GAGFC,EAAQ9J,EACjB,CAEA,SAAS6J,EAAiB7J,GACxB,OAAa,OAATA,GAA0B,KAATA,EACZkD,EAAIlD,GAGN8J,EAAQ9J,EACjB,CAEA,SAAS8J,EAAQ9J,GACf,OAAa,OAATA,EACKkD,EAAIlD,GAGA,KAATA,GACFZ,EAAQ0C,QAAQ9B,GACT+J,GAGLhL,EAAmBiB,IACrBqJ,EAAcS,EACPE,EAAahK,KAGtBZ,EAAQ0C,QAAQ9B,GACT8J,EACT,CAEA,SAASC,EAAa/J,GACpB,OAAa,KAATA,GACFZ,EAAQ0C,QAAQ9B,GACT+C,GAGF+G,EAAQ9J,EACjB,CAEA,SAAS0J,EAAU1J,GACjB,OAAIA,IAAS4D,EAAOS,WAAWrB,MAC7B5D,EAAQ0C,QAAQ9B,GACTgD,IAAUY,EAAO3D,OAASgK,EAAQP,GAGpCxG,EAAIlD,EACb,CAEA,SAASiK,EAAMjK,GACb,OAAa,OAATA,EACKkD,EAAIlD,GAGA,KAATA,GACFZ,EAAQ0C,QAAQ9B,GACTkK,GAGLnL,EAAmBiB,IACrBqJ,EAAcY,EACPD,EAAahK,KAGtBZ,EAAQ0C,QAAQ9B,GACTiK,EACT,CAEA,SAASC,EAAWlK,GAClB,OAAa,KAATA,GACFZ,EAAQ0C,QAAQ9B,GACTmK,GAGFF,EAAMjK,EACf,CAEA,SAASmK,EAASnK,GAChB,OAAa,KAATA,EACK+C,EAAI/C,GAGA,KAATA,GACFZ,EAAQ0C,QAAQ9B,GACTmK,GAGFF,EAAMjK,EACf,CAEA,SAAS2J,EAAY3J,GACnB,OAAa,OAATA,GAA0B,KAATA,EACZ+C,EAAI/C,GAGTjB,EAAmBiB,IACrBqJ,EAAcM,EACPK,EAAahK,KAGtBZ,EAAQ0C,QAAQ9B,GACT2J,EACT,CAEA,SAASJ,EAAYvJ,GACnB,OAAa,OAATA,EACKkD,EAAIlD,GAGA,KAATA,GACFZ,EAAQ0C,QAAQ9B,GACToK,GAGLrL,EAAmBiB,IACrBqJ,EAAcE,EACPS,EAAahK,KAGtBZ,EAAQ0C,QAAQ9B,GACTuJ,EACT,CAEA,SAASa,EAAiBpK,GACxB,OAAgB,KAATA,EAAc+C,EAAI/C,GAAQuJ,EAAYvJ,EAC/C,CAEA,SAAS6F,EAAc7F,GACrB,OAAI+E,EAAW/E,IACbZ,EAAQ0C,QAAQ9B,GACTqK,GAGFnH,EAAIlD,EACb,CAEA,SAASqK,EAASrK,GAChB,OAAa,KAATA,GAAegF,EAAkBhF,IACnCZ,EAAQ0C,QAAQ9B,GACTqK,GAGFC,EAAgBtK,EACzB,CAEA,SAASsK,EAAgBtK,GACvB,OAAIjB,EAAmBiB,IACrBqJ,EAAciB,EACPN,EAAahK,IAGlBkF,EAAclF,IAChBZ,EAAQ0C,QAAQ9B,GACTsK,GAGFvH,EAAI/C,EACb,CAEA,SAASwJ,EAAQxJ,GACf,OAAa,KAATA,GAAegF,EAAkBhF,IACnCZ,EAAQ0C,QAAQ9B,GACTwJ,GAGI,KAATxJ,GAAwB,KAATA,GAAeiF,EAA0BjF,GACnDuK,EAAevK,GAGjBkD,EAAIlD,EACb,CAEA,SAASuK,EAAevK,GACtB,OAAa,KAATA,GACFZ,EAAQ0C,QAAQ9B,GACT+C,GAGI,KAAT/C,GAAwB,KAATA,GAAe+E,EAAW/E,IAC3CZ,EAAQ0C,QAAQ9B,GACTwK,GAGLzL,EAAmBiB,IACrBqJ,EAAckB,EACPP,EAAahK,IAGlBkF,EAAclF,IAChBZ,EAAQ0C,QAAQ9B,GACTuK,GAGFxH,EAAI/C,EACb,CAEA,SAASwK,EAAqBxK,GAC5B,OACW,KAATA,GACS,KAATA,GACS,KAATA,GACS,KAATA,GACAgF,EAAkBhF,IAElBZ,EAAQ0C,QAAQ9B,GACTwK,GAGFC,EAA0BzK,EACnC,CAEA,SAASyK,EAA0BzK,GACjC,OAAa,KAATA,GACFZ,EAAQ0C,QAAQ9B,GACT0K,GAGL3L,EAAmBiB,IACrBqJ,EAAcoB,EACPT,EAAahK,IAGlBkF,EAAclF,IAChBZ,EAAQ0C,QAAQ9B,GACTyK,GAGFF,EAAevK,EACxB,CAEA,SAAS0K,EAA4B1K,GACnC,OACW,OAATA,GACS,KAATA,GACS,KAATA,GACS,KAATA,GACS,KAATA,EAEOkD,EAAIlD,GAGA,KAATA,GAAwB,KAATA,GACjBZ,EAAQ0C,QAAQ9B,GAChB0F,EAAS1F,EACF2K,GAGL5L,EAAmBiB,IACrBqJ,EAAcqB,EACPV,EAAahK,IAGlBkF,EAAclF,IAChBZ,EAAQ0C,QAAQ9B,GACT0K,IAGTtL,EAAQ0C,QAAQ9B,GAChB0F,OAASrE,EACFuJ,EACT,CAEA,SAASD,EAA4B3K,GACnC,OAAIA,IAAS0F,GACXtG,EAAQ0C,QAAQ9B,GACT6K,GAGI,OAAT7K,EACKkD,EAAIlD,GAGTjB,EAAmBiB,IACrBqJ,EAAcsB,EACPX,EAAahK,KAGtBZ,EAAQ0C,QAAQ9B,GACT2K,EACT,CAEA,SAASE,EAAiC7K,GACxC,OAAa,KAATA,GAAwB,KAATA,GAAeiF,EAA0BjF,GACnDuK,EAAevK,GAGjBkD,EAAIlD,EACb,CAEA,SAAS4K,EAA8B5K,GACrC,OACW,OAATA,GACS,KAATA,GACS,KAATA,GACS,KAATA,GACS,KAATA,GACS,KAATA,EAEOkD,EAAIlD,GAGA,KAATA,GAAeiF,EAA0BjF,GACpCuK,EAAevK,IAGxBZ,EAAQ0C,QAAQ9B,GACT4K,EACT,CAGA,SAASZ,EAAahK,GAKpB,OAJAZ,EAAQmD,KAAK,gBACbnD,EAAQ8C,MAAM,cACd9C,EAAQ0C,QAAQ9B,GAChBZ,EAAQmD,KAAK,cACNtD,EACLG,EACA0L,EACA,aACAtL,EAAKuC,OAAOoB,WAAWE,QAAQC,KAAKC,QAAQ,iBAAmB,OAC3DlC,EACA,EAER,CAEA,SAASyJ,EAAY9K,GAEnB,OADAZ,EAAQ8C,MAAM,gBACPmH,EAAYrJ,EACrB,CAEA,SAAS+C,EAAI/C,GACX,OAAa,KAATA,GACFZ,EAAQ0C,QAAQ9B,GAChBZ,EAAQmD,KAAK,gBACbnD,EAAQmD,KAAK,YACN1C,GAGFqD,EAAIlD,EACb,CACF,GAEA8E,EAAOjG,QAAUuK,C,kBChbjB,IAAInE,EAA4BjG,EAAQ,OACpC4F,EAAqB5F,EAAQ,MAC7B+L,EAAoB/L,EAAQ,OAoBhC8F,EAAOjG,QAdP,SAA2BmB,GACzB,OACW,OAATA,GACAiF,EAA0BjF,IAC1B+K,EAAkB/K,GAEX,EAGL4E,EAAmB5E,GACd,OADT,CAGF,C,YCXA8E,EAAOjG,QAPP,SAAmBmM,EAAOC,GAIxB,OAHAD,EAAMrH,QAAUsH,EAChBD,EAAMC,QAAUA,EAChBD,EAAME,cAAgBD,EACfD,CACT,C,kBCPA,IAAI7B,EAASnK,EAAQ,OAMrB8F,EAAOjG,QAJP,SAAiBsM,GACf,OAAOhC,EAAO,CAAC,EAAGgC,EACpB,C,kBCJA,IAAIpM,EAAqBC,EAAQ,OAC7BoM,EAAUpM,EAAQ,OAClBC,EAAeD,EAAQ,OAEvBqM,EAAkB,CACpB9F,KAAM,kBACNpG,SAwDF,SAAiCC,EAASS,EAAIqD,GAC5C,IAEIwC,EACA4F,EAHA9L,EAAOC,KACPuD,EAAQxD,EAAKgI,OAAOvH,OAIxB,KAAO+C,KAGL,GACiC,eAA/BxD,EAAKgI,OAAOxE,GAAO,GAAGyE,MACS,eAA/BjI,EAAKgI,OAAOxE,GAAO,GAAGyE,MACS,YAA/BjI,EAAKgI,OAAOxE,GAAO,GAAGyE,KACtB,CACA6D,EAA2C,cAA/B9L,EAAKgI,OAAOxE,GAAO,GAAGyE,KAClC,KACF,CAGF,OAEA,SAAezH,GACb,IAAKR,EAAKwB,OAASxB,EAAKmB,WAAa2K,GAInC,OAHAlM,EAAQ8C,MAAM,qBACd9C,EAAQ8C,MAAM,6BACdwD,EAAS1F,EACFuL,EAAgBvL,GAGzB,OAAOkD,EAAIlD,EACb,EAEA,SAASuL,EAAgBvL,GACvB,OAAIA,IAAS0F,GACXtG,EAAQ0C,QAAQ9B,GACTuL,IAGTnM,EAAQmD,KAAK,6BACNtD,EAAaG,EAASoM,EAAoB,aAA1CvM,CAAwDe,GACjE,CAEA,SAASwL,EAAmBxL,GAC1B,OAAa,OAATA,GAAiBjB,EAAmBiB,IACtCZ,EAAQmD,KAAK,qBACN1C,EAAGG,IAGLkD,EAAIlD,EACb,CACF,EAzGEuH,UAGF,SAAkCC,EAAQuB,GACxC,IACIV,EACAoD,EACAC,EACAC,EAJA3I,EAAQwE,EAAOvH,OAOnB,KAAO+C,KACL,GAAyB,UAArBwE,EAAOxE,GAAO,GAAgB,CAChC,GAA8B,YAA1BwE,EAAOxE,GAAO,GAAGyE,KAAoB,CACvCY,EAAUrF,EACV,KACF,CAE8B,cAA1BwE,EAAOxE,GAAO,GAAGyE,OACnBgE,EAAOzI,EAEX,KAEgC,YAA1BwE,EAAOxE,GAAO,GAAGyE,MAEnBD,EAAOE,OAAO1E,EAAO,GAGlB0I,GAAwC,eAA1BlE,EAAOxE,GAAO,GAAGyE,OAClCiE,EAAa1I,GAKnB2I,EAAU,CACRlE,KAAM,gBACNlG,MAAO6J,EAAQ5D,EAAOiE,GAAM,GAAGlK,OAC/BwB,IAAKqI,EAAQ5D,EAAOA,EAAOvH,OAAS,GAAG,GAAG8C,MAG5CyE,EAAOiE,GAAM,GAAGhE,KAAO,oBAGnBiE,GACFlE,EAAOE,OAAO+D,EAAM,EAAG,CAAC,QAASE,EAAS5C,IAC1CvB,EAAOE,OAAOgE,EAAa,EAAG,EAAG,CAAC,OAAQlE,EAAOa,GAAS,GAAIU,IAC9DvB,EAAOa,GAAS,GAAGtF,IAAMqI,EAAQ5D,EAAOkE,GAAY,GAAG3I,MAEvDyE,EAAOa,GAAS,GAAKsD,EAIvB,OADAnE,EAAO5F,KAAK,CAAC,OAAQ+J,EAAS5C,IACvBvB,CACT,GAsDA1C,EAAOjG,QAAUwM,C,kBClHjB,IAEIO,EAAiB,CACnBrG,KAAM,iBACNpG,SAIF,SAAgCC,EAASS,EAAIqD,GAC3C,IAAI1D,EAAOC,KACX,OAEA,SAAeO,GAMb,OALAZ,EAAQ8C,MAAM,aACd9C,EAAQ8C,MAAM,eACd9C,EAAQ0C,QAAQ9B,GAChBZ,EAAQmD,KAAK,eACbnD,EAAQmD,KAAK,aACNsJ,CACT,EAEA,SAASA,EAAM7L,GAEb,OAAgB,KAATA,GAEL,2BAA4BR,EAAKuC,OAAOoB,WAEtCD,EAAIlD,GACJH,EAAGG,EACT,CACF,EAzBEkJ,WALalK,EAAQ,OAKAkK,YA2BvBpE,EAAOjG,QAAU+M,C,kBChCjB,IAAIE,EAAmB9M,EAAQ,OAE3B+M,EAAkB,CACpBxG,KAAM,kBACNpG,SAGF,SAAiCC,EAASS,EAAIqD,GAC5C,OAEA,SAAelD,GAKb,OAJAZ,EAAQ8C,MAAM,mBACd9C,EAAQ8C,MAAM,gBACd9C,EAAQ0C,QAAQ9B,GAChBZ,EAAQmD,KAAK,gBACNoD,CACT,EAEA,SAASA,EAAK3F,GACZ,OAAI8L,EAAiB9L,IACnBZ,EAAQ8C,MAAM,wBACd9C,EAAQ0C,QAAQ9B,GAChBZ,EAAQmD,KAAK,wBACbnD,EAAQmD,KAAK,mBACN1C,GAGFqD,EAAIlD,EACb,CACF,GAEA8E,EAAOjG,QAAUkN,C,YC/BjB,IAAIrE,EAAS,GAAGA,OAEhB5C,EAAOjG,QAAU6I,C,kBCFjB,IAAI3I,EAAqBC,EAAQ,OAC7BiG,EAA4BjG,EAAQ,OACpCgN,EAAahN,EAAQ,OACrBC,EAAeD,EAAQ,OAEvBiN,EAAa,CACf1G,KAAM,aACNpG,SAIF,SAA4BC,EAASS,EAAIqD,GACvC,IAOIwC,EAPAlG,EAAOC,KACPyM,EAAwB,CAC1B/M,SAuHF,SAA8BC,EAASS,EAAIqD,GACzC,IAAIJ,EAAO,EACX,OAAO7D,EACLG,EACA+M,EACA,aACA1M,KAAKsC,OAAOoB,WAAWE,QAAQC,KAAKC,QAAQ,iBAAmB,OAC3DlC,EACA,GAGN,SAAS8K,EAAqBnM,GAG5B,OAFAZ,EAAQ8C,MAAM,mBACd9C,EAAQ8C,MAAM,2BACPqJ,EAAgBvL,EACzB,CAEA,SAASuL,EAAgBvL,GACvB,OAAIA,IAAS0F,GACXtG,EAAQ0C,QAAQ9B,GAChB8C,IACOyI,GAGLzI,EAAOsJ,EAAiBlJ,EAAIlD,IAChCZ,EAAQmD,KAAK,2BACNtD,EAAaG,EAASoM,EAAoB,aAA1CvM,CAAwDe,GACjE,CAEA,SAASwL,EAAmBxL,GAC1B,OAAa,OAATA,GAAiBjB,EAAmBiB,IACtCZ,EAAQmD,KAAK,mBACN1C,EAAGG,IAGLkD,EAAIlD,EACb,CACF,EA3JEsB,SAAS,GAEP+K,EAAgBL,EAAWvM,KAAK+H,OAAQ,cACxC4E,EAAW,EAEf,OAEA,SAAepM,GAKb,OAJAZ,EAAQ8C,MAAM,cACd9C,EAAQ8C,MAAM,mBACd9C,EAAQ8C,MAAM,2BACdwD,EAAS1F,EACFsM,EAAatM,EACtB,EAEA,SAASsM,EAAatM,GACpB,OAAIA,IAAS0F,GACXtG,EAAQ0C,QAAQ9B,GAChBoM,IACOE,IAGTlN,EAAQmD,KAAK,2BACN6J,EAAW,EACdlJ,EAAIlD,GACJf,EAAaG,EAASmN,EAAU,aAAhCtN,CAA8Ce,GACpD,CAEA,SAASuM,EAASvM,GAChB,OAAa,OAATA,GAAiBjB,EAAmBiB,GAC/BwM,EAAUxM,IAGnBZ,EAAQ8C,MAAM,uBACd9C,EAAQ8C,MAAM,cAAe,CAC3BC,YAAa,WAERsK,EAAKzM,GACd,CAEA,SAASyM,EAAKzM,GACZ,OAAa,OAATA,GAAiBiF,EAA0BjF,IAC7CZ,EAAQmD,KAAK,eACbnD,EAAQmD,KAAK,uBACNtD,EAAaG,EAASsN,EAAW,aAAjCzN,CAA+Ce,IAG3C,KAATA,GAAeA,IAAS0F,EAAexC,EAAIlD,IAC/CZ,EAAQ0C,QAAQ9B,GACTyM,EACT,CAEA,SAASC,EAAU1M,GACjB,OAAa,OAATA,GAAiBjB,EAAmBiB,GAC/BwM,EAAUxM,IAGnBZ,EAAQ8C,MAAM,uBACd9C,EAAQ8C,MAAM,cAAe,CAC3BC,YAAa,WAERwK,EAAK3M,GACd,CAEA,SAAS2M,EAAK3M,GACZ,OAAa,OAATA,GAAiBjB,EAAmBiB,IACtCZ,EAAQmD,KAAK,eACbnD,EAAQmD,KAAK,uBACNiK,EAAUxM,IAGN,KAATA,GAAeA,IAAS0F,EAAexC,EAAIlD,IAC/CZ,EAAQ0C,QAAQ9B,GACT2M,EACT,CAEA,SAASH,EAAUxM,GAEjB,OADAZ,EAAQmD,KAAK,mBACN/C,EAAKmB,UAAYd,EAAGG,GAAQqI,EAAQrI,EAC7C,CAEA,SAASqI,EAAQrI,GACf,OAAa,OAATA,EACK6L,EAAM7L,GAGXjB,EAAmBiB,IACrBZ,EAAQ8C,MAAM,cACd9C,EAAQ0C,QAAQ9B,GAChBZ,EAAQmD,KAAK,cACNnD,EAAQe,QACb+L,EACAL,EACAQ,EACIpN,EAAaG,EAASiJ,EAAS,aAAcgE,EAAgB,GAC7DhE,KAIRjJ,EAAQ8C,MAAM,iBACP0K,EAAgB5M,GACzB,CAEA,SAAS4M,EAAgB5M,GACvB,OAAa,OAATA,GAAiBjB,EAAmBiB,IACtCZ,EAAQmD,KAAK,iBACN8F,EAAQrI,KAGjBZ,EAAQ0C,QAAQ9B,GACT4M,EACT,CAEA,SAASf,EAAM7L,GAEb,OADAZ,EAAQmD,KAAK,cACN1C,EAAGG,EACZ,CAwCF,EAnKEQ,UAAU,GAqKZsE,EAAOjG,QAAUoN,C,kBC7KjB,IAAIlN,EAAqBC,EAAQ,OAC7BC,EAAeD,EAAQ,OAEvBE,EAAmB,CACrBC,SAIF,SAAkCC,EAASS,EAAIqD,GAC7C,OAAOjE,EAAaG,GAEpB,SAAyBY,GACvB,OAAgB,OAATA,GAAiBjB,EAAmBiB,GAAQH,EAAGG,GAAQkD,EAAIlD,EACpE,GAJ8C,aAKhD,EATEsB,SAAS,GAWXwD,EAAOjG,QAAUK,C,kBChBjB,IAAIiG,EAAenG,EAAQ,MAU3B8F,EAAOjG,QARP,SAAoBgO,GAClB,OAEA,SAAe7M,GACb,OAAO6M,EAAMC,KAAK3H,EAAanF,GACjC,CACF,C,YC0DA8E,EAAOjG,QAjEM,CACX,UACA,UACA,QACA,OACA,WACA,aACA,OACA,UACA,SACA,MACA,WACA,KACA,UACA,SACA,MACA,MACA,KACA,KACA,WACA,aACA,SACA,SACA,OACA,QACA,WACA,KACA,KACA,KACA,KACA,KACA,KACA,OACA,SACA,KACA,OACA,SACA,SACA,KACA,OACA,OACA,OACA,WACA,MACA,WACA,KACA,WACA,SACA,IACA,QACA,UACA,SACA,UACA,QACA,QACA,KACA,QACA,KACA,QACA,QACA,KACA,QACA,K,YC3DFiG,EAAOjG,QAJP,SAA4BmB,GAC1B,OAAOA,GAAQ,CACjB,C,kBCFA,IAAI+M,EAAgB/N,EAAQ,OAW5B8F,EAAOjG,QATP,SAAqBmO,EAAMC,GACzB,OAAID,EAAK/M,QACP8M,EAAcC,EAAMA,EAAK/M,OAAQ,EAAGgN,GAC7BD,GAGFC,CACT,C,kBCTA,IAAIC,EAAalO,EAAQ,OAQzB8F,EAAOjG,QANP,SAAoB2I,EAAQC,GAC1B,IAAI0F,EAAO3F,EAAOA,EAAOvH,OAAS,GAClC,OAAKkN,GAAQA,EAAK,GAAG1F,OAASA,EACvByF,EAAWC,EAAK,GAAGtK,YAAYsK,EAAK,KADA,CAE7C,C,kBCNA,IAAIpO,EAAqBC,EAAQ,OAE7BoO,EAAkB,CACpB7H,KAAM,kBACNpG,SAGF,SAAiCC,EAASS,EAAIqD,GAC5C,OAEA,SAAelD,GAIb,OAHAZ,EAAQ8C,MAAM,mBACd9C,EAAQ8C,MAAM,gBACd9C,EAAQ0C,QAAQ9B,GACT2F,CACT,EAEA,SAASA,EAAK3F,GACZ,OAAIjB,EAAmBiB,IACrBZ,EAAQmD,KAAK,gBACbnD,EAAQmD,KAAK,mBACN1C,EAAGG,IAGLkD,EAAIlD,EACb,CACF,GAEA8E,EAAOjG,QAAUuO,C,kBC5BjB,IAAIlI,EAAgBlG,EAAQ,OA2B5B8F,EAAOjG,QAzBP,SAAsBO,EAASS,EAAI4H,EAAM4F,GACvC,IAAIC,EAAQD,EAAMA,EAAM,EAAIE,IACxBzK,EAAO,EACX,OAEA,SAAe9C,GACb,GAAIkF,EAAclF,GAEhB,OADAZ,EAAQ8C,MAAMuF,GACP+F,EAAOxN,GAGhB,OAAOH,EAAGG,EACZ,EAEA,SAASwN,EAAOxN,GACd,OAAIkF,EAAclF,IAAS8C,IAASwK,GAClClO,EAAQ0C,QAAQ9B,GACTwN,IAGTpO,EAAQmD,KAAKkF,GACN5H,EAAGG,GACZ,CACF,C,mCCZA,MAAMwD,EAAS,cAKR,SAASC,IACd,IAKIC,EALAC,EAAS,EACTC,EAAS,GAETrC,GAAQ,EAGZ,OAGA,SAAsBzC,EAAO+E,EAAUd,GAErC,MAAMe,EAAS,GAEf,IAAIC,EAEArB,EAEAsB,EAEAC,EAEAjE,EAGJlB,EAAQ8E,EAAS9E,EAAMoF,SAASL,GAChCG,EAAgB,EAChBJ,EAAS,GACLrC,IAE0B,QAAxBzC,EAAMuF,WAAW,IACnBL,IAEFzC,OAAQF,GAEV,KAAO2C,EAAgBlF,EAAMmB,QAAQ,CAMnC,GALAuD,EAAOc,UAAYN,EACnBD,EAAQP,EAAOe,KAAKzF,GACpBmF,EACEF,QAAyB1C,IAAhB0C,EAAMf,MAAsBe,EAAMf,MAAQlE,EAAMmB,OAC3DD,EAAOlB,EAAMuF,WAAWJ,IACnBF,EAAO,CACVH,EAAS9E,EAAM0F,MAAMR,GACrB,KACF,CACA,GAAa,KAAThE,GAAegE,IAAkBC,GAAeP,EAClDI,EAAOlC,MAAM,GACb8B,OAAmBrC,OAUnB,OARIqC,IACFI,EAAOlC,MAAM,GACb8B,OAAmBrC,GAEjB2C,EAAgBC,IAClBH,EAAOlC,KAAK9C,EAAM0F,MAAMR,EAAeC,IACvCN,GAAUM,EAAcD,GAElBhE,GACN,KAAK,EACH8D,EAAOlC,KAAK,OACZ+B,IACA,MAEF,KAAK,EAGH,IAFAjB,EAA+B,EAAxB+B,KAAKC,KAAKf,EAAS,GAC1BG,EAAOlC,MAAM,GACN+B,IAAWjB,GAAMoB,EAAOlC,MAAM,GACrC,MAEF,KAAK,GACHkC,EAAOlC,MAAM,GACb+B,EAAS,EACT,MAEF,QACED,GAAmB,EACnBC,EAAS,EAIfK,EAAgBC,EAAc,CAChC,CACIlB,IACEW,GAAkBI,EAAOlC,MAAM,GAC/BgC,GAAQE,EAAOlC,KAAKgC,GACxBE,EAAOlC,KAAK,OAEd,OAAOkC,CACT,CACF,C,YCnFAgB,EAAOjG,QAxBP,SAAqBiF,EAAQrB,GAC3B,IAIIgL,EAJAC,EAAajL,EAAMlB,MAAMoM,OACzBC,EAAmBnL,EAAMlB,MAAM2J,aAC/B2C,EAAWpL,EAAMM,IAAI4K,OACrBG,EAAiBrL,EAAMM,IAAImI,aAiB/B,OAdIwC,IAAeG,EACjBJ,EAAO,CAAC3J,EAAO4J,GAAYlJ,MAAMoJ,EAAkBE,KAEnDL,EAAO3J,EAAOU,MAAMkJ,EAAYG,GAE5BD,GAAoB,IACtBH,EAAK,GAAKA,EAAK,GAAGjJ,MAAMoJ,IAGtBE,EAAiB,GACnBL,EAAK7L,KAAKkC,EAAO+J,GAAUrJ,MAAM,EAAGsJ,KAIjCL,CACT,C,kBCtBA,IAAI/F,EAAS1I,EAAQ,OAmCrB8F,EAAOjG,QA/BP,SAAuBmO,EAAMzL,EAAOwM,EAAQd,GAC1C,IAEIe,EAFAjL,EAAMiK,EAAK/M,OACXgO,EAAa,EAWjB,GAPE1M,EADEA,EAAQ,GACDA,EAAQwB,EAAM,EAAIA,EAAMxB,EAEzBA,EAAQwB,EAAMA,EAAMxB,EAG9BwM,EAASA,EAAS,EAAIA,EAAS,EAE3Bd,EAAMhN,OAAS,KACjB+N,EAAaE,MAAMC,KAAKlB,IACbmB,QAAQ7M,EAAOwM,GAC1BrG,EAAO2G,MAAMrB,EAAMgB,QAKnB,IAFID,GAAQrG,EAAO2G,MAAMrB,EAAM,CAACzL,EAAOwM,IAEhCE,EAAahB,EAAMhN,SACxB+N,EAAaf,EAAMzI,MAAMyJ,EAAYA,EAAa,MACvCG,QAAQ7M,EAAO,GAC1BmG,EAAO2G,MAAMrB,EAAMgB,GACnBC,GAAc,IACd1M,GAAS,GAGf,C,YCxBAuD,EAAOjG,QARP,SAAsBmB,GACpB,OAGEA,EAAO,IAAe,MAATA,CAEjB,C,kBCPA,IAAIsO,EAAetP,EAAQ,OACvBgG,EAAoBhG,EAAQ,OAC5BuP,EAAavP,EAAQ,OACrBwP,EAAgBxP,EAAQ,OAE5B,SAASyP,EAAsBC,GAC7B,OAAOA,GAAkB,kBAANA,GAAkB,YAAaA,EAAIA,EAAI,CAACC,QAASD,EACtE,CAEA,IAAIE,EAAsCH,EAAsBH,GAE5DO,EAAqB,CACvBtJ,KAAM,qBACNpG,SAGF,SAAoCC,EAASS,EAAIqD,GAC/C,IAEImK,EACAP,EAHAtN,EAAOC,KACPqD,EAAO,EAGX,OAEA,SAAe9C,GAKb,OAJAZ,EAAQ8C,MAAM,sBACd9C,EAAQ8C,MAAM,4BACd9C,EAAQ0C,QAAQ9B,GAChBZ,EAAQmD,KAAK,4BACNoD,CACT,EAEA,SAASA,EAAK3F,GACZ,OAAa,KAATA,GACFZ,EAAQ8C,MAAM,mCACd9C,EAAQ0C,QAAQ9B,GAChBZ,EAAQmD,KAAK,mCACNuM,IAGT1P,EAAQ8C,MAAM,2BACdmL,EAAM,GACNP,EAAO9H,EACAlG,EAAMkB,GACf,CAEA,SAAS8O,EAAQ9O,GACf,OAAa,KAATA,GAAwB,MAATA,GACjBZ,EAAQ8C,MAAM,uCACd9C,EAAQ0C,QAAQ9B,GAChBZ,EAAQmD,KAAK,uCACbnD,EAAQ8C,MAAM,2BACdmL,EAAM,EACNP,EAAO0B,EACA1P,IAGTM,EAAQ8C,MAAM,2BACdmL,EAAM,EACNP,EAAOyB,EACAzP,EAAMkB,GACf,CAEA,SAASlB,EAAMkB,GACb,IAAIyC,EAEJ,OAAa,KAATzC,GAAe8C,GACjBL,EAAQrD,EAAQmD,KAAK,2BAGnBuK,IAAS9H,GACR4J,EAA+B,QAAEpP,EAAKuP,eAAetM,KAKxDrD,EAAQ8C,MAAM,4BACd9C,EAAQ0C,QAAQ9B,GAChBZ,EAAQmD,KAAK,4BACbnD,EAAQmD,KAAK,sBACN1C,GAPEqD,EAAIlD,IAUX8M,EAAK9M,IAAS8C,IAASuK,GACzBjO,EAAQ0C,QAAQ9B,GACTlB,GAGFoE,EAAIlD,EACb,CACF,GAEA8E,EAAOjG,QAAUgQ,C,kBC3FjB,IAAIG,EAAiBhQ,EAAQ,OACzB+N,EAAgB/N,EAAQ,OACxBiQ,EAAWjQ,EAAQ,OAavB,SAASkQ,EAAUC,EAAKD,GACtB,IAAIE,EACAC,EACAC,EACAtP,EAEJ,IAAKoP,KAAQF,EAIX,IAAKlP,KAHLqP,EAAOL,EAAe/L,KAAKkM,EAAKC,GAAQD,EAAIC,GAASD,EAAIC,GAAQ,CAAC,EAClEE,EAAQJ,EAAUE,GAGhBC,EAAKrP,GAAQmD,EACX8L,EAASK,EAAMtP,IACfgP,EAAe/L,KAAKoM,EAAMrP,GAAQqP,EAAKrP,GAAQ,GAIvD,CAEA,SAASmD,EAAW6J,EAAMuC,GAIxB,IAHA,IAAIvM,GAAS,EACTwM,EAAS,KAEJxM,EAAQgK,EAAK/M,SACE,UAApB+M,EAAKhK,GAAOyM,IAAkBF,EAAWC,GAAQ5N,KAAKoL,EAAKhK,IAI/D,OADA+J,EAAcwC,EAAU,EAAG,EAAGC,GACvBD,CACT,CAEAzK,EAAOjG,QA1CP,SAA2B6Q,GAIzB,IAHA,IAAIP,EAAM,CAAC,EACPnM,GAAS,IAEJA,EAAQ0M,EAAWzP,QAC1BiP,EAAUC,EAAKO,EAAW1M,IAG5B,OAAOmM,CACT,C,kBCbA,IAAIpQ,EAAqBC,EAAQ,OAC7BgN,EAAahN,EAAQ,OACrB2J,EAAc3J,EAAQ,OACtBC,EAAeD,EAAQ,OAGvBqJ,EAAU,CACZlJ,SAgBF,SAAyBC,EAASS,GAChC,IAAIuC,EACJ,OAEA,SAAepC,GAKb,OAJAZ,EAAQ8C,MAAM,WACdE,EAAWhD,EAAQ8C,MAAM,eAAgB,CACvCC,YAAa,YAERwN,EAAK3P,EACd,EAEA,SAAS2P,EAAK3P,GACZ,OAAa,OAATA,EACK4P,EAAW5P,GAGhBjB,EAAmBiB,GACdZ,EAAQ8B,MACb2O,EACAjD,EACAgD,EAHKxQ,CAILY,IAGJZ,EAAQ0C,QAAQ9B,GACT2P,EACT,CAEA,SAASC,EAAW5P,GAGlB,OAFAZ,EAAQmD,KAAK,gBACbnD,EAAQmD,KAAK,WACN1C,EAAGG,EACZ,CAEA,SAAS4M,EAAgB5M,GAOvB,OANAZ,EAAQ0C,QAAQ9B,GAChBZ,EAAQmD,KAAK,gBACbH,EAAWA,EAASM,KAAOtD,EAAQ8C,MAAM,eAAgB,CACvDC,YAAa,UACbC,SAAUA,IAELuN,CACT,CACF,EA3DE3G,QAUF,SAAwBxB,GAEtB,OADAmB,EAAYnB,GACLA,CACT,EAZE5G,eAAe,EACfI,MAAM,GAEJ6O,EAAwB,CAC1B1Q,SAwDF,SAA8BC,EAASS,EAAIqD,GACzC,IAAI1D,EAAOC,KACX,OAEA,SAAwBO,GAItB,OAHAZ,EAAQ8C,MAAM,cACd9C,EAAQ0C,QAAQ9B,GAChBZ,EAAQmD,KAAK,cACNtD,EAAaG,EAAS0Q,EAAU,aACzC,EAEA,SAASA,EAAS9P,GAChB,OAAa,OAATA,GAAiBjB,EAAmBiB,GAC/BkD,EAAIlD,GAIXR,EAAKuC,OAAOoB,WAAWE,QAAQC,KAAKC,QAAQ,iBAAmB,GAC/DyI,EAAWxM,EAAKgI,OAAQ,cAAgB,EAEjCpI,EAAQuB,UAAUnB,EAAKuC,OAAOoB,WAAWnB,KAAMkB,EAAKrD,EAApDT,CAAwDY,GAG1DH,EAAGG,EACZ,CACF,EAhFEsB,SAAS,GAkFXwD,EAAOjG,QAAUwJ,C,YCnFjBvD,EAAOjG,QAXP,SAAoBiF,GAIlB,IAHA,IAAId,GAAS,EACTF,EAAO,IAEFE,EAAQc,EAAO7D,QACtB6C,GAAiC,kBAAlBgB,EAAOd,GAAsBc,EAAOd,GAAO/C,OAAS,EAGrE,OAAO6C,CACT,C,YCXA,IAAIiN,EAAM,CAAC,EAAEf,eAEblK,EAAOjG,QAAUkR,C,kBCFjB,IAEIpI,EAFa3I,EAAQ,MAER6F,CAAW,uBAE5BC,EAAOjG,QAAU8I,C,kBCJjB,IAAI4G,EAAavP,EAAQ,OACrBkG,EAAgBlG,EAAQ,OACxBgN,EAAahN,EAAQ,OACrBkO,EAAalO,EAAQ,OACrBC,EAAeD,EAAQ,OACvBE,EAAmBF,EAAQ,OAC3B4J,EAAgB5J,EAAQ,OAExBgO,EAAO,CACTzH,KAAM,OACNpG,SAeF,SAA2BC,EAASS,EAAIqD,GACtC,IAAI1D,EAAOC,KACPuQ,EAAchE,EAAWxM,EAAKgI,OAAQ,cACtC1E,EAAO,EACX,OAEA,SAAe9C,GACb,IAAIwF,EACFhG,EAAKU,eAAeuH,OACV,KAATzH,GAAwB,KAATA,GAAwB,KAATA,EAC3B,gBACA,eAEN,GACW,kBAATwF,GACKhG,EAAKU,eAAewF,QAAU1F,IAASR,EAAKU,eAAewF,OAC5D6I,EAAWvO,GACf,CAQA,GAPKR,EAAKU,eAAeuH,OACvBjI,EAAKU,eAAeuH,KAAOjC,EAC3BpG,EAAQ8C,MAAMsD,EAAM,CAClByK,YAAY,KAIH,kBAATzK,EAEF,OADApG,EAAQ8C,MAAM,kBACE,KAATlC,GAAwB,KAATA,EAClBZ,EAAQ8B,MAAM0H,EAAe1F,EAAKgN,EAAlC9Q,CAA4CY,GAC5CkQ,EAASlQ,GAGf,IAAKR,EAAKmB,WAAsB,KAATX,EAGrB,OAFAZ,EAAQ8C,MAAM,kBACd9C,EAAQ8C,MAAM,iBACPiO,EAAOnQ,EAElB,CAEA,OAAOkD,EAAIlD,EACb,EAEA,SAASmQ,EAAOnQ,GACd,OAAIuO,EAAWvO,MAAW8C,EAAO,IAC/B1D,EAAQ0C,QAAQ9B,GACTmQ,KAIL3Q,EAAKmB,WAAamC,EAAO,KAC1BtD,EAAKU,eAAewF,OACjB1F,IAASR,EAAKU,eAAewF,OACpB,KAAT1F,GAAwB,KAATA,IAEnBZ,EAAQmD,KAAK,iBACN2N,EAASlQ,IAGXkD,EAAIlD,EACb,CAEA,SAASkQ,EAASlQ,GAKhB,OAJAZ,EAAQ8C,MAAM,kBACd9C,EAAQ0C,QAAQ9B,GAChBZ,EAAQmD,KAAK,kBACb/C,EAAKU,eAAewF,OAASlG,EAAKU,eAAewF,QAAU1F,EACpDZ,EAAQ8B,MACbhC,EACAM,EAAKmB,UAAYuC,EAAMkN,EACvBhR,EAAQe,QACNkQ,EACAC,EACAC,GAGN,CAEA,SAASH,EAAQpQ,GAGf,OAFAR,EAAKU,eAAesQ,kBAAmB,EACvCR,IACOM,EAAYtQ,EACrB,CAEA,SAASuQ,EAAYvQ,GACnB,OAAIkF,EAAclF,IAChBZ,EAAQ8C,MAAM,4BACd9C,EAAQ0C,QAAQ9B,GAChBZ,EAAQmD,KAAK,4BACN+N,GAGFpN,EAAIlD,EACb,CAEA,SAASsQ,EAAYtQ,GAGnB,OAFAR,EAAKU,eAAe4C,KAClBkN,EAAc9C,EAAW1N,EAAKqD,YAAYzD,EAAQmD,KAAK,oBAClD1C,EAAGG,EACZ,CACF,EAjHEI,aAAc,CACZjB,SAkHJ,SAAkCC,EAASS,EAAIqD,GAC7C,IAAI1D,EAAOC,KAEX,OADAD,EAAKU,eAAea,gBAAaM,EAC1BjC,EAAQ8B,MAAMhC,GAErB,SAAiBc,GAMf,OALAR,EAAKU,eAAeuQ,kBAClBjR,EAAKU,eAAeuQ,mBACpBjR,EAAKU,eAAesQ,iBAGfvR,EACLG,EACAS,EACA,iBACAL,EAAKU,eAAe4C,KAAO,EAJtB7D,CAKLe,EACJ,IAEA,SAAkBA,GAChB,GAAIR,EAAKU,eAAeuQ,oBAAsBvL,EAAclF,GAE1D,OADAR,EAAKU,eAAeuQ,kBAAoBjR,EAAKU,eAAesQ,sBAAmBnP,EACxEqP,EAAiB1Q,GAI1B,OADAR,EAAKU,eAAeuQ,kBAAoBjR,EAAKU,eAAesQ,sBAAmBnP,EACxEjC,EAAQe,QAAQwQ,EAAiB9Q,EAAI6Q,EAArCtR,CAAuDY,EAChE,IAEA,SAAS0Q,EAAiB1Q,GAKxB,OAHAR,EAAKU,eAAea,YAAa,EAEjCvB,EAAKmB,eAAYU,EACVpC,EACLG,EACAA,EAAQe,QAAQ6M,EAAMnN,EAAIqD,GAC1B,aACA1D,EAAKuC,OAAOoB,WAAWE,QAAQC,KAAKC,QAAQ,iBAAmB,OAC3DlC,EACA,EANCpC,CAOLe,EACJ,CACF,GA3JEuC,KA8KF,SAAyBnD,GACvBA,EAAQmD,KAAK9C,KAAKS,eAAeuH,KACnC,GA9KI4I,EAAoC,CACtClR,SA+KF,SAA0CC,EAASS,EAAIqD,GACrD,IAAI1D,EAAOC,KACX,OAAOR,EACLG,GAQF,SAAqBY,GACnB,OAAOkF,EAAclF,KAClBgM,EAAWxM,EAAKgI,OAAQ,4BACvBtE,EAAIlD,GACJH,EAAGG,EACT,GAXE,2BACAR,EAAKuC,OAAOoB,WAAWE,QAAQC,KAAKC,QAAQ,iBAAmB,OAC3DlC,EACA,EASR,EA/LEC,SAAS,GAEPqP,EAAkB,CACpBxR,SAsJF,SAAwBC,EAASS,EAAIqD,GACnC,IAAI1D,EAAOC,KACX,OAAOR,EACLG,GAMF,SAAqBY,GACnB,OAAOgM,EAAWxM,EAAKgI,OAAQ,oBAC7BhI,EAAKU,eAAe4C,KAClBjD,EAAGG,GACHkD,EAAIlD,EACV,GATE,iBACAR,EAAKU,eAAe4C,KAAO,EAS/B,EApKExB,SAAS,GA6LXwD,EAAOjG,QAAUmO,C,kBCnNjBrO,OAAOC,eAAeC,EAAS,aAA/BF,CAA8CG,OAAO,IAErD,IAAI8R,EAAS5R,EAAQ,OACjB6R,EAAY7R,EAAQ,OACpB6I,EAAW7I,EAAQ,MACnB8R,EAAa9R,EAAQ,OACrB+M,EAAkB/M,EAAQ,OAC1B6P,EAAqB7P,EAAQ,OAC7BiN,EAAajN,EAAQ,OACrB+R,EAAe/R,EAAQ,OACvBgS,EAAWhS,EAAQ,OACnB0M,EAAa1M,EAAQ,OACrBoO,EAAkBpO,EAAQ,OAC1BiS,EAAajS,EAAQ,OACrBsG,EAAWtG,EAAQ,MACnBoK,EAAWpK,EAAQ,OACnBkS,EAAWlS,EAAQ,OACnBmS,EAAkBnS,EAAQ,OAC1B4M,EAAiB5M,EAAQ,OACzBoS,EAAapS,EAAQ,OACrBgO,EAAOhO,EAAQ,OACfqM,EAAkBrM,EAAQ,OAC1B4J,EAAgB5J,EAAQ,OAExBoE,EAAW,CACb,GAAI4J,EAEJ,GAAIA,EAEJ,GAAIA,EAEJ,GAAIA,EAEJ,GAAIA,EAEJ,GAAIA,EAEJ,GAAIA,EAEJ,GAAIA,EAEJ,GAAIA,EAEJ,GAAIA,EAEJ,GAAIA,EAEJ,GAAIA,EAEJ,GAAIA,EAEJ,GAAI8D,GAEFO,EAAiB,CACnB,GAAI3F,GAEFnD,EAAc,CAChB,KAAMwI,EAEN,KAAMA,EAEN,GAAIA,GAEF/O,EAAO,CACT,GAAIiP,EAEJ,GAAIrI,EAEJ,GAAI,CAACyC,EAAiBzC,GAEtB,GAAItD,EAEJ,GAAI+F,EAEJ,GAAIzC,EAEJ,GAAIqD,EAEJ,IAAKA,GAEHqF,EAAS,CACX,GAAIzC,EAEJ,GAAI9C,GAEFN,EAAO,CACT,KAAM2F,EAEN,KAAMA,EAEN,KAAMA,EAEN,GAAID,EAEJ,GAAItC,EAEJ,GAAIgC,EAEJ,GAAI,CAAChJ,EAAUuB,GAEf,GAAIwC,EAEJ,GAAI,CAACwB,EAAiBrB,GAEtB,GAAImF,EAEJ,GAAIL,EAEJ,GAAIG,GAEFO,EAAa,CACfjO,KAAM,CAACuN,EAAWD,EAAOY,WAM3B3S,EAAQwS,eAAiBA,EACzBxS,EAAQwE,QALM,CACZC,KAAM,IAKRzE,EAAQuE,SAAWA,EACnBvE,EAAQmD,KAAOA,EACfnD,EAAQ0J,YAAcA,EACtB1J,EAAQ0S,WAAaA,EACrB1S,EAAQyS,OAASA,EACjBzS,EAAQ4M,KAAOA,C,kBC5Hf,IAAI1M,EAAqBC,EAAQ,OAC7BkG,EAAgBlG,EAAQ,OAoF5B8F,EAAOjG,QAjFP,SAAsBO,EAASS,EAAIqD,EAAKuE,EAAMgK,EAAYC,GACxD,IAEI/B,EAFAnQ,EAAOC,KACPqD,EAAO,EAEX,OAEA,SAAe9C,GAMb,OALAZ,EAAQ8C,MAAMuF,GACdrI,EAAQ8C,MAAMuP,GACdrS,EAAQ0C,QAAQ9B,GAChBZ,EAAQmD,KAAKkP,GACbrS,EAAQ8C,MAAMwP,GACP7I,CACT,EAEA,SAASA,EAAQ7I,GACf,OACW,OAATA,GACS,KAATA,GACU,KAATA,IAAgB2P,GAEP,KAAT3P,IAEE8C,GAED,2BAA4BtD,EAAKuC,OAAOoB,YAC1CL,EAAO,IAEAI,EAAIlD,GAGA,KAATA,GACFZ,EAAQmD,KAAKmP,GACbtS,EAAQ8C,MAAMuP,GACdrS,EAAQ0C,QAAQ9B,GAChBZ,EAAQmD,KAAKkP,GACbrS,EAAQmD,KAAKkF,GACN5H,GAGLd,EAAmBiB,IACrBZ,EAAQ8C,MAAM,cACd9C,EAAQ0C,QAAQ9B,GAChBZ,EAAQmD,KAAK,cACNsG,IAGTzJ,EAAQ8C,MAAM,cAAe,CAC3BC,YAAa,WAERwP,EAAM3R,GACf,CAEA,SAAS2R,EAAM3R,GACb,OACW,OAATA,GACS,KAATA,GACS,KAATA,GACAjB,EAAmBiB,IACnB8C,IAAS,KAET1D,EAAQmD,KAAK,eACNsG,EAAQ7I,KAGjBZ,EAAQ0C,QAAQ9B,GAChB2P,EAAOA,IAASzK,EAAclF,GACd,KAATA,EAAc4R,EAAcD,EACrC,CAEA,SAASC,EAAY5R,GACnB,OAAa,KAATA,GAAwB,KAATA,GAAwB,KAATA,GAChCZ,EAAQ0C,QAAQ9B,GAChB8C,IACO6O,GAGFA,EAAM3R,EACf,CACF,C,kBCnFA,IAEI8L,EAFa9M,EAAQ,MAEF6F,CAAW,kBAElCC,EAAOjG,QAAUiN,C,kBCJjB,IAEI9G,EAFahG,EAAQ,MAED6F,CAAW,cAEnCC,EAAOjG,QAAUmG,C,kDCIV,SAAS0D,EAAYlB,GAC1B,OAAQmB,EAAAA,EAAAA,GAAYnB,KAGpB,OAAOA,CACT,C,kBCbA,IAAIzI,EAAqBC,EAAQ,OAC7BiG,EAA4BjG,EAAQ,OACpC6S,EAAsB7S,EAAQ,OAC9B8S,EAAqB9S,EAAQ,OAC7B+S,EAAe/S,EAAQ,OACvBC,EAAeD,EAAQ,OACvBgT,EAAoBhT,EAAQ,OAC5BiT,EAAejT,EAAQ,OAEvB0M,EAAa,CACfnG,KAAM,aACNpG,SAOF,SAA4BC,EAASS,EAAIqD,GACvC,IACIgP,EADA1S,EAAOC,KAEX,OAEA,SAAeO,GAEb,OADAZ,EAAQ8C,MAAM,cACP6P,EAAa9O,KAClBzD,EACAJ,EACA+S,EACAjP,EACA,kBACA,wBACA,wBAPK6O,CAQL/R,EACJ,EAEA,SAASmS,EAAWnS,GAKlB,OAJAkS,EAAaL,EACXrS,EAAKuP,eAAevP,EAAKgI,OAAOhI,EAAKgI,OAAOvH,OAAS,GAAG,IAAIuE,MAAM,GAAI,IAG3D,KAATxE,GACFZ,EAAQ8C,MAAM,oBACd9C,EAAQ0C,QAAQ9B,GAChBZ,EAAQmD,KAAK,oBAENyP,EACL5S,EACA0S,EACE1S,EACAA,EAAQe,QACNiS,EACAnT,EAAaG,EAASyM,EAAO,cAC7B5M,EAAaG,EAASyM,EAAO,eAE/B3I,EACA,wBACA,+BACA,qCACA,2BACA,iCAKCA,EAAIlD,EACb,CAEA,SAAS6L,EAAM7L,GACb,OAAa,OAATA,GAAiBjB,EAAmBiB,IACtCZ,EAAQmD,KAAK,cAET/C,EAAKuC,OAAOsQ,QAAQ9O,QAAQ2O,GAAc,GAC5C1S,EAAKuC,OAAOsQ,QAAQzQ,KAAKsQ,GAGpBrS,EAAGG,IAGLkD,EAAIlD,EACb,CACF,GApEIoS,EAAiB,CACnBjT,SAqEF,SAAuBC,EAASS,EAAIqD,GAClC,OAEA,SAAelD,GACb,OAAOiF,EAA0BjF,GAC7BgS,EAAkB5S,EAASoQ,EAA3BwC,CAAmChS,GACnCkD,EAAIlD,EACV,EAEA,SAASwP,EAAOxP,GACd,OAAa,KAATA,GAAwB,KAATA,GAAwB,KAATA,EACzBiS,EACL7S,EACAH,EAAaG,EAASyM,EAAO,cAC7B3I,EACA,kBACA,wBACA,wBANK+O,CAOLjS,GAGGkD,EAAIlD,EACb,CAEA,SAAS6L,EAAM7L,GACb,OAAgB,OAATA,GAAiBjB,EAAmBiB,GAAQH,EAAGG,GAAQkD,EAAIlD,EACpE,CACF,EA/FEsB,SAAS,GAiGXwD,EAAOjG,QAAU6M,C,kBChHjB,IAEIX,EAFa/L,EAAQ,MAED6F,CAAW,MAEnCC,EAAOjG,QAAUkM,C,kBCJjB,IAAI5F,EAAenG,EAAQ,MAqC3B8F,EAAOjG,QAnCP,SAAyBiF,GAOvB,IANA,IAEIwO,EACAxT,EACAyT,EAJAvP,GAAS,EACTwP,EAAS,KAKJxP,EAAQc,EAAO7D,QAAQ,CAG9B,GAAqB,kBAFrBqS,EAAQxO,EAAOd,IAGblE,EAAQwT,OACH,IAAe,IAAXA,EACTxT,EAAQ,UACH,IAAe,IAAXwT,EACTxT,EAAQ,UACH,IAAe,IAAXwT,EACTxT,EAAQ,YACH,IAAe,IAAXwT,EACTxT,EAAQ,UACH,IAAe,IAAXwT,EAAc,CACvB,GAAIC,EAAO,SACXzT,EAAQ,GACV,MAEEA,EAAQqG,EAAamN,GAGvBC,GAAmB,IAAXD,EACRE,EAAO5Q,KAAK9C,EACd,CAEA,OAAO0T,EAAOC,KAAK,GACrB,C,YCnCA,IAAIjP,EAAS,cAoFbsB,EAAOjG,QAlFP,WACE,IAGI6E,EAHAnC,GAAQ,EACRoC,EAAS,EACTC,EAAS,GAEb,OAEA,SAAsB9E,EAAO+E,EAAUd,GACrC,IACIgB,EACArB,EACAsB,EACAC,EACAjE,EALA8D,EAAS,GAMbhF,EAAQ8E,EAAS9E,EAAMoF,SAASL,GAChCG,EAAgB,EAChBJ,EAAS,GAELrC,IAC0B,QAAxBzC,EAAMuF,WAAW,IACnBL,IAGFzC,OAAQF,GAGV,KAAO2C,EAAgBlF,EAAMmB,QAAQ,CAMnC,GALAuD,EAAOc,UAAYN,EAEnBC,GADAF,EAAQP,EAAOe,KAAKzF,IACEiF,EAAMf,MAAQlE,EAAMmB,OAC1CD,EAAOlB,EAAMuF,WAAWJ,IAEnBF,EAAO,CACVH,EAAS9E,EAAM0F,MAAMR,GACrB,KACF,CAEA,GAAa,KAAThE,GAAegE,IAAkBC,GAAeP,EAClDI,EAAOlC,MAAM,GACb8B,OAAmBrC,OAYnB,GAVIqC,IACFI,EAAOlC,MAAM,GACb8B,OAAmBrC,GAGjB2C,EAAgBC,IAClBH,EAAOlC,KAAK9C,EAAM0F,MAAMR,EAAeC,IACvCN,GAAUM,EAAcD,GAGb,IAAThE,EACF8D,EAAOlC,KAAK,OACZ+B,SACK,GAAa,IAAT3D,EAIT,IAHA0C,EAA+B,EAAxB+B,KAAKC,KAAKf,EAAS,GAC1BG,EAAOlC,MAAM,GAEN+B,IAAWjB,GAAMoB,EAAOlC,MAAM,QACnB,KAAT5B,GACT8D,EAAOlC,MAAM,GACb+B,EAAS,IAGTD,GAAmB,EACnBC,EAAS,GAIbK,EAAgBC,EAAc,CAChC,CAEIlB,IACEW,GAAkBI,EAAOlC,MAAM,GAC/BgC,GAAQE,EAAOlC,KAAKgC,GACxBE,EAAOlC,KAAK,OAGd,OAAOkC,CACT,CACF,C,kBClFA,IAAI/E,EAAqBC,EAAQ,OAE7BgS,EAAW,CACbzL,KAAM,WACNpG,SAmEF,SAA0BC,EAASS,EAAIqD,GACrC,IACIJ,EACAL,EAFA2J,EAAW,EAGf,OAEA,SAAepM,GAGb,OAFAZ,EAAQ8C,MAAM,YACd9C,EAAQ8C,MAAM,oBACPwQ,EAAgB1S,EACzB,EAEA,SAAS0S,EAAgB1S,GACvB,OAAa,KAATA,GACFZ,EAAQ0C,QAAQ9B,GAChBoM,IACOsG,IAGTtT,EAAQmD,KAAK,oBACNoQ,EAAI3S,GACb,CAEA,SAAS2S,EAAI3S,GAEX,OAAa,OAATA,EACKkD,EAAIlD,GAIA,KAATA,GACFyC,EAAQrD,EAAQ8C,MAAM,oBACtBY,EAAO,EACAyI,EAAgBvL,IAGZ,KAATA,GACFZ,EAAQ8C,MAAM,SACd9C,EAAQ0C,QAAQ9B,GAChBZ,EAAQmD,KAAK,SACNoQ,GAGL5T,EAAmBiB,IACrBZ,EAAQ8C,MAAM,cACd9C,EAAQ0C,QAAQ9B,GAChBZ,EAAQmD,KAAK,cACNoQ,IAGTvT,EAAQ8C,MAAM,gBACPyN,EAAK3P,GACd,CAEA,SAAS2P,EAAK3P,GACZ,OACW,OAATA,GACS,KAATA,GACS,KAATA,GACAjB,EAAmBiB,IAEnBZ,EAAQmD,KAAK,gBACNoQ,EAAI3S,KAGbZ,EAAQ0C,QAAQ9B,GACT2P,EACT,CAEA,SAASpE,EAAgBvL,GAEvB,OAAa,KAATA,GACFZ,EAAQ0C,QAAQ9B,GAChB8C,IACOyI,GAGLzI,IAASsJ,GACXhN,EAAQmD,KAAK,oBACbnD,EAAQmD,KAAK,YACN1C,EAAGG,KAGZyC,EAAMgF,KAAO,eACNkI,EAAK3P,GACd,CACF,EAxJEgJ,QAIF,SAAyBxB,GACvB,IAEIxE,EACAd,EAHA0Q,EAAgBpL,EAAOvH,OAAS,EAChC4S,EAAiB,EAIrB,IACsC,eAAnCrL,EAAOqL,GAAgB,GAAGpL,MACU,UAAnCD,EAAOqL,GAAgB,GAAGpL,QACO,eAAlCD,EAAOoL,GAAe,GAAGnL,MACU,UAAlCD,EAAOoL,GAAe,GAAGnL,MAI3B,IAFAzE,EAAQ6P,IAEC7P,EAAQ4P,GACf,GAA8B,iBAA1BpL,EAAOxE,GAAO,GAAGyE,KAAyB,CAE5CD,EAAOoL,GAAe,GAAGnL,KAAOD,EAAOqL,GAAgB,GAAGpL,KACxD,kBACFoL,GAAkB,EAClBD,GAAiB,EACjB,KACF,CAIJ5P,EAAQ6P,EAAiB,EACzBD,IAEA,OAAS5P,GAAS4P,QACFvR,IAAVa,EACEc,IAAU4P,GAA2C,eAA1BpL,EAAOxE,GAAO,GAAGyE,OAC9CvF,EAAQc,GAGVA,IAAU4P,GACgB,eAA1BpL,EAAOxE,GAAO,GAAGyE,OAEjBD,EAAOtF,GAAO,GAAGuF,KAAO,eAEpBzE,IAAUd,EAAQ,IACpBsF,EAAOtF,GAAO,GAAGa,IAAMyE,EAAOxE,EAAQ,GAAG,GAAGD,IAC5CyE,EAAOE,OAAOxF,EAAQ,EAAGc,EAAQd,EAAQ,GACzC0Q,GAAiB5P,EAAQd,EAAQ,EACjCc,EAAQd,EAAQ,GAGlBA,OAAQb,GAIZ,OAAOmG,CACT,EAvDEpF,SAyDF,SAAkBpC,GAEhB,OACW,KAATA,GACgD,oBAAhDP,KAAK+H,OAAO/H,KAAK+H,OAAOvH,OAAS,GAAG,GAAGwH,IAE3C,GA0FA3C,EAAOjG,QAAUmS,C,kBC/JjB,IAAIpJ,EAAe5I,EAAQ,OACvBiG,EAA4BjG,EAAQ,OACpCD,EAAqBC,EAAQ,OA8HjC8F,EAAOjG,QA3HP,SACEO,EACAS,EACAqD,EACAuE,EACAqL,EACAC,EACAC,EACAtB,EACArE,GAEA,IAAIC,EAAQD,GAAOE,IACf0F,EAAU,EACd,OAEA,SAAejT,GACb,GAAa,KAATA,EAMF,OALAZ,EAAQ8C,MAAMuF,GACdrI,EAAQ8C,MAAM4Q,GACd1T,EAAQ8C,MAAM6Q,GACd3T,EAAQ0C,QAAQ9B,GAChBZ,EAAQmD,KAAKwQ,GACNG,EAGT,GAAItL,EAAa5H,IAAkB,KAATA,EACxB,OAAOkD,EAAIlD,GASb,OANAZ,EAAQ8C,MAAMuF,GACdrI,EAAQ8C,MAAM8Q,GACd5T,EAAQ8C,MAAMwP,GACdtS,EAAQ8C,MAAM,cAAe,CAC3BC,YAAa,WAERgR,EAAenT,EACxB,EAEA,SAASkT,EAA0BlT,GACjC,OAAa,KAATA,GACFZ,EAAQ8C,MAAM6Q,GACd3T,EAAQ0C,QAAQ9B,GAChBZ,EAAQmD,KAAKwQ,GACb3T,EAAQmD,KAAKuQ,GACb1T,EAAQmD,KAAKkF,GACN5H,IAGTT,EAAQ8C,MAAMwP,GACdtS,EAAQ8C,MAAM,cAAe,CAC3BC,YAAa,WAERiR,EAAoBpT,GAC7B,CAEA,SAASoT,EAAoBpT,GAC3B,OAAa,KAATA,GACFZ,EAAQmD,KAAK,eACbnD,EAAQmD,KAAKmP,GACNwB,EAA0BlT,IAGtB,OAATA,GAA0B,KAATA,GAAejB,EAAmBiB,GAC9CkD,EAAIlD,IAGbZ,EAAQ0C,QAAQ9B,GACA,KAATA,EAAcqT,EAA4BD,EACnD,CAEA,SAASC,EAA0BrT,GACjC,OAAa,KAATA,GAAwB,KAATA,GAAwB,KAATA,GAChCZ,EAAQ0C,QAAQ9B,GACToT,GAGFA,EAAoBpT,EAC7B,CAEA,SAASmT,EAAenT,GACtB,OAAa,KAATA,IACIiT,EAAU3F,EAAcpK,EAAIlD,IAClCZ,EAAQ0C,QAAQ9B,GACTmT,GAGI,KAATnT,EACGiT,KAQL7T,EAAQ0C,QAAQ9B,GACTmT,IARL/T,EAAQmD,KAAK,eACbnD,EAAQmD,KAAKmP,GACbtS,EAAQmD,KAAKyQ,GACb5T,EAAQmD,KAAKkF,GACN5H,EAAGG,IAOD,OAATA,GAAiBiF,EAA0BjF,GACzCiT,EAAgB/P,EAAIlD,IACxBZ,EAAQmD,KAAK,eACbnD,EAAQmD,KAAKmP,GACbtS,EAAQmD,KAAKyQ,GACb5T,EAAQmD,KAAKkF,GACN5H,EAAGG,IAGR4H,EAAa5H,GAAckD,EAAIlD,IACnCZ,EAAQ0C,QAAQ9B,GACA,KAATA,EAAcsT,EAAuBH,EAC9C,CAEA,SAASG,EAAqBtT,GAC5B,OAAa,KAATA,GAAwB,KAATA,GAAwB,KAATA,GAChCZ,EAAQ0C,QAAQ9B,GACTmT,GAGFA,EAAenT,EACxB,CACF,C,kBC9HArB,OAAOC,eAAeC,EAAS,aAA/BF,CAA8CG,OAAO,IAErD,IAAIqK,EAASnK,EAAQ,OACjBoM,EAAUpM,EAAQ,OAElByM,EAAO8H,EAAkB,QACzBjC,EAASiC,EAAkB,UAC3B/B,EAAW,CACbtI,WAAYsK,KAGd,SAASD,EAAkBE,GACzB,MAAO,CACLtU,SAMF,SAAwBC,GACtB,IAAII,EAAOC,KACP0D,EAAa1D,KAAKsC,OAAOoB,WAAWsQ,GACpChI,EAAOrM,EAAQe,QAAQgD,EAAY5B,EAAOmS,GAC9C,OAAOnS,EAEP,SAASA,EAAMvB,GACb,OAAO6I,EAAQ7I,GAAQyL,EAAKzL,GAAQ0T,EAAQ1T,EAC9C,CAEA,SAAS0T,EAAQ1T,GACf,GAAa,OAATA,EAOJ,OAFAZ,EAAQ8C,MAAM,QACd9C,EAAQ0C,QAAQ9B,GACT2P,EANLvQ,EAAQ0C,QAAQ9B,EAOpB,CAEA,SAAS2P,EAAK3P,GACZ,OAAI6I,EAAQ7I,IACVZ,EAAQmD,KAAK,QACNkJ,EAAKzL,KAGdZ,EAAQ0C,QAAQ9B,GACT2P,EACT,CAEA,SAAS9G,EAAQ7I,GACf,IAAIgN,EAAO7J,EAAWnD,GAClBgD,GAAS,EAEb,GAAa,OAAThD,EACF,OAAO,EAGT,GAAIgN,EACF,OAAShK,EAAQgK,EAAK/M,QACpB,IACG+M,EAAKhK,GAAOZ,UACb4K,EAAKhK,GAAOZ,SAASa,KAAKzD,EAAMA,EAAK4C,UAErC,OAAO,CAIf,CACF,EAvDE8G,WAAYsK,EACA,SAAVC,EAAmBE,OAAyBtS,GAuDlD,CAEA,SAASmS,EAAeI,GACtB,OAEA,SAAwBpM,EAAQuB,GAC9B,IACI7G,EADAc,GAAS,EAIb,OAASA,GAASwE,EAAOvH,aACToB,IAAVa,EACEsF,EAAOxE,IAAoC,SAA1BwE,EAAOxE,GAAO,GAAGyE,OACpCvF,EAAQc,EACRA,KAEQwE,EAAOxE,IAAoC,SAA1BwE,EAAOxE,GAAO,GAAGyE,OAExCzE,IAAUd,EAAQ,IACpBsF,EAAOtF,GAAO,GAAGa,IAAMyE,EAAOxE,EAAQ,GAAG,GAAGD,IAC5CyE,EAAOE,OAAOxF,EAAQ,EAAGc,EAAQd,EAAQ,GACzCc,EAAQd,EAAQ,GAGlBA,OAAQb,GAIZ,OAAOuS,EAAgBA,EAAcpM,EAAQuB,GAAWvB,CAC1D,CACF,CAQA,SAASmM,EAAuBnM,EAAQuB,GAWtC,IAVA,IACIjF,EACA6L,EACA2C,EACAtP,EACA6Q,EACA/Q,EACAgR,EACArR,EARAsR,GAAc,IAUTA,GAAcvM,EAAOvH,QAC5B,IACG8T,IAAevM,EAAOvH,QACU,eAA/BuH,EAAOuM,GAAY,GAAGtM,OACW,SAAnCD,EAAOuM,EAAa,GAAG,GAAGtM,KAC1B,CAQA,IAPAkI,EAAOnI,EAAOuM,EAAa,GAAG,GAE9B/Q,GADAc,EAASiF,EAAQlG,YAAY8M,IACd1P,OACf4T,GAAe,EACf/Q,EAAO,EACPgR,OAAOzS,EAEA2B,KAGL,GAAqB,kBAFrBsP,EAAQxO,EAAOd,IAEgB,CAG7B,IAFA6Q,EAAcvB,EAAMrS,OAEyB,KAAtCqS,EAAMjO,WAAWwP,EAAc,IACpC/Q,IACA+Q,IAGF,GAAIA,EAAa,MACjBA,GAAe,CACjB,MACK,IAAe,IAAXvB,EACPwB,GAAO,EACPhR,SACK,IAAe,IAAXwP,EACN,CAEHtP,IACA,KACF,CAGEF,IACFL,EAAQ,CACNgF,KACEsM,IAAevM,EAAOvH,QAAU6T,GAAQhR,EAAO,EAC3C,aACA,oBACNvB,MAAO,CACLyS,KAAMrE,EAAK5M,IAAIiR,KACfrQ,OAAQgM,EAAK5M,IAAIY,OAASb,EAC1BmI,OAAQ0E,EAAK5M,IAAIkI,OAASnI,EAC1B6K,OAAQgC,EAAKpO,MAAMoM,OAAS3K,EAC5BkI,aAAclI,EACV6Q,EACAlE,EAAKpO,MAAM2J,aAAe2I,GAEhC9Q,IAAKqI,EAAQuE,EAAK5M,MAEpB4M,EAAK5M,IAAMqI,EAAQ3I,EAAMlB,OAErBoO,EAAKpO,MAAM0J,SAAW0E,EAAK5M,IAAIkI,OACjC9B,EAAOwG,EAAMlN,IAEb+E,EAAOE,OACLqM,EACA,EACA,CAAC,QAAStR,EAAOsG,GACjB,CAAC,OAAQtG,EAAOsG,IAElBgL,GAAc,IAIlBA,GACF,CAGF,OAAOvM,CACT,CAEA3I,EAAQ2S,SAAWA,EACnB3S,EAAQyS,OAASA,EACjBzS,EAAQ4M,KAAOA,C,kBCtMf,IAEI1G,EAFa/F,EAAQ,MAER6F,CAAW,YAE5BC,EAAOjG,QAAUkG,C,kBCJjB,IAAIoE,EAASnK,EAAQ,OACjB+N,EAAgB/N,EAAQ,OACxBoM,EAAUpM,EAAQ,OAkGtB,SAASiV,EAAWzM,EAAQuM,GAkB1B,IAjBA,IASIG,EACA9R,EACAY,EACAmR,EACApR,EACAqR,EAdA3R,EAAQ+E,EAAOuM,GAAY,GAC3BhL,EAAUvB,EAAOuM,GAAY,GAC7B/P,EAAgB+P,EAAa,EAC7BM,EAAiB,GACjBC,EACF7R,EAAMJ,YAAc0G,EAAQhH,OAAOU,EAAMN,aAAaM,EAAMlB,OAC1DgT,EAAcD,EAAU9M,OACxBgN,EAAQ,GACRC,EAAO,CAAC,EASLhS,GAAO,CAEZ,KAAO+E,IAASxD,GAAe,KAAOvB,IAItC4R,EAAezS,KAAKoC,GAEfvB,EAAMJ,aACT6R,EAASnL,EAAQlG,YAAYJ,GAExBA,EAAMC,MACTwR,EAAOtS,KAAK,MAGVQ,GACFkS,EAAU3R,WAAWF,EAAMlB,OAGzBkB,EAAMiS,6BACRJ,EAAUK,oCAAqC,GAGjDL,EAAU1R,MAAMsR,GAEZzR,EAAMiS,6BACRJ,EAAUK,wCAAqCtT,IAInDe,EAAWK,EACXA,EAAQA,EAAMC,IAChB,CAMA,IAHAD,EAAQL,EACRY,EAAQuR,EAAYtU,OAEb+C,KAGyB,UAA1BuR,EAAYvR,GAAO,GACrBmR,GAAU,EAGVA,GACAI,EAAYvR,GAAO,GAAGyE,OAAS8M,EAAYvR,EAAQ,GAAG,GAAGyE,MACzD8M,EAAYvR,GAAO,GAAGzB,MAAMyS,OAASO,EAAYvR,GAAO,GAAGD,IAAIiR,OAE/DvE,EAAI8E,EAAY/P,MAAMxB,EAAQ,EAAGD,IAEjCN,EAAMJ,WAAaI,EAAMC,UAAOrB,EAChCoB,EAAQA,EAAML,SACdW,EAAMC,EAAQ,GAWlB,IANAsR,EAAU9M,OAAS/E,EAAMJ,WAAaI,EAAMC,UAAOrB,EAEnDoO,EAAI8E,EAAY/P,MAAM,EAAGzB,IACzBC,GAAS,EACToR,EAAS,IAEApR,EAAQwR,EAAMvU,QACrBwU,EAAKL,EAASI,EAAMxR,GAAO,IAAMoR,EAASI,EAAMxR,GAAO,GACvDoR,GAAUI,EAAMxR,GAAO,GAAKwR,EAAMxR,GAAO,GAAK,EAGhD,OAAOyR,EAEP,SAAShF,EAAIjL,GACX,IAAIjD,EAAQ8S,EAAeO,MAC3BJ,EAAMpG,QAAQ,CAAC7M,EAAOA,EAAQiD,EAAMvE,OAAS,IAC7C8M,EAAcvF,EAAQjG,EAAO,EAAGiD,EAClC,CACF,CAEAM,EAAOjG,QAhMP,SAAqB2I,GAWnB,IAVA,IAEIqN,EACAC,EACAC,EACAC,EACAhH,EACAiH,EACAC,EARAV,EAAQ,CAAC,EACTxR,GAAS,IASJA,EAAQwE,EAAOvH,QAAQ,CAC9B,KAAO+C,KAASwR,GACdxR,EAAQwR,EAAMxR,GAMhB,GAHA6R,EAAQrN,EAAOxE,GAIbA,GACkB,cAAlB6R,EAAM,GAAGpN,MACqB,mBAA9BD,EAAOxE,EAAQ,GAAG,GAAGyE,QAGrBsN,EAAa,IADbE,EAAYJ,EAAM,GAAGxS,WAAWmF,QAIPvH,QACW,oBAAlCgV,EAAUF,GAAY,GAAGtN,OAEzBsN,GAAc,GAIdA,EAAaE,EAAUhV,QACW,YAAlCgV,EAAUF,GAAY,GAAGtN,MAEzB,OAASsN,EAAaE,EAAUhV,QACQ,YAAlCgV,EAAUF,GAAY,GAAGtN,MAIS,cAAlCwN,EAAUF,GAAY,GAAGtN,OAC3BwN,EAAUF,GAAY,GAAGL,4BAA6B,EACtDK,KAMR,GAAiB,UAAbF,EAAM,GACJA,EAAM,GAAG1S,cACXgH,EAAOqL,EAAOP,EAAWzM,EAAQxE,IACjCA,EAAQwR,EAAMxR,GACdkS,GAAO,QAGN,GAAIL,EAAM,GAAG5E,YAAc4E,EAAM,GAAGM,yBAA0B,CAIjE,IAHAJ,EAAa/R,EACb8R,OAAYzT,EAEL0T,MAIoB,gBAHzBC,EAAaxN,EAAOuN,IAGP,GAAGtN,MACS,oBAAvBuN,EAAW,GAAGvN,OAEQ,UAAlBuN,EAAW,KACTF,IACFtN,EAAOsN,GAAW,GAAGrN,KAAO,mBAG9BuN,EAAW,GAAGvN,KAAO,aACrBqN,EAAYC,GAOdD,IAEFD,EAAM,GAAG9R,IAAMqI,EAAQ5D,EAAOsN,GAAW,GAAGvT,QAE5CyM,EAAaxG,EAAOhD,MAAMsQ,EAAW9R,IAC1BoL,QAAQyG,GACnB9H,EAAcvF,EAAQsN,EAAW9R,EAAQ8R,EAAY,EAAG9G,GAE5D,CACF,CAEA,OAAQkH,CACV,C,kBClGA,IAAInW,EAAqBC,EAAQ,OAC7BkG,EAAgBlG,EAAQ,OACxBC,EAAeD,EAAQ,OA2B3B8F,EAAOjG,QAzBP,SAA2BO,EAASS,GAClC,IAAIuV,EACJ,OAEA,SAAS7T,EAAMvB,GACb,GAAIjB,EAAmBiB,GAKrB,OAJAZ,EAAQ8C,MAAM,cACd9C,EAAQ0C,QAAQ9B,GAChBZ,EAAQmD,KAAK,cACb6S,GAAO,EACA7T,EAGT,GAAI2D,EAAclF,GAChB,OAAOf,EACLG,EACAmC,EACA6T,EAAO,aAAe,aAHjBnW,CAILe,GAGJ,OAAOH,EAAGG,EACZ,CACF,C,kBC3BA,IAAIqV,EAAcrW,EAAQ,OACtB+N,EAAgB/N,EAAQ,OACxBsW,EAAoBtW,EAAQ,OAC5BuW,EAAYvW,EAAQ,OACpBkK,EAAalK,EAAQ,OACrBoM,EAAUpM,EAAQ,OAElB6R,EAAY,CACdtL,KAAM,YACNpG,SA8IF,SAA2BC,EAASS,GAClC,IACI6F,EADA8J,EAAS8F,EAAkB7V,KAAK2C,UAEpC,OAEA,SAAepC,GAGb,OAFAZ,EAAQ8C,MAAM,qBACdwD,EAAS1F,EACF8I,EAAS9I,EAClB,EAEA,SAAS8I,EAAS9I,GAChB,IAAIyC,EACAoJ,EACAlG,EACA6P,EAEJ,OAAIxV,IAAS0F,GACXtG,EAAQ0C,QAAQ9B,GACT8I,IAGTrG,EAAQrD,EAAQmD,KAAK,qBAErBoD,IADAkG,EAAQyJ,EAAkBtV,KACE,IAAV6L,GAAe2D,EACjCgG,GAAShG,GAAsB,IAAXA,GAAgB3D,EACpCpJ,EAAMgT,MAAmB,KAAX/P,EAAgBC,EAAOA,IAAS6J,IAAWgG,GACzD/S,EAAMiT,OAAoB,KAAXhQ,EAAgB8P,EAAQA,IAAU3J,IAAUlG,GACpD9F,EAAGG,GACZ,CACF,EA3KEkJ,WAGF,SAA6B1B,EAAQuB,GACnC,IACIpD,EACAgQ,EACAlK,EACAiH,EACAnH,EACAqK,EACAC,EACA5K,EARAjI,GAAS,EAab,OAASA,EAAQwE,EAAOvH,QAEtB,GACuB,UAArBuH,EAAOxE,GAAO,IACY,sBAA1BwE,EAAOxE,GAAO,GAAGyE,MACjBD,EAAOxE,GAAO,GAAG0S,OAIjB,IAFA/P,EAAO3C,EAEA2C,KAEL,GACsB,SAApB6B,EAAO7B,GAAM,IACY,sBAAzB6B,EAAO7B,GAAM,GAAG8B,MAChBD,EAAO7B,GAAM,GAAG8P,OAChB1M,EAAQgG,eAAevH,EAAO7B,GAAM,IAAItB,WAAW,KACjD0E,EAAQgG,eAAevH,EAAOxE,GAAO,IAAIqB,WAAW,GACtD,CAKA,IACGmD,EAAO7B,GAAM,GAAG+P,QAAUlO,EAAOxE,GAAO,GAAGyS,SAC3CjO,EAAOxE,GAAO,GAAGD,IAAIkI,OAASzD,EAAOxE,GAAO,GAAGzB,MAAM0J,QAAU,MAE7DzD,EAAO7B,GAAM,GAAG5C,IAAIkI,OACnBzD,EAAO7B,GAAM,GAAGpE,MAAM0J,OACtBzD,EAAOxE,GAAO,GAAGD,IAAIkI,OACrBzD,EAAOxE,GAAO,GAAGzB,MAAM0J,QACzB,GAGF,SAQFyH,EAAkB,CAChBjL,MANFmO,EACEpO,EAAO7B,GAAM,GAAG5C,IAAIkI,OAASzD,EAAO7B,GAAM,GAAGpE,MAAM0J,OAAS,GAC5DzD,EAAOxE,GAAO,GAAGD,IAAIkI,OAASzD,EAAOxE,GAAO,GAAGzB,MAAM0J,OAAS,EAC1D,EACA,GAEQ,EAAI,iBAAmB,mBACnC1J,MAAOgU,EAAUnK,EAAQ5D,EAAO7B,GAAM,GAAG5C,MAAO6S,GAChD7S,IAAKqI,EAAQ5D,EAAO7B,GAAM,GAAG5C,MAE/BwI,EAAkB,CAChB9D,KAAMmO,EAAM,EAAI,iBAAmB,mBACnCrU,MAAO6J,EAAQ5D,EAAOxE,GAAO,GAAGzB,OAChCwB,IAAKwS,EAAUnK,EAAQ5D,EAAOxE,GAAO,GAAGzB,OAAQqU,IAElDnK,EAAO,CACLhE,KAAMmO,EAAM,EAAI,aAAe,eAC/BrU,MAAO6J,EAAQ5D,EAAO7B,GAAM,GAAG5C,KAC/BA,IAAKqI,EAAQ5D,EAAOxE,GAAO,GAAGzB,QAEhCoU,EAAQ,CACNlO,KAAMmO,EAAM,EAAI,SAAW,WAC3BrU,MAAO6J,EAAQsH,EAAgBnR,OAC/BwB,IAAKqI,EAAQG,EAAgBxI,MAE/ByE,EAAO7B,GAAM,GAAG5C,IAAMqI,EAAQsH,EAAgBnR,OAC9CiG,EAAOxE,GAAO,GAAGzB,MAAQ6J,EAAQG,EAAgBxI,KACjD8S,EAAa,GAETrO,EAAO7B,GAAM,GAAG5C,IAAIkI,OAASzD,EAAO7B,GAAM,GAAGpE,MAAM0J,SACrD4K,EAAaR,EAAYQ,EAAY,CACnC,CAAC,QAASrO,EAAO7B,GAAM,GAAIoD,GAC3B,CAAC,OAAQvB,EAAO7B,GAAM,GAAIoD,MAI9B8M,EAAaR,EAAYQ,EAAY,CACnC,CAAC,QAASF,EAAO5M,GACjB,CAAC,QAAS2J,EAAiB3J,GAC3B,CAAC,OAAQ2J,EAAiB3J,GAC1B,CAAC,QAAS0C,EAAM1C,KAGlB8M,EAAaR,EACXQ,EACA3M,EACEH,EAAQhH,OAAOoB,WAAWoO,WAAWjO,KACrCkE,EAAOhD,MAAMmB,EAAO,EAAG3C,GACvB+F,IAIJ8M,EAAaR,EAAYQ,EAAY,CACnC,CAAC,OAAQpK,EAAM1C,GACf,CAAC,QAASwC,EAAiBxC,GAC3B,CAAC,OAAQwC,EAAiBxC,GAC1B,CAAC,OAAQ4M,EAAO5M,KAGdvB,EAAOxE,GAAO,GAAGD,IAAIkI,OAASzD,EAAOxE,GAAO,GAAGzB,MAAM0J,QACvDA,EAAS,EACT4K,EAAaR,EAAYQ,EAAY,CACnC,CAAC,QAASrO,EAAOxE,GAAO,GAAI+F,GAC5B,CAAC,OAAQvB,EAAOxE,GAAO,GAAI+F,MAG7BkC,EAAS,EAGX8B,EAAcvF,EAAQ7B,EAAO,EAAG3C,EAAQ2C,EAAO,EAAGkQ,GAClD7S,EAAQ2C,EAAOkQ,EAAW5V,OAASgL,EAAS,EAC5C,KACF,CAKNjI,GAAS,EAET,OAASA,EAAQwE,EAAOvH,QACQ,sBAA1BuH,EAAOxE,GAAO,GAAGyE,OACnBD,EAAOxE,GAAO,GAAGyE,KAAO,QAI5B,OAAOD,CACT,GAkCA1C,EAAOjG,QAAUgS,C,kBCvLjB,IAAI9R,EAAqBC,EAAQ,OAC7BiG,EAA4BjG,EAAQ,OACpCkG,EAAgBlG,EAAQ,OACxB+N,EAAgB/N,EAAQ,OACxBC,EAAeD,EAAQ,OAEvBiS,EAAa,CACf1L,KAAM,aACNpG,SAqDF,SAA4BC,EAASS,EAAIqD,GACvC,IAAI1D,EAAOC,KACPqD,EAAO,EACX,OAEA,SAAe9C,GAGb,OAFAZ,EAAQ8C,MAAM,cACd9C,EAAQ8C,MAAM,sBACP4T,EAAgB9V,EACzB,EAEA,SAAS8V,EAAgB9V,GACvB,OAAa,KAATA,GAAe8C,IAAS,GAC1B1D,EAAQ0C,QAAQ9B,GACT8V,GAGI,OAAT9V,GAAiBiF,EAA0BjF,IAC7CZ,EAAQmD,KAAK,sBACN/C,EAAKmB,UAAYd,EAAGG,GAAQ+V,EAAa/V,IAG3CkD,EAAIlD,EACb,CAEA,SAAS+V,EAAa/V,GACpB,OAAa,KAATA,GACFZ,EAAQ8C,MAAM,sBACP4G,EAAS9I,IAGL,OAATA,GAAiBjB,EAAmBiB,IACtCZ,EAAQmD,KAAK,cACN1C,EAAGG,IAGRkF,EAAclF,GACTf,EAAaG,EAAS2W,EAAc,aAApC9W,CAAkDe,IAG3DZ,EAAQ8C,MAAM,kBACPyN,EAAK3P,GACd,CAEA,SAAS8I,EAAS9I,GAChB,OAAa,KAATA,GACFZ,EAAQ0C,QAAQ9B,GACT8I,IAGT1J,EAAQmD,KAAK,sBACNwT,EAAa/V,GACtB,CAEA,SAAS2P,EAAK3P,GACZ,OAAa,OAATA,GAA0B,KAATA,GAAeiF,EAA0BjF,IAC5DZ,EAAQmD,KAAK,kBACNwT,EAAa/V,KAGtBZ,EAAQ0C,QAAQ9B,GACT2P,EACT,CACF,EAnHE3G,QAGF,SAA2BxB,EAAQuB,GACjC,IAEIV,EACAoD,EAHAmE,EAAapI,EAAOvH,OAAS,EAC7B+V,EAAe,EAIkB,eAAjCxO,EAAOwO,GAAc,GAAGvO,OAC1BuO,GAAgB,GAIhBpG,EAAa,EAAIoG,GACc,eAA/BxO,EAAOoI,GAAY,GAAGnI,OAEtBmI,GAAc,GAIiB,uBAA/BpI,EAAOoI,GAAY,GAAGnI,OACrBuO,IAAiBpG,EAAa,GAC5BA,EAAa,EAAIoG,GACmB,eAAnCxO,EAAOoI,EAAa,GAAG,GAAGnI,QAE9BmI,GAAcoG,EAAe,IAAMpG,EAAa,EAAI,GAGlDA,EAAaoG,IACf3N,EAAU,CACRZ,KAAM,iBACNlG,MAAOiG,EAAOwO,GAAc,GAAGzU,MAC/BwB,IAAKyE,EAAOoI,GAAY,GAAG7M,KAE7B0I,EAAO,CACLhE,KAAM,YACNlG,MAAOiG,EAAOwO,GAAc,GAAGzU,MAC/BwB,IAAKyE,EAAOoI,GAAY,GAAG7M,IAC3BZ,YAAa,QAEf4K,EAAcvF,EAAQwO,EAAcpG,EAAaoG,EAAe,EAAG,CACjE,CAAC,QAAS3N,EAASU,GACnB,CAAC,QAAS0C,EAAM1C,GAChB,CAAC,OAAQ0C,EAAM1C,GACf,CAAC,OAAQV,EAASU,MAItB,OAAOvB,CACT,GAmEA1C,EAAOjG,QAAUoS,C,kBC9HjB,IAAIhM,EAA4BjG,EAAQ,OACpCqW,EAAcrW,EAAQ,OACtB+N,EAAgB/N,EAAQ,OACxB6S,EAAsB7S,EAAQ,OAC9BkK,EAAalK,EAAQ,OACrBoM,EAAUpM,EAAQ,OAClB8S,EAAqB9S,EAAQ,OAC7B+S,EAAe/S,EAAQ,OACvBiT,EAAejT,EAAQ,OACvBgT,EAAoBhT,EAAQ,OAE5BkS,EAAW,CACb3L,KAAM,WACNpG,SAiIF,SAA0BC,EAASS,EAAIqD,GACrC,IAEI+S,EACA5D,EAHA7S,EAAOC,KACPuD,EAAQxD,EAAKgI,OAAOvH,OAIxB,KAAO+C,KACL,IACkC,eAA/BxD,EAAKgI,OAAOxE,GAAO,GAAGyE,MACU,cAA/BjI,EAAKgI,OAAOxE,GAAO,GAAGyE,QACvBjI,EAAKgI,OAAOxE,GAAO,GAAGkT,UACvB,CACAD,EAAazW,EAAKgI,OAAOxE,GAAO,GAChC,KACF,CAGF,OAEA,SAAehD,GACb,IAAKiW,EACH,OAAO/S,EAAIlD,GAGb,OAAIiW,EAAWE,UAAkBC,EAASpW,IAC1CqS,EACE7S,EAAKuC,OAAOsQ,QAAQ9O,QAClBsO,EACErS,EAAKuP,eAAe,CAClBxN,MAAO0U,EAAWlT,IAClBA,IAAKvD,EAAKyC,WAGX,EACP7C,EAAQ8C,MAAM,YACd9C,EAAQ8C,MAAM,eACd9C,EAAQ0C,QAAQ9B,GAChBZ,EAAQmD,KAAK,eACbnD,EAAQmD,KAAK,YACN8T,EACT,EAEA,SAASA,EAAcrW,GAErB,OAAa,KAATA,EACKZ,EAAQe,QACbmW,EACAzW,EACAwS,EAAUxS,EAAKuW,EAHVhX,CAILY,GAGS,KAATA,EACKZ,EAAQe,QACboW,EACA1W,EACAwS,EACIjT,EAAQe,QAAQqW,EAA6B3W,EAAIuW,GACjDA,EALChX,CAMLY,GAGGqS,EAAUxS,EAAGG,GAAQoW,EAASpW,EACvC,CAEA,SAASoW,EAASpW,GAEhB,OADAiW,EAAWC,WAAY,EAChBhT,EAAIlD,EACb,CACF,EArMEuH,UAoCF,SAA2BC,EAAQuB,GACjC,IAEI4M,EACAhE,EACAlG,EACAhJ,EACAkD,EACA6P,EACAiB,EARAzT,EAAQwE,EAAOvH,OACfgL,EAAS,EASb,KAAOjI,KAGL,GAFAP,EAAQ+E,EAAOxE,GAAO,GAElB2C,EAAM,CAER,GACiB,SAAflD,EAAMgF,MACU,cAAfhF,EAAMgF,MAAwBhF,EAAM0T,UAErC,MAIuB,UAArB3O,EAAOxE,GAAO,IAAiC,cAAfP,EAAMgF,OACxChF,EAAM0T,WAAY,EAEtB,MAAO,GAAIX,GACT,GACuB,UAArBhO,EAAOxE,GAAO,KACE,eAAfP,EAAMgF,MAAwC,cAAfhF,EAAMgF,QACrChF,EAAMyT,YAEPvQ,EAAO3C,EAEY,cAAfP,EAAMgF,MAAsB,CAC9BwD,EAAS,EACT,KACF,MAEsB,aAAfxI,EAAMgF,OACf+N,EAAQxS,GAgDZ,OA5CA2S,EAAQ,CACNlO,KAA+B,cAAzBD,EAAO7B,GAAM,GAAG8B,KAAuB,OAAS,QACtDlG,MAAO6J,EAAQ5D,EAAO7B,GAAM,GAAGpE,OAC/BwB,IAAKqI,EAAQ5D,EAAOA,EAAOvH,OAAS,GAAG,GAAG8C,MAE5C4O,EAAQ,CACNlK,KAAM,QACNlG,MAAO6J,EAAQ5D,EAAO7B,GAAM,GAAGpE,OAC/BwB,IAAKqI,EAAQ5D,EAAOgO,GAAO,GAAGzS,MAEhC0I,EAAO,CACLhE,KAAM,YACNlG,MAAO6J,EAAQ5D,EAAO7B,EAAOsF,EAAS,GAAG,GAAGlI,KAC5CA,IAAKqI,EAAQ5D,EAAOgO,EAAQ,GAAG,GAAGjU,QAOpCkV,EAAQpB,EALRoB,EAAQ,CACN,CAAC,QAASd,EAAO5M,GACjB,CAAC,QAAS4I,EAAO5I,IAGQvB,EAAOhD,MAAMmB,EAAO,EAAGA,EAAOsF,EAAS,IAElEwL,EAAQpB,EAAYoB,EAAO,CAAC,CAAC,QAAShL,EAAM1C,KAE5C0N,EAAQpB,EACNoB,EACAvN,EACEH,EAAQhH,OAAOoB,WAAWoO,WAAWjO,KACrCkE,EAAOhD,MAAMmB,EAAOsF,EAAS,EAAGuK,EAAQ,GACxCzM,IAIJ0N,EAAQpB,EAAYoB,EAAO,CACzB,CAAC,OAAQhL,EAAM1C,GACfvB,EAAOgO,EAAQ,GACfhO,EAAOgO,EAAQ,GACf,CAAC,OAAQ7D,EAAO5I,KAGlB0N,EAAQpB,EAAYoB,EAAOjP,EAAOhD,MAAMgR,EAAQ,IAEhDiB,EAAQpB,EAAYoB,EAAO,CAAC,CAAC,OAAQd,EAAO5M,KAC5CgE,EAAcvF,EAAQ7B,EAAM6B,EAAOvH,OAAQwW,GACpCjP,CACT,EA7HE0B,WAYF,SAA4B1B,GAC1B,IACI/E,EADAO,GAAS,EAGb,OAASA,EAAQwE,EAAOvH,SACtBwC,EAAQ+E,EAAOxE,GAAO,IAGb0T,OACS,eAAfjU,EAAMgF,MACU,cAAfhF,EAAMgF,MACS,aAAfhF,EAAMgF,OAGRD,EAAOE,OAAO1E,EAAQ,EAAkB,eAAfP,EAAMgF,KAAwB,EAAI,GAC3DhF,EAAMgF,KAAO,OACbzE,KAIJ,OAAOwE,CACT,GA/BI8O,EAAoB,CACtBnX,SAmMF,SAA0BC,EAASS,EAAIqD,GACrC,OAEA,SAAelD,GAKb,OAJAZ,EAAQ8C,MAAM,YACd9C,EAAQ8C,MAAM,kBACd9C,EAAQ0C,QAAQ9B,GAChBZ,EAAQmD,KAAK,kBACNyP,EAAkB5S,EAASuG,EACpC,EAEA,SAASA,EAAK3F,GACZ,OAAa,KAATA,EACK+C,EAAI/C,GAGN8R,EACL1S,EACAuX,EACAzT,EACA,sBACA,6BACA,mCACA,yBACA,4BACA,EATK4O,CAUL9R,EACJ,CAEA,SAAS2W,EAAiB3W,GACxB,OAAOiF,EAA0BjF,GAC7BgS,EAAkB5S,EAASwX,EAA3B5E,CAAoChS,GACpC+C,EAAI/C,EACV,CAEA,SAAS4W,EAAQ5W,GACf,OAAa,KAATA,GAAwB,KAATA,GAAwB,KAATA,EACzBiS,EACL7S,EACA4S,EAAkB5S,EAAS2D,GAC3BG,EACA,gBACA,sBACA,sBANK+O,CAOLjS,GAGG+C,EAAI/C,EACb,CAEA,SAAS+C,EAAI/C,GACX,OAAa,KAATA,GACFZ,EAAQ8C,MAAM,kBACd9C,EAAQ0C,QAAQ9B,GAChBZ,EAAQmD,KAAK,kBACbnD,EAAQmD,KAAK,YACN1C,GAGFqD,EAAIlD,EACb,CACF,GA9PIuW,EAAyB,CAC3BpX,SA+PF,SAA+BC,EAASS,EAAIqD,GAC1C,IAAI1D,EAAOC,KACX,OAEA,SAAeO,GACb,OAAO+R,EAAa9O,KAClBzD,EACAJ,EACAyX,EACA3T,EACA,YACA,kBACA,kBAPK6O,CAQL/R,EACJ,EAEA,SAAS6W,EAAW7W,GAClB,OAAOR,EAAKuC,OAAOsQ,QAAQ9O,QACzBsO,EACErS,EAAKuP,eAAevP,EAAKgI,OAAOhI,EAAKgI,OAAOvH,OAAS,GAAG,IAAIuE,MAAM,GAAI,KAEtE,EACAtB,EAAIlD,GACJH,EAAGG,EACT,CACF,GAtRIwW,EAA8B,CAChCrX,SAuRF,SAAoCC,EAASS,EAAIqD,GAC/C,OAEA,SAAelD,GAKb,OAJAZ,EAAQ8C,MAAM,aACd9C,EAAQ8C,MAAM,mBACd9C,EAAQ0C,QAAQ9B,GAChBZ,EAAQmD,KAAK,mBACNoD,CACT,EAEA,SAASA,EAAK3F,GACZ,OAAa,KAATA,GACFZ,EAAQ8C,MAAM,mBACd9C,EAAQ0C,QAAQ9B,GAChBZ,EAAQmD,KAAK,mBACbnD,EAAQmD,KAAK,aACN1C,GAGFqD,EAAIlD,EACb,CACF,GAEA8E,EAAOjG,QAAUqS,C,kBCvUjB,IAAIvI,EAAc3J,EAAQ,OAU1B8F,EAAOjG,QARP,SAAqB2I,GACnB,MAAQmB,EAAYnB,KAIpB,OAAOA,CACT,C,kBCRA7I,OAAOC,eAAeC,EAAS,aAA/BF,CAA8CG,OAAO,IAErD,IAAIC,EAAqBC,EAAQ,OAC7BC,EAAeD,EAAQ,OAEvBG,EAEJ,SAA2BC,GACzB,IAKIgD,EALA4T,EAAe5W,EAAQe,QACzBV,KAAKsC,OAAOoB,WAAWkO,gBAOzB,SAAoCrR,GAClC,GAAa,OAATA,EAEF,YADAZ,EAAQ0C,QAAQ9B,GAOlB,OAHAZ,EAAQ8C,MAAM,cACd9C,EAAQ0C,QAAQ9B,GAChBZ,EAAQmD,KAAK,cACNtD,EAAaG,EAAS4W,EAAc,aAC7C,IAEA,SAA0BhW,GAExB,OADAZ,EAAQ8C,MAAM,aACP4U,EAAU9W,EACnB,IAjBA,OAAOgW,EAmBP,SAASc,EAAU9W,GACjB,IAAIyC,EAAQrD,EAAQ8C,MAAM,YAAa,CACrCC,YAAa,OACbC,SAAUA,IAQZ,OALIA,IACFA,EAASM,KAAOD,GAGlBL,EAAWK,EACJkN,EAAK3P,EACd,CAEA,SAAS2P,EAAK3P,GACZ,OAAa,OAATA,GACFZ,EAAQmD,KAAK,aACbnD,EAAQmD,KAAK,kBACbnD,EAAQ0C,QAAQ9B,IAIdjB,EAAmBiB,IACrBZ,EAAQ0C,QAAQ9B,GAChBZ,EAAQmD,KAAK,aACNuU,IAGT1X,EAAQ0C,QAAQ9B,GACT2P,EACT,CACF,EAEA9Q,EAAQM,SAAWA,C,kBClEnB,IAAIkJ,EAAUrJ,EAAQ,OAClBoE,EAAWpE,EAAQ,KACnBgD,EAAOhD,EAAQ,MACfyM,EAAOzM,EAAQ,OACf+X,EAAoB/X,EAAQ,OAC5BgY,EAAkBhY,EAAQ,OAC1BiQ,EAAWjQ,EAAQ,OACnBmE,EAAanE,EAAQ,OA0BzB8F,EAAOjG,QAxBP,SAAeoY,GACb,IACIlV,EAAS,CACXsQ,QAAS,GACTlP,WAAY4T,EACV,CAAC5T,GAAY+T,OAAOjI,GAJTgI,GAAW,CAAC,GAIevH,cAExCrH,QAAS8O,EAAO9O,GAChBjF,SAAU+T,EAAO/T,GACjBpB,KAAMmV,EAAOnV,GACbsP,OAAQ6F,EAAO1L,EAAK6F,QACpB7F,KAAM0L,EAAO1L,EAAKA,OAEpB,OAAO1J,EAEP,SAASoV,EAAOC,GACd,OAEA,SAAiBjJ,GACf,OAAO6I,EAAgBjV,EAAQqV,EAAajJ,EAC9C,CACF,CACF,C,kBC/BA,IAAIjJ,EAAgBlG,EAAQ,OACxBC,EAAeD,EAAQ,OAEvB8R,EAAa,CACfvL,KAAM,aACNpG,SAOF,SAAiCC,EAASS,EAAIqD,GAC5C,IAAI1D,EAAOC,KACX,OAEA,SAAeO,GACb,GAAa,KAATA,EAYF,OAXKR,EAAKU,eAAeyF,OACvBvG,EAAQ8C,MAAM,aAAc,CAC1B+N,YAAY,IAEdzQ,EAAKU,eAAeyF,MAAO,GAG7BvG,EAAQ8C,MAAM,oBACd9C,EAAQ8C,MAAM,oBACd9C,EAAQ0C,QAAQ9B,GAChBZ,EAAQmD,KAAK,oBACNsJ,EAGT,OAAO3I,EAAIlD,EACb,EAEA,SAAS6L,EAAM7L,GACb,OAAIkF,EAAclF,IAChBZ,EAAQ8C,MAAM,8BACd9C,EAAQ0C,QAAQ9B,GAChBZ,EAAQmD,KAAK,8BACbnD,EAAQmD,KAAK,oBACN1C,IAGTT,EAAQmD,KAAK,oBACN1C,EAAGG,GACZ,CACF,EAzCEI,aAAc,CACZjB,SA0CJ,SAAwCC,EAASS,EAAIqD,GACnD,OAAOjE,EACLG,EACAA,EAAQe,QAAQ2Q,EAAYjR,EAAIqD,GAChC,aACAzD,KAAKsC,OAAOoB,WAAWE,QAAQC,KAAKC,QAAQ,iBAAmB,OAC3DlC,EACA,EAER,GAjDEkB,KAmDF,SAAcnD,GACZA,EAAQmD,KAAK,aACf,GAEAuC,EAAOjG,QAAUiS,C,kBChEjB,IAEIK,EAAkB,CACpB5L,KAAM,kBACNpG,SAIF,SAAiCC,EAASS,EAAIqD,GAC5C,IAAI1D,EAAOC,KACX,OAEA,SAAeO,GAKb,OAJAZ,EAAQ8C,MAAM,cACd9C,EAAQ8C,MAAM,oBACd9C,EAAQ0C,QAAQ9B,GAChBZ,EAAQmD,KAAK,oBACNoD,CACT,EAEA,SAASA,EAAK3F,GACZ,OAAa,KAATA,GACFZ,EAAQ8C,MAAM,eACd9C,EAAQ0C,QAAQ9B,GAChBZ,EAAQmD,KAAK,eACbnD,EAAQmD,KAAK,cACNsJ,GAGF3I,EAAIlD,EACb,CAEA,SAAS6L,EAAM7L,GAEb,OAAgB,KAATA,GAEL,2BAA4BR,EAAKuC,OAAOoB,WAEtCD,EAAIlD,GACJH,EAAGG,EACT,CACF,EApCEkJ,WALalK,EAAQ,OAKAkK,YAsCvBpE,EAAOjG,QAAUsS,C,YCnCjBrM,EAAOjG,QAFkB,kvC,+OCGlB,MAAMwJ,EAAU,CACrBlJ,SAOF,SAA2BC,GACzB,MAAM4W,EAAe5W,EAAQe,QAC3BV,KAAKsC,OAAOoB,WAAWkO,gBASzB,SAAoCrR,GAClC,GAAa,OAATA,EAEF,YADAZ,EAAQ0C,QAAQ9B,GAMlB,OAHAZ,EAAQ8C,MAAM,cACd9C,EAAQ0C,QAAQ9B,GAChBZ,EAAQmD,KAAK,eACNtD,EAAAA,EAAAA,GAAaG,EAAS4W,EAAc,aAC7C,IAGA,SAA0BhW,GAExB,OADAZ,EAAQ8C,MAAM,aACP4U,EAAU9W,EACnB,IAnBA,IAAIoC,EACJ,OAAO4T,EAqBP,SAASc,EAAU9W,GACjB,MAAMyC,EAAQrD,EAAQ8C,MAAM,YAAa,CACvCC,YAAa,OACbC,aAMF,OAJIA,IACFA,EAASM,KAAOD,GAElBL,EAAWK,EACJkN,EAAK3P,EACd,CAGA,SAAS2P,EAAK3P,GACZ,OAAa,OAATA,GACFZ,EAAQmD,KAAK,aACbnD,EAAQmD,KAAK,kBACbnD,EAAQ0C,QAAQ9B,KAGdjB,EAAAA,EAAAA,IAAmBiB,IACrBZ,EAAQ0C,QAAQ9B,GAChBZ,EAAQmD,KAAK,aACNuU,IAIT1X,EAAQ0C,QAAQ9B,GACT2P,EACT,CACF,G,eC1DO,MAAMvM,EAAW,CACtBjE,SAYF,SAA4BC,GAC1B,MAAMI,EAAOC,KAEPC,EAAQ,GACd,IAEIJ,EAEAC,EAEA8X,EANA1X,EAAY,EAOhB,OAAO4B,EAGP,SAASA,EAAMvB,GAWb,GAAIL,EAAYD,EAAMO,OAAQ,CAC5B,MAAMqX,EAAO5X,EAAMC,GAEnB,OADAH,EAAKU,eAAiBoX,EAAK,GACpBlY,EAAQe,QACbmX,EAAK,GAAGlX,aACRoB,EACA+V,EAHKnY,CAILY,EACJ,CAGA,OAAOuX,EAAmBvX,EAC5B,CAGA,SAASwB,EAAiBxB,GAMxB,GALAL,IAKIH,EAAKU,eAAea,WAAY,CAClCvB,EAAKU,eAAea,gBAAaM,EAC7B/B,GACFkY,IAKF,MAAMC,EAAmBjY,EAAKgI,OAAOvH,OACrC,IAEI+K,EAFA0M,EAAkBD,EAKtB,KAAOC,KACL,GACsC,SAApClY,EAAKgI,OAAOkQ,GAAiB,IACY,cAAzClY,EAAKgI,OAAOkQ,GAAiB,GAAGjQ,KAChC,CACAuD,EAAQxL,EAAKgI,OAAOkQ,GAAiB,GAAG3U,IACxC,KACF,CAEFlB,EAAelC,GAGf,IAAIqD,EAAQyU,EACZ,KAAOzU,EAAQxD,EAAKgI,OAAOvH,QACzBT,EAAKgI,OAAOxE,GAAO,GAAGD,IAAMpE,OAAOwK,OAAO,CAAC,EAAG6B,GAC9ChI,IAaF,OATA0E,EAAAA,EAAAA,GACElI,EAAKgI,OACLkQ,EAAkB,EAClB,EACAlY,EAAKgI,OAAOhD,MAAMiT,IAIpBjY,EAAKgI,OAAOvH,OAAS+C,EACduU,EAAmBvX,EAC5B,CACA,OAAOuB,EAAMvB,EACf,CAGA,SAASuX,EAAmBvX,GAM1B,GAAIL,IAAcD,EAAMO,OAAQ,CAI9B,IAAKX,EACH,OAAOmC,EAAkBzB,GAM3B,GAAIV,EAAUiB,kBAAoBjB,EAAUiB,iBAAiBC,SAC3D,OAAOkB,EAAU1B,GAQnBR,EAAKmB,UAAYgX,QACfrY,EAAUiB,mBAAqBjB,EAAUsY,8BAE7C,CAIA,OADApY,EAAKU,eAAiB,CAAC,EAChBd,EAAQ8B,MACbL,EACAgX,EACAC,EAHK1Y,CAILY,EACJ,CAGA,SAAS6X,EAAqB7X,GAG5B,OAFIV,GAAWkY,IACf3V,EAAelC,GACR8B,EAAkBzB,EAC3B,CAGA,SAAS8X,EAAsB9X,GAG7B,OAFAR,EAAKuC,OAAOf,KAAKxB,EAAKyC,MAAM+R,MAAQrU,IAAcD,EAAMO,OACxDoX,EAAkB7X,EAAKyC,MAAMgJ,OACtBvJ,EAAU1B,EACnB,CAGA,SAASyB,EAAkBzB,GAGzB,OADAR,EAAKU,eAAiB,CAAC,EAChBd,EAAQe,QACbU,EACAc,EACAD,EAHKtC,CAILY,EACJ,CAGA,SAAS2B,EAAkB3B,GAIzB,OAHAL,IACAD,EAAMkC,KAAK,CAACpC,EAAKe,iBAAkBf,EAAKU,iBAEjCuB,EAAkBzB,EAC3B,CAGA,SAAS0B,EAAU1B,GACjB,OAAa,OAATA,GACEV,GAAWkY,IACf3V,EAAe,QACfzC,EAAQ0C,QAAQ9B,KAGlBV,EAAYA,GAAaE,EAAKuC,OAAOC,KAAKxC,EAAKyC,OAC/C7C,EAAQ8C,MAAM,YAAa,CACzBC,YAAa,OACbC,SAAU7C,EACV8C,WAAY/C,IAEPmB,EAAaT,GACtB,CAGA,SAASS,EAAaT,GACpB,OAAa,OAATA,GACF+X,EAAa3Y,EAAQmD,KAAK,cAAc,GACxCV,EAAe,QACfzC,EAAQ0C,QAAQ9B,KAGdjB,EAAAA,EAAAA,IAAmBiB,IACrBZ,EAAQ0C,QAAQ9B,GAChB+X,EAAa3Y,EAAQmD,KAAK,cAE1B5C,EAAY,EACZH,EAAKmB,eAAYU,EACVE,IAETnC,EAAQ0C,QAAQ9B,GACTS,EACT,CAOA,SAASsX,EAAatV,EAAOuV,GAC3B,MAAM9D,EAAS1U,EAAKqD,YAAYJ,GAyChC,GAxCIuV,GAAK9D,EAAOtS,KAAK,MACrBa,EAAML,SAAW7C,EACbA,IAAYA,EAAWmD,KAAOD,GAClClD,EAAakD,EACbnD,EAAUqD,WAAWF,EAAMlB,OAC3BjC,EAAUsD,MAAMsR,GAmCZ1U,EAAKuC,OAAOf,KAAKyB,EAAMlB,MAAMyS,MAAO,CACtC,IAAIhR,EAAQ1D,EAAUkI,OAAOvH,OAC7B,KAAO+C,KACL,GAEE1D,EAAUkI,OAAOxE,GAAO,GAAGzB,MAAM0J,OAASoM,KAExC/X,EAAUkI,OAAOxE,GAAO,GAAGD,KAE3BzD,EAAUkI,OAAOxE,GAAO,GAAGD,IAAIkI,OAASoM,GAI1C,OAMJ,MAAMI,EAAmBjY,EAAKgI,OAAOvH,OACrC,IAEImV,EAEApK,EAJA0M,EAAkBD,EAOtB,KAAOC,KACL,GACsC,SAApClY,EAAKgI,OAAOkQ,GAAiB,IACY,cAAzClY,EAAKgI,OAAOkQ,GAAiB,GAAGjQ,KAChC,CACA,GAAI2N,EAAM,CACRpK,EAAQxL,EAAKgI,OAAOkQ,GAAiB,GAAG3U,IACxC,KACF,CACAqS,GAAO,CACT,CAMF,IAJAvT,EAAelC,GAGfqD,EAAQyU,EACDzU,EAAQxD,EAAKgI,OAAOvH,QACzBT,EAAKgI,OAAOxE,GAAO,GAAGD,IAAMpE,OAAOwK,OAAO,CAAC,EAAG6B,GAC9ChI,KAIF0E,EAAAA,EAAAA,GACElI,EAAKgI,OACLkQ,EAAkB,EAClB,EACAlY,EAAKgI,OAAOhD,MAAMiT,IAIpBjY,EAAKgI,OAAOvH,OAAS+C,CACvB,CACF,CAMA,SAASnB,EAAeiB,GACtB,IAAIE,EAAQtD,EAAMO,OAGlB,KAAO+C,KAAUF,GAAM,CACrB,MAAMmV,EAAQvY,EAAMsD,GACpBxD,EAAKU,eAAiB+X,EAAM,GAC5BA,EAAM,GAAG1V,KAAKU,KAAKzD,EAAMJ,EAC3B,CACAM,EAAMO,OAAS6C,CACjB,CACA,SAAS0U,IACPlY,EAAUsD,MAAM,CAAC,OACjBrD,OAAa8B,EACb/B,OAAY+B,EACZ7B,EAAKU,eAAea,gBAAaM,CACnC,CACF,GArVMR,EAAqB,CACzB1B,SA0VF,SAA2BC,EAASS,EAAIqD,GAGtC,OAAOjE,EAAAA,EAAAA,GACLG,EACAA,EAAQe,QAAQV,KAAKsC,OAAOoB,WAAWC,SAAUvD,EAAIqD,GACrD,aACAzD,KAAKsC,OAAOoB,WAAWE,QAAQC,KAAK4U,SAAS,qBAAkB7W,EAAY,EAE/E,G,0BClXO,MAAMW,EAAO,CAClB7C,SAOF,SAAwBC,GACtB,MAAMI,EAAOC,KACP6I,EAAUlJ,EAAQe,QAEtBgY,EAAAA,GAoBF,SAAuBnY,GACrB,GAAa,OAATA,EAEF,YADAZ,EAAQ0C,QAAQ9B,GAOlB,OAJAZ,EAAQ8C,MAAM,mBACd9C,EAAQ0C,QAAQ9B,GAChBZ,EAAQmD,KAAK,mBACb/C,EAAKe,sBAAmBc,EACjBiH,CACT,GA3BElJ,EAAQe,QACNV,KAAKsC,OAAOoB,WAAWoF,YACvBC,GACAvJ,EAAAA,EAAAA,GACEG,EACAA,EAAQe,QACNV,KAAKsC,OAAOoB,WAAWnB,KACvBwG,EACApJ,EAAQe,QAAQkI,EAAAA,EAASG,IAE3B,gBAIN,OAAOF,EAgBP,SAASE,EAAexI,GACtB,GAAa,OAATA,EAQJ,OAJAZ,EAAQ8C,MAAM,cACd9C,EAAQ0C,QAAQ9B,GAChBZ,EAAQmD,KAAK,cACb/C,EAAKe,sBAAmBc,EACjBiH,EAPLlJ,EAAQ0C,QAAQ9B,EAQpB,CACF,GC1DO,MAAMwR,EAAW,CACtBtI,WAAYsK,KAEDlC,EAASiC,EAAkB,UAC3B9H,EAAO8H,EAAkB,QAMtC,SAASA,EAAkBE,GACzB,MAAO,CACLtU,SAUF,SAAwBC,GACtB,MAAMI,EAAOC,KACP0D,EAAa1D,KAAKsC,OAAOoB,WAAWsQ,GACpChI,EAAOrM,EAAQe,QAAQgD,EAAY5B,EAAOmS,GAChD,OAAOnS,EAGP,SAASA,EAAMvB,GACb,OAAO6I,EAAQ7I,GAAQyL,EAAKzL,GAAQ0T,EAAQ1T,EAC9C,CAGA,SAAS0T,EAAQ1T,GACf,GAAa,OAATA,EAMJ,OAFAZ,EAAQ8C,MAAM,QACd9C,EAAQ0C,QAAQ9B,GACT2P,EALLvQ,EAAQ0C,QAAQ9B,EAMpB,CAGA,SAAS2P,EAAK3P,GACZ,OAAI6I,EAAQ7I,IACVZ,EAAQmD,KAAK,QACNkJ,EAAKzL,KAIdZ,EAAQ0C,QAAQ9B,GACT2P,EACT,CAMA,SAAS9G,EAAQ7I,GACf,GAAa,OAATA,EACF,OAAO,EAET,MAAMgN,EAAO7J,EAAWnD,GACxB,IAAIgD,GAAS,EACb,GAAIgK,EAGF,OAAShK,EAAQgK,EAAK/M,QAAQ,CAC5B,MAAMqX,EAAOtK,EAAKhK,GAClB,IAAKsU,EAAKlV,UAAYkV,EAAKlV,SAASa,KAAKzD,EAAMA,EAAK4C,UAClD,OAAO,CAEX,CAEF,OAAO,CACT,CACF,EAjEE8G,WAAYsK,EACA,SAAVC,EAAmBE,OAAyBtS,GAiElD,CAMA,SAASmS,EAAeI,GACtB,OAGA,SAAwBpM,EAAQuB,GAC9B,IAEI7G,EAFAc,GAAS,EAMb,OAASA,GAASwE,EAAOvH,aACToB,IAAVa,EACEsF,EAAOxE,IAAoC,SAA1BwE,EAAOxE,GAAO,GAAGyE,OACpCvF,EAAQc,EACRA,KAEQwE,EAAOxE,IAAoC,SAA1BwE,EAAOxE,GAAO,GAAGyE,OAExCzE,IAAUd,EAAQ,IACpBsF,EAAOtF,GAAO,GAAGa,IAAMyE,EAAOxE,EAAQ,GAAG,GAAGD,IAC5CyE,EAAOE,OAAOxF,EAAQ,EAAGc,EAAQd,EAAQ,GACzCc,EAAQd,EAAQ,GAElBA,OAAQb,GAGZ,OAAOuS,EAAgBA,EAAcpM,EAAQuB,GAAWvB,CAC1D,CACF,CAaA,SAASmM,EAAuBnM,EAAQuB,GACtC,IAAIgL,EAAa,EAEjB,OAASA,GAAcvM,EAAOvH,QAC5B,IACG8T,IAAevM,EAAOvH,QACU,eAA/BuH,EAAOuM,GAAY,GAAGtM,OACW,SAAnCD,EAAOuM,EAAa,GAAG,GAAGtM,KAC1B,CACA,MAAMkI,EAAOnI,EAAOuM,EAAa,GAAG,GAC9BjQ,EAASiF,EAAQlG,YAAY8M,GACnC,IAIImE,EAJA9Q,EAAQc,EAAO7D,OACf4T,GAAe,EACf/Q,EAAO,EAGX,KAAOE,KAAS,CACd,MAAMsP,EAAQxO,EAAOd,GACrB,GAAqB,kBAAVsP,EAAoB,CAE7B,IADAuB,EAAcvB,EAAMrS,OACyB,KAAtCqS,EAAMjO,WAAWwP,EAAc,IACpC/Q,IACA+Q,IAEF,GAAIA,EAAa,MACjBA,GAAe,CACjB,MAEK,IAAe,IAAXvB,EACPwB,GAAO,EACPhR,SACK,IAAe,IAAXwP,EAEJ,CAELtP,IACA,KACF,CACF,CACA,GAAIF,EAAM,CACR,MAAML,EAAQ,CACZgF,KACEsM,IAAevM,EAAOvH,QAAU6T,GAAQhR,EAAO,EAC3C,aACA,oBACNvB,MAAO,CACLyS,KAAMrE,EAAK5M,IAAIiR,KACfrQ,OAAQgM,EAAK5M,IAAIY,OAASb,EAC1BmI,OAAQ0E,EAAK5M,IAAIkI,OAASnI,EAC1B6K,OAAQgC,EAAKpO,MAAMoM,OAAS3K,EAC5BkI,aAAclI,EACV6Q,EACAlE,EAAKpO,MAAM2J,aAAe2I,GAEhC9Q,IAAKpE,OAAOwK,OAAO,CAAC,EAAGwG,EAAK5M,MAE9B4M,EAAK5M,IAAMpE,OAAOwK,OAAO,CAAC,EAAG1G,EAAMlB,OAC/BoO,EAAKpO,MAAM0J,SAAW0E,EAAK5M,IAAIkI,OACjCtM,OAAOwK,OAAOwG,EAAMlN,IAEpB+E,EAAOE,OACLqM,EACA,EACA,CAAC,QAAStR,EAAOsG,GACjB,CAAC,OAAQtG,EAAOsG,IAElBgL,GAAc,EAElB,CACAA,GACF,CAEF,OAAOvM,CACT,C,cClKO,SAASwP,EAAgBjV,EAAQqW,EAAYjK,GAElD,IAAInD,EAAQrM,OAAOwK,OACjBgF,EACIxP,OAAOwK,OAAO,CAAC,EAAGgF,GAClB,CACE6F,KAAM,EACNrQ,OAAQ,EACRsH,OAAQ,GAEd,CACE0C,OAAQ,EACRzC,cAAe,IAInB,MAAMmN,EAAc,CAAC,EAEfC,EAAuB,GAE7B,IAAIxU,EAAS,GAETpE,EAAQ,GAER6Y,GAAW,EAOf,MAAMnZ,EAAU,CACd0C,QAkJF,SAAiB9B,IACXjB,EAAAA,EAAAA,IAAmBiB,IACrBgL,EAAMgJ,OACNhJ,EAAMrH,OAAS,EACfqH,EAAMC,SAAoB,IAAVjL,EAAc,EAAI,EAClCwY,MACmB,IAAVxY,IACTgL,EAAMrH,SACNqH,EAAMC,UAIJD,EAAME,aAAe,EACvBF,EAAM2C,UAEN3C,EAAME,eAKFF,EAAME,eAAiBpH,EAAOkH,EAAM2C,QAAQ1N,SAC9C+K,EAAME,cAAgB,EACtBF,EAAM2C,WAKV5E,EAAQ3G,SAAWpC,EAGnBuY,GAAW,CACb,EAhLErW,MAmLF,SAAeuF,EAAMgR,GAGnB,MAAMhW,EAAQgW,GAAU,CAAC,EAKzB,OAJAhW,EAAMgF,KAAOA,EACbhF,EAAMlB,MAAQU,IACd8G,EAAQvB,OAAO5F,KAAK,CAAC,QAASa,EAAOsG,IACrCrJ,EAAMkC,KAAKa,GACJA,CACT,EA3LEF,KA8LF,SAAckF,GACZ,MAAMhF,EAAQ/C,EAAMkV,MAGpB,OAFAnS,EAAMM,IAAMd,IACZ8G,EAAQvB,OAAO5F,KAAK,CAAC,OAAQa,EAAOsG,IAC7BtG,CACT,EAlMEtC,QAASuY,GAyMX,SAA+BC,EAAWlM,GACxCmM,EAAUD,EAAWlM,EAAK0B,KAC5B,IA1MEjN,MAAOwX,EAAiBG,GACxBlY,UAAW+X,EAAiBG,EAAmB,CAC7ClY,WAAW,KASToI,EAAU,CACd3G,SAAU,KACVpC,KAAM,KACNE,eAAgB,CAAC,EACjBsH,OAAQ,GACRzF,SACAc,cACAkM,eA6CF,SAAwBtM,EAAOqW,GAC7B,OAsYJ,SAAyBhV,EAAQgV,GAC/B,IAAI9V,GAAS,EAEb,MAAMwP,EAAS,GAEf,IAAID,EACJ,OAASvP,EAAQc,EAAO7D,QAAQ,CAC9B,MAAMqS,EAAQxO,EAAOd,GAErB,IAAIlE,EACJ,GAAqB,kBAAVwT,EACTxT,EAAQwT,OAER,OAAQA,GACN,KAAM,EACJxT,EAAQ,KACR,MAEF,KAAM,EACJA,EAAQ,KACR,MAEF,KAAM,EACJA,EAAQ,OACR,MAEF,KAAM,EACJA,EAAQga,EAAa,IAAM,KAC3B,MAEF,KAAM,EACJ,IAAKA,GAAcvG,EAAO,SAC1BzT,EAAQ,IACR,MAEF,QAEEA,EAAQ2J,OAAOtD,aAAamN,GAGlCC,GAAmB,IAAXD,EACRE,EAAO5Q,KAAK9C,EACd,CACA,OAAO0T,EAAOC,KAAK,GACrB,CAlbWsG,CAAgBlW,EAAYJ,GAAQqW,EAC7C,EA9CE7W,MACAU,WAkEF,SAAoB7D,GAClBuZ,EAAYvZ,EAAMkV,MAAQlV,EAAM6E,OAChC6U,GACF,EApEE5V,MAsBF,SAAe4B,GAKb,GAJAV,GAASlC,EAAAA,EAAAA,GAAKkC,EAAQU,GACtBwU,IAGkC,OAA9BlV,EAAOA,EAAO7D,OAAS,GACzB,MAAO,GAMT,OAJA2Y,EAAUR,EAAY,GAGtBrP,EAAQvB,QAAS0B,EAAAA,EAAAA,GAAWoP,EAAsBvP,EAAQvB,OAAQuB,GAC3DA,EAAQvB,MACjB,GA3BA,IAOIyR,EAPAC,EAAQd,EAAWjZ,SAAS8D,KAAK8F,EAAS3J,GAW9C,OAHIgZ,EAAWlP,YACboP,EAAqB1W,KAAKwW,GAErBrP,EA4BP,SAASlG,EAAYJ,GACnB,OA8VJ,SAAqBqB,EAAQrB,GAC3B,MAAMiL,EAAajL,EAAMlB,MAAMoM,OACzBC,EAAmBnL,EAAMlB,MAAM2J,aAC/B2C,EAAWpL,EAAMM,IAAI4K,OACrBG,EAAiBrL,EAAMM,IAAImI,aAEjC,IAAIuC,EACJ,GAAIC,IAAeG,EAEjBJ,EAAO,CAAC3J,EAAO4J,GAAYlJ,MAAMoJ,EAAkBE,QAC9C,CAEL,GADAL,EAAO3J,EAAOU,MAAMkJ,EAAYG,GAC5BD,GAAoB,EAAG,CACzB,MAAMuL,EAAO1L,EAAK,GACE,kBAAT0L,EACT1L,EAAK,GAAK0L,EAAK3U,MAAMoJ,GAErBH,EAAK2L,OAET,CACItL,EAAiB,GAEnBL,EAAK7L,KAAKkC,EAAO+J,GAAUrJ,MAAM,EAAGsJ,GAExC,CACA,OAAOL,CACT,CAxXW4L,CAAYvV,EAAQrB,EAC7B,CAGA,SAASR,IAEP,MAAM,KAAC+R,EAAI,OAAErQ,EAAM,OAAEsH,EAAM,OAAE0C,EAAM,aAAEzC,GAAgBF,EACrD,MAAO,CACLgJ,OACArQ,SACAsH,SACA0C,SACAzC,eAEJ,CAsBA,SAAS8N,IAEP,IAAIM,EACJ,KAAOtO,EAAM2C,OAAS7J,EAAO7D,QAAQ,CACnC,MAAMqS,EAAQxO,EAAOkH,EAAM2C,QAG3B,GAAqB,kBAAV2E,EAKT,IAJAgH,EAAatO,EAAM2C,OACf3C,EAAME,aAAe,IACvBF,EAAME,aAAe,GAGrBF,EAAM2C,SAAW2L,GACjBtO,EAAME,aAAeoH,EAAMrS,QAE3BsZ,EAAGjH,EAAMjO,WAAW2G,EAAME,oBAG5BqO,EAAGjH,EAEP,CACF,CAQA,SAASiH,EAAGvZ,GACVuY,OAAWlX,EACX4X,EAAejZ,EACfkZ,EAAQA,EAAMlZ,EAChB,CAsEA,SAAS6Y,EAAkBW,EAAG/M,GAC5BA,EAAKgN,SACP,CAQA,SAASf,EAAiBgB,EAAUjB,GAClC,OAWA,SAActV,EAAYkG,EAAasQ,GAErC,IAAIC,EAEAC,EAEAtZ,EAEAkM,EACJ,OAAOyB,MAAM4L,QAAQ3W,GACjB4W,EAAuB5W,GACvB,aAAcA,EAEd4W,EAAuB,CAAC5W,IAS5B,SAA+B6W,GAC7B,OAAOzY,EAGP,SAASA,EAAMvB,GACb,MAAMia,EAAe,OAATja,GAAiBga,EAAIha,GAC3BmP,EAAe,OAATnP,GAAiBga,EAAI1W,KAOjC,OAAOyW,EANM,IAGP7L,MAAM4L,QAAQG,GAAOA,EAAMA,EAAM,CAACA,GAAO,MACzC/L,MAAM4L,QAAQ3K,GAAOA,EAAMA,EAAM,CAACA,GAAO,IAExC4K,CAA6B/Z,EACtC,CACF,CAvBIka,CAAsB/W,GA+B1B,SAAS4W,EAAuB/M,GAG9B,OAFA4M,EAAmB5M,EACnB6M,EAAiB,EACG,IAAhB7M,EAAK/M,OACA0Z,EAEFQ,EAAgBnN,EAAK6M,GAC9B,CAQA,SAASM,EAAgBxB,GACvB,OAGA,SAAe3Y,GAKbyM,EAwER,WACE,MAAM2N,EAAanY,IACboY,EAAgBtR,EAAQ3G,SACxBkY,EAAwBvR,EAAQxI,iBAChCga,EAAmBxR,EAAQvB,OAAOvH,OAClCua,EAAatM,MAAMC,KAAKzO,GAC9B,MAAO,CACL+Z,UACAtL,KAAMoM,GAQR,SAASd,IACPzO,EAAQoP,EACRrR,EAAQ3G,SAAWiY,EACnBtR,EAAQxI,iBAAmB+Z,EAC3BvR,EAAQvB,OAAOvH,OAASsa,EACxB7a,EAAQ8a,EACRhC,GACF,CACF,CAhGeiC,GACPla,EAAmBoY,EACdA,EAAUrX,UACbyH,EAAQxI,iBAAmBoY,GAK7B,GACEA,EAAUpT,MACVwD,EAAQhH,OAAOoB,WAAWE,QAAQC,KAAK4U,SAASS,EAAUpT,MAE1D,OAAOrC,EAAIlD,GAEb,OAAO2Y,EAAUxZ,SAAS8D,KAIxBwV,EAAS9Z,OAAOwK,OAAOxK,OAAOwY,OAAOpO,GAAU0P,GAAU1P,EACzD3J,EACAS,EACAqD,EAPKyV,CAQL3Y,EACJ,CACF,CAGA,SAASH,EAAGG,GAGV,OAFAuY,GAAW,EACXmB,EAASnZ,EAAkBkM,GACpBpD,CACT,CAGA,SAASnG,EAAIlD,GAGX,OAFAuY,GAAW,EACX9L,EAAKgN,YACCI,EAAiBD,EAAiB3Z,OAC/Bka,EAAgBP,EAAiBC,IAEnCF,CACT,CACF,CACF,CAOA,SAASf,EAAUD,EAAWxK,GACxBwK,EAAUzP,aAAeoP,EAAqBJ,SAASS,IACzDL,EAAqB1W,KAAK+W,GAExBA,EAAU3P,UACZtB,EAAAA,EAAAA,GACEqB,EAAQvB,OACR2G,EACApF,EAAQvB,OAAOvH,OAASkO,EACxBwK,EAAU3P,QAAQD,EAAQvB,OAAOhD,MAAM2J,GAAOpF,IAG9C4P,EAAUpR,YACZwB,EAAQvB,OAASmR,EAAUpR,UAAUwB,EAAQvB,OAAQuB,GAEzD,CAuCA,SAASyP,IACHxN,EAAMgJ,QAAQqE,GAAerN,EAAMrH,OAAS,IAC9CqH,EAAMrH,OAAS0U,EAAYrN,EAAMgJ,MACjChJ,EAAMC,QAAUoN,EAAYrN,EAAMgJ,MAAQ,EAE9C,CACF,C,8NChdO,MAAM5Q,EAAW,CACtB,GAAM4J,EAAAA,EACN,GAAMA,EAAAA,EACN,GAAMA,EAAAA,EACN,GAAMA,EAAAA,EACN,GAAMA,EAAAA,EACN,GAAMA,EAAAA,EACN,GAAMA,EAAAA,EACN,GAAMA,EAAAA,EACN,GAAMA,EAAAA,EACN,GAAMA,EAAAA,EACN,GAAMA,EAAAA,EACN,GAAMA,EAAAA,EACN,GAAMA,EAAAA,EACN,GAAM8D,EAAAA,GAIKO,EAAiB,CAC5B,GAAM3F,EAAAA,GAIKnD,EAAc,CACzB,EAAE,GAAIwI,EAAAA,EACN,EAAE,GAAIA,EAAAA,EACN,GAAMA,EAAAA,GAIK/O,EAAO,CAClB,GAAMiP,EAAAA,EACN,GAAMrI,EAAAA,EACN,GAAM,CAACyC,EAAAA,EAAiBzC,EAAAA,GACxB,GAAMtD,EAAAA,EACN,GAAM+F,EAAAA,EACN,GAAMzC,EAAAA,EACN,GAAMqD,EAAAA,EACN,IAAOA,EAAAA,GAIIqF,EAAS,CACpB,GAAMzC,EAAAA,EACN,GAAM9C,EAAAA,GAIKN,EAAO,CAClB,EAAE,GAAI2F,EAAAA,EACN,EAAE,GAAIA,EAAAA,EACN,EAAE,GAAIA,EAAAA,EACN,GAAMD,EAAAA,EACN,GAAMtC,EAAAA,EACN,GAAMgC,EAAAA,EACN,GAAM,CAAChJ,EAAAA,EAAUuB,EAAAA,GACjB,GAAMwC,EAAAA,EACN,GAAM,CAACwB,EAAAA,EAAiBrB,EAAAA,GACxB,GAAMmF,EAAAA,EACN,GAAML,EAAAA,EACN,GAAMG,EAAAA,GAIKO,EAAa,CACxBjO,KAAM,CAACuN,EAAAA,EAAW6J,IAIPC,EAAmB,CAC9BrX,KAAM,CAAC,GAAI,KAIAD,EAAU,CACrBC,KAAM,ICpFD,SAASsX,EAAM3D,GACpB,MAAM4D,EAAW5D,GAAW,CAAC,EAMvBlV,EAAS,CACbsQ,QAAS,GACTrR,KAAM,CAAC,EACPmC,YANA4T,EAAAA,EAAAA,GAAkB,CAAC+D,KAAuBD,EAASnL,YAAc,KAOjErH,QAAS8O,EAAO9O,GAChBjF,SAAU+T,EAAO/T,GACjBpB,KAAMmV,EAAOnV,GACbsP,OAAQ6F,EAAO7F,GACf7F,KAAM0L,EAAO1L,IAEf,OAAO1J,EAKP,SAASoV,EAAO7O,GACd,OAEA,SAAiB6F,GACf,OAAO6I,EAAgBjV,EAAQuG,EAAS6F,EAC1C,CACF,CACF,C,kBC/CA,IAAIhJ,EAAenG,EAAQ,MAuB3B8F,EAAOjG,QArBP,SAAqBC,EAAOic,GAC1B,IAAI/a,EAAOgb,SAASlc,EAAOic,GAE3B,OAEE/a,EAAO,GACE,KAATA,GACCA,EAAO,IAAMA,EAAO,IACpBA,EAAO,KAAOA,EAAO,KACrBA,EAAO,OAASA,EAAO,OACvBA,EAAO,OAASA,EAAO,OACL,SAAX,MAAPA,IACkB,SAAX,MAAPA,IACDA,EAAO,QAEA,SAGFmF,EAAanF,EACtB,C,gPCVO,MAAMqI,EAAU,CACrBlJ,SASF,SAA2BC,GACzB,MAAM4W,EAAe5W,EAAQe,QAAQV,KAAKsC,OAAOoB,WAAWkO,gBAM5D,SAAoCrR,GAClC,GAAa,OAATA,EAEF,YADAZ,EAAQ0C,QAAQ9B,GAMlB,OAHAZ,EAAQ8C,MAAM,cACd9C,EAAQ0C,QAAQ9B,GAChBZ,EAAQmD,KAAK,eACNtD,EAAAA,EAAAA,GAAaG,EAAS4W,EAAc,aAC7C,IAGA,SAA0BhW,GAExB,OADAZ,EAAQ8C,MAAM,aACP4U,EAAU9W,EACnB,IAnBA,IAAIoC,EACJ,OAAO4T,EAqBP,SAASc,EAAU9W,GACjB,MAAMyC,EAAQrD,EAAQ8C,MAAM,YAAa,CACvCC,YAAa,OACbC,aAMF,OAJIA,IACFA,EAASM,KAAOD,GAElBL,EAAWK,EACJkN,EAAK3P,EACd,CAGA,SAAS2P,EAAK3P,GACZ,OAAa,OAATA,GACFZ,EAAQmD,KAAK,aACbnD,EAAQmD,KAAK,kBACbnD,EAAQ0C,QAAQ9B,KAGdjB,EAAAA,EAAAA,IAAmBiB,IACrBZ,EAAQ0C,QAAQ9B,GAChBZ,EAAQmD,KAAK,aACNuU,IAIT1X,EAAQ0C,QAAQ9B,GACT2P,EACT,CACF,G,yBCvDO,MAAMvM,EAAW,CACtBjE,SAcF,SAA4BC,GAC1B,MAAMI,EAAOC,KAEPC,EAAQ,GACd,IAEIJ,EAEAC,EAEA8X,EANA1X,EAAY,EAOhB,OAAO4B,EAGP,SAASA,EAAMvB,GAWb,GAAIL,EAAYD,EAAMO,OAAQ,CAC5B,MAAMqX,EAAO5X,EAAMC,GAEnB,OADAH,EAAKU,eAAiBoX,EAAK,GACpBlY,EAAQe,QAAQmX,EAAK,GAAGlX,aAAcoB,EAAkB+V,EAAxDnY,CAA4EY,EACrF,CAGA,OAAOuX,EAAmBvX,EAC5B,CAGA,SAASwB,EAAiBxB,GAMxB,GALAL,IAKIH,EAAKU,eAAea,WAAY,CAClCvB,EAAKU,eAAea,gBAAaM,EAC7B/B,GACFkY,IAKF,MAAMC,EAAmBjY,EAAKgI,OAAOvH,OACrC,IAEI+K,EAFA0M,EAAkBD,EAKtB,KAAOC,KACL,GAAwC,SAApClY,EAAKgI,OAAOkQ,GAAiB,IAA0D,cAAzClY,EAAKgI,OAAOkQ,GAAiB,GAAGjQ,KAAsB,CACtGuD,EAAQxL,EAAKgI,OAAOkQ,GAAiB,GAAG3U,IACxC,KACF,CAEFlB,EAAelC,GAGf,IAAIqD,EAAQyU,EACZ,KAAOzU,EAAQxD,EAAKgI,OAAOvH,QACzBT,EAAKgI,OAAOxE,GAAO,GAAGD,KAAGkY,EAAAA,EAAAA,GAAA,GACpBjQ,GAELhI,IAQF,OAJA0E,EAAAA,EAAAA,GAAOlI,EAAKgI,OAAQkQ,EAAkB,EAAG,EAAGlY,EAAKgI,OAAOhD,MAAMiT,IAG9DjY,EAAKgI,OAAOvH,OAAS+C,EACduU,EAAmBvX,EAC5B,CACA,OAAOuB,EAAMvB,EACf,CAGA,SAASuX,EAAmBvX,GAM1B,GAAIL,IAAcD,EAAMO,OAAQ,CAI9B,IAAKX,EACH,OAAOmC,EAAkBzB,GAM3B,GAAIV,EAAUiB,kBAAoBjB,EAAUiB,iBAAiBC,SAC3D,OAAOkB,EAAU1B,GAQnBR,EAAKmB,UAAYgX,QAAQrY,EAAUiB,mBAAqBjB,EAAUsY,8BACpE,CAIA,OADApY,EAAKU,eAAiB,CAAC,EAChBd,EAAQ8B,MAAML,EAAoBgX,EAAsBC,EAAxD1Y,CAA+EY,EACxF,CAGA,SAAS6X,EAAqB7X,GAG5B,OAFIV,GAAWkY,IACf3V,EAAelC,GACR8B,EAAkBzB,EAC3B,CAGA,SAAS8X,EAAsB9X,GAG7B,OAFAR,EAAKuC,OAAOf,KAAKxB,EAAKyC,MAAM+R,MAAQrU,IAAcD,EAAMO,OACxDoX,EAAkB7X,EAAKyC,MAAMgJ,OACtBvJ,EAAU1B,EACnB,CAGA,SAASyB,EAAkBzB,GAGzB,OADAR,EAAKU,eAAiB,CAAC,EAChBd,EAAQe,QAAQU,EAAoBc,EAAmBD,EAAvDtC,CAAkEY,EAC3E,CAGA,SAAS2B,EAAkB3B,GAIzB,OAHAL,IACAD,EAAMkC,KAAK,CAACpC,EAAKe,iBAAkBf,EAAKU,iBAEjCuB,EAAkBzB,EAC3B,CAGA,SAAS0B,EAAU1B,GACjB,OAAa,OAATA,GACEV,GAAWkY,IACf3V,EAAe,QACfzC,EAAQ0C,QAAQ9B,KAGlBV,EAAYA,GAAaE,EAAKuC,OAAOC,KAAKxC,EAAKyC,OAC/C7C,EAAQ8C,MAAM,YAAa,CACzBG,WAAY/C,EACZ6C,YAAa,OACbC,SAAU7C,IAELkB,EAAaT,GACtB,CAGA,SAASS,EAAaT,GACpB,OAAa,OAATA,GACF+X,EAAa3Y,EAAQmD,KAAK,cAAc,GACxCV,EAAe,QACfzC,EAAQ0C,QAAQ9B,KAGdjB,EAAAA,EAAAA,IAAmBiB,IACrBZ,EAAQ0C,QAAQ9B,GAChB+X,EAAa3Y,EAAQmD,KAAK,cAE1B5C,EAAY,EACZH,EAAKmB,eAAYU,EACVE,IAETnC,EAAQ0C,QAAQ9B,GACTS,EACT,CAUA,SAASsX,EAAatV,EAAOyY,GAC3B,MAAMhH,EAAS1U,EAAKqD,YAAYJ,GAyChC,GAxCIyY,GAAWhH,EAAOtS,KAAK,MAC3Ba,EAAML,SAAW7C,EACbA,IAAYA,EAAWmD,KAAOD,GAClClD,EAAakD,EACbnD,EAAUqD,WAAWF,EAAMlB,OAC3BjC,EAAUsD,MAAMsR,GAmCZ1U,EAAKuC,OAAOf,KAAKyB,EAAMlB,MAAMyS,MAAO,CACtC,IAAIhR,EAAQ1D,EAAUkI,OAAOvH,OAC7B,KAAO+C,KACL,GAEA1D,EAAUkI,OAAOxE,GAAO,GAAGzB,MAAM0J,OAASoM,KAEzC/X,EAAUkI,OAAOxE,GAAO,GAAGD,KAE5BzD,EAAUkI,OAAOxE,GAAO,GAAGD,IAAIkI,OAASoM,GAGtC,OAMJ,MAAMI,EAAmBjY,EAAKgI,OAAOvH,OACrC,IAEImV,EAEApK,EAJA0M,EAAkBD,EAOtB,KAAOC,KACL,GAAwC,SAApClY,EAAKgI,OAAOkQ,GAAiB,IAA0D,cAAzClY,EAAKgI,OAAOkQ,GAAiB,GAAGjQ,KAAsB,CACtG,GAAI2N,EAAM,CACRpK,EAAQxL,EAAKgI,OAAOkQ,GAAiB,GAAG3U,IACxC,KACF,CACAqS,GAAO,CACT,CAMF,IAJAvT,EAAelC,GAGfqD,EAAQyU,EACDzU,EAAQxD,EAAKgI,OAAOvH,QACzBT,EAAKgI,OAAOxE,GAAO,GAAGD,KAAGkY,EAAAA,EAAAA,GAAA,GACpBjQ,GAELhI,KAIF0E,EAAAA,EAAAA,GAAOlI,EAAKgI,OAAQkQ,EAAkB,EAAG,EAAGlY,EAAKgI,OAAOhD,MAAMiT,IAG9DjY,EAAKgI,OAAOvH,OAAS+C,CACvB,CACF,CAQA,SAASnB,EAAeiB,GACtB,IAAIE,EAAQtD,EAAMO,OAGlB,KAAO+C,KAAUF,GAAM,CACrB,MAAMmV,EAAQvY,EAAMsD,GACpBxD,EAAKU,eAAiB+X,EAAM,GAC5BA,EAAM,GAAG1V,KAAKU,KAAKzD,EAAMJ,EAC3B,CACAM,EAAMO,OAAS6C,CACjB,CACA,SAAS0U,IACPlY,EAAUsD,MAAM,CAAC,OACjBrD,OAAa8B,EACb/B,OAAY+B,EACZ7B,EAAKU,eAAea,gBAAaM,CACnC,CACF,GAjUMR,EAAqB,CACzB1B,SAwUF,SAA2BC,EAASS,EAAIqD,GAGtC,OAAOjE,EAAAA,EAAAA,GAAaG,EAASA,EAAQe,QAAQV,KAAKsC,OAAOoB,WAAWC,SAAUvD,EAAIqD,GAAM,aAAczD,KAAKsC,OAAOoB,WAAWE,QAAQC,KAAK4U,SAAS,qBAAkB7W,EAAY,EACnL,G,0BC5VO,MAAMW,EAAO,CAClB7C,SASF,SAAwBC,GACtB,MAAMI,EAAOC,KACP6I,EAAUlJ,EAAQe,QAExBgY,EAAAA,GAMA,SAAuBnY,GACrB,GAAa,OAATA,EAEF,YADAZ,EAAQ0C,QAAQ9B,GAOlB,OAJAZ,EAAQ8C,MAAM,mBACd9C,EAAQ0C,QAAQ9B,GAChBZ,EAAQmD,KAAK,mBACb/C,EAAKe,sBAAmBc,EACjBiH,CACT,GAdAlJ,EAAQe,QAAQV,KAAKsC,OAAOoB,WAAWoF,YAAaC,GAAgBvJ,EAAAA,EAAAA,GAAaG,EAASA,EAAQe,QAAQV,KAAKsC,OAAOoB,WAAWnB,KAAMwG,EAAgBpJ,EAAQe,QAAQkI,EAAAA,EAASG,IAAkB,gBAClM,OAAOF,EAgBP,SAASE,EAAexI,GACtB,GAAa,OAATA,EAQJ,OAJAZ,EAAQ8C,MAAM,cACd9C,EAAQ0C,QAAQ9B,GAChBZ,EAAQmD,KAAK,cACb/C,EAAKe,sBAAmBc,EACjBiH,EAPLlJ,EAAQ0C,QAAQ9B,EAQpB,CACF,GC9CO,MAAMwR,EAAW,CACtBtI,WAAYsK,KAEDlC,EAASiC,EAAkB,UAC3B9H,EAAO8H,EAAkB,QAQtC,SAASA,EAAkBE,GACzB,MAAO,CACLvK,WAAYsK,EAAyB,SAAVC,EAAmBE,OAAyBtS,GACvElC,SAQF,SAAwBC,GACtB,MAAMI,EAAOC,KACP0D,EAAa1D,KAAKsC,OAAOoB,WAAWsQ,GACpChI,EAAOrM,EAAQe,QAAQgD,EAAY5B,EAAOmS,GAChD,OAAOnS,EAGP,SAASA,EAAMvB,GACb,OAAO6I,EAAQ7I,GAAQyL,EAAKzL,GAAQ0T,EAAQ1T,EAC9C,CAGA,SAAS0T,EAAQ1T,GACf,GAAa,OAATA,EAMJ,OAFAZ,EAAQ8C,MAAM,QACd9C,EAAQ0C,QAAQ9B,GACT2P,EALLvQ,EAAQ0C,QAAQ9B,EAMpB,CAGA,SAAS2P,EAAK3P,GACZ,OAAI6I,EAAQ7I,IACVZ,EAAQmD,KAAK,QACNkJ,EAAKzL,KAIdZ,EAAQ0C,QAAQ9B,GACT2P,EACT,CAQA,SAAS9G,EAAQ7I,GACf,GAAa,OAATA,EACF,OAAO,EAET,MAAMgN,EAAO7J,EAAWnD,GACxB,IAAIgD,GAAS,EACb,GAAIgK,EAGF,OAAShK,EAAQgK,EAAK/M,QAAQ,CAC5B,MAAMqX,EAAOtK,EAAKhK,GAClB,IAAKsU,EAAKlV,UAAYkV,EAAKlV,SAASa,KAAKzD,EAAMA,EAAK4C,UAClD,OAAO,CAEX,CAEF,OAAO,CACT,CACF,EACF,CAQA,SAASoR,EAAeI,GACtB,OAGA,SAAwBpM,EAAQuB,GAC9B,IAEI7G,EAFAc,GAAS,EAMb,OAASA,GAASwE,EAAOvH,aACToB,IAAVa,EACEsF,EAAOxE,IAAoC,SAA1BwE,EAAOxE,GAAO,GAAGyE,OACpCvF,EAAQc,EACRA,KAEQwE,EAAOxE,IAAoC,SAA1BwE,EAAOxE,GAAO,GAAGyE,OAExCzE,IAAUd,EAAQ,IACpBsF,EAAOtF,GAAO,GAAGa,IAAMyE,EAAOxE,EAAQ,GAAG,GAAGD,IAC5CyE,EAAOE,OAAOxF,EAAQ,EAAGc,EAAQd,EAAQ,GACzCc,EAAQd,EAAQ,GAElBA,OAAQb,GAGZ,OAAOuS,EAAgBA,EAAcpM,EAAQuB,GAAWvB,CAC1D,CACF,CAaA,SAASmM,EAAuBnM,EAAQuB,GACtC,IAAIgL,EAAa,EAEjB,OAASA,GAAcvM,EAAOvH,QAC5B,IAAK8T,IAAevM,EAAOvH,QAAyC,eAA/BuH,EAAOuM,GAAY,GAAGtM,OAA6D,SAAnCD,EAAOuM,EAAa,GAAG,GAAGtM,KAAiB,CAC9H,MAAMkI,EAAOnI,EAAOuM,EAAa,GAAG,GAC9BjQ,EAASiF,EAAQlG,YAAY8M,GACnC,IAIImE,EAJA9Q,EAAQc,EAAO7D,OACf4T,GAAe,EACf/Q,EAAO,EAGX,KAAOE,KAAS,CACd,MAAMsP,EAAQxO,EAAOd,GACrB,GAAqB,kBAAVsP,EAAoB,CAE7B,IADAuB,EAAcvB,EAAMrS,OACyB,KAAtCqS,EAAMjO,WAAWwP,EAAc,IACpC/Q,IACA+Q,IAEF,GAAIA,EAAa,MACjBA,GAAe,CACjB,MAEK,IAAe,IAAXvB,EACPwB,GAAO,EACPhR,SACK,IAAe,IAAXwP,EAEJ,CAELtP,IACA,KACF,CACF,CAMA,GAHI+F,EAAQoS,0BAA4BpH,IAAevM,EAAOvH,SAC5D6C,EAAO,GAELA,EAAM,CACR,MAAML,EAAQ,CACZgF,KAAMsM,IAAevM,EAAOvH,QAAU6T,GAAQhR,EAAO,EAAI,aAAe,oBACxEvB,MAAO,CACL2J,aAAclI,EAAQ6Q,EAAclE,EAAKpO,MAAM2J,aAAe2I,EAC9DlG,OAAQgC,EAAKpO,MAAMoM,OAAS3K,EAC5BgR,KAAMrE,EAAK5M,IAAIiR,KACfrQ,OAAQgM,EAAK5M,IAAIY,OAASb,EAC1BmI,OAAQ0E,EAAK5M,IAAIkI,OAASnI,GAE5BC,KAAGkY,EAAAA,EAAAA,GAAA,GACEtL,EAAK5M,MAGZ4M,EAAK5M,KAAGkY,EAAAA,EAAAA,GAAA,GACHxY,EAAMlB,OAEPoO,EAAKpO,MAAM0J,SAAW0E,EAAK5M,IAAIkI,OACjCtM,OAAOwK,OAAOwG,EAAMlN,IAEpB+E,EAAOE,OAAOqM,EAAY,EAAG,CAAC,QAAStR,EAAOsG,GAAU,CAAC,OAAQtG,EAAOsG,IACxEgL,GAAc,EAElB,CACAA,GACF,CAEF,OAAOvM,CACT,C,6NC3MO,MAAMpE,EAAW,CACtB,GAAM4J,EAAAA,EACN,GAAMA,EAAAA,EACN,GAAMA,EAAAA,EACN,GAAMA,EAAAA,EACN,GAAMA,EAAAA,EACN,GAAMA,EAAAA,EACN,GAAMA,EAAAA,EACN,GAAMA,EAAAA,EACN,GAAMA,EAAAA,EACN,GAAMA,EAAAA,EACN,GAAMA,EAAAA,EACN,GAAMA,EAAAA,EACN,GAAMA,EAAAA,EACN,GAAM8D,EAAAA,GAIKO,EAAiB,CAC5B,GAAM3F,EAAAA,GAIKnD,EAAc,CACzB,EAAE,GAAIwI,EAAAA,EACN,EAAE,GAAIA,EAAAA,EACN,GAAMA,EAAAA,GAIK/O,EAAO,CAClB,GAAMiP,EAAAA,EACN,GAAMrI,EAAAA,EACN,GAAM,CAACyC,EAAAA,EAAiBzC,EAAAA,GACxB,GAAMtD,EAAAA,EACN,GAAM+F,EAAAA,EACN,GAAMzC,EAAAA,EACN,GAAMqD,EAAAA,EACN,IAAOA,EAAAA,GAIIqF,EAAS,CACpB,GAAMzC,EAAAA,EACN,GAAM9C,EAAAA,GAIKN,EAAO,CAClB,EAAE,GAAI2F,EAAAA,EACN,EAAE,GAAIA,EAAAA,EACN,EAAE,GAAIA,EAAAA,EACN,GAAMD,EAAAA,EACN,GAAMtC,EAAAA,EACN,GAAMgC,EAAAA,EACN,GAAM,CAAChJ,EAAAA,EAAUuB,EAAAA,GACjB,GAAMwC,EAAAA,EACN,GAAM,CAACwB,EAAAA,EAAiBrB,EAAAA,GACxB,GAAMmF,EAAAA,EACN,GAAML,EAAAA,EACN,GAAMG,EAAAA,GAIKO,EAAa,CACxBjO,KAAM,CAACuN,EAAAA,EAAW6J,IAIPC,EAAmB,CAC9BrX,KAAM,CAAC,GAAI,KAIAD,EAAU,CACrBC,KAAM,I,eCvBD,SAAS0T,EAAgBjV,EAAQqW,EAAYjK,GAElD,IAAInD,EAAQ,CACVE,cAAe,EACfyC,OAAQ,EACRqG,KAAM7F,GAAQA,EAAK6F,MAAQ,EAC3BrQ,OAAQwK,GAAQA,EAAKxK,QAAU,EAC/BsH,OAAQkD,GAAQA,EAAKlD,QAAU,GAGjC,MAAMoN,EAAc,CAAC,EAEfC,EAAuB,GAE7B,IAAIxU,EAAS,GAETpE,EAAQ,GAER6Y,GAAW,EAOf,MAAMnZ,EAAU,CACde,QAASuY,GAoNX,SAA+BC,EAAWlM,GACxCmM,EAAUD,EAAWlM,EAAK0B,KAC5B,IArNEjN,MAAOwX,EAAiBG,GACxB/W,QAsJF,SAAiB9B,IACXjB,EAAAA,EAAAA,IAAmBiB,IACrBgL,EAAMgJ,OACNhJ,EAAMrH,OAAS,EACfqH,EAAMC,SAAoB,IAAVjL,EAAc,EAAI,EAClCwY,MACmB,IAAVxY,IACTgL,EAAMrH,SACNqH,EAAMC,UAIJD,EAAME,aAAe,EACvBF,EAAM2C,UAEN3C,EAAME,eAGFF,EAAME,eAIVpH,EAAOkH,EAAM2C,QAAQ1N,SACnB+K,EAAME,cAAgB,EACtBF,EAAM2C,WAKV5E,EAAQ3G,SAAWpC,EAGnBuY,GAAW,CACb,EAtLErW,MAyLF,SAAeuF,EAAMgR,GAGnB,MAAMhW,EAAQgW,GAAU,CAAC,EAKzB,OAJAhW,EAAMgF,KAAOA,EACbhF,EAAMlB,MAAQU,IACd8G,EAAQvB,OAAO5F,KAAK,CAAC,QAASa,EAAOsG,IACrCrJ,EAAMkC,KAAKa,GACJA,CACT,EAjMEF,KAoMF,SAAckF,GACZ,MAAMhF,EAAQ/C,EAAMkV,MAGpB,OAFAnS,EAAMM,IAAMd,IACZ8G,EAAQvB,OAAO5F,KAAK,CAAC,OAAQa,EAAOsG,IAC7BtG,CACT,EAxME9B,UAAW+X,EAAiBG,EAAmB,CAC7ClY,WAAW,KASToI,EAAU,CACd/I,KAAM,KACNE,eAAgB,CAAC,EACjByC,WA8EF,SAAoB7D,GAClBuZ,EAAYvZ,EAAMkV,MAAQlV,EAAM6E,OAChC6U,GACF,EAhFEhR,OAAQ,GACRvF,MACAF,SACAK,SAAU,KACV2M,eA4CF,SAAwBtM,EAAOqW,GAC7B,OAuZJ,SAAyBhV,EAAQgV,GAC/B,IAAI9V,GAAS,EAEb,MAAMwP,EAAS,GAEf,IAAID,EACJ,OAASvP,EAAQc,EAAO7D,QAAQ,CAC9B,MAAMqS,EAAQxO,EAAOd,GAErB,IAAIlE,EACJ,GAAqB,kBAAVwT,EACTxT,EAAQwT,OACH,OAAQA,GACb,KAAM,EAEFxT,EAAQ,KACR,MAEJ,KAAM,EAEFA,EAAQ,KACR,MAEJ,KAAM,EAEFA,EAAQ,OACR,MAEJ,KAAM,EAEFA,EAAQga,EAAa,IAAM,KAC3B,MAEJ,KAAM,EAEF,IAAKA,GAAcvG,EAAO,SAC1BzT,EAAQ,IACR,MAEJ,QAGIA,EAAQ2J,OAAOtD,aAAamN,GAGlCC,GAAmB,IAAXD,EACRE,EAAO5Q,KAAK9C,EACd,CACA,OAAO0T,EAAOC,KAAK,GACrB,CAxcWsG,CAAgBlW,EAAYJ,GAAQqW,EAC7C,EA7CEjW,cACAD,MAsBF,SAAe4B,GAKb,GAJAV,GAASlC,EAAAA,EAAAA,GAAKkC,EAAQU,GACtBwU,IAGkC,OAA9BlV,EAAOA,EAAO7D,OAAS,GACzB,MAAO,GAMT,OAJA2Y,EAAUR,EAAY,GAGtBrP,EAAQvB,QAAS0B,EAAAA,EAAAA,GAAWoP,EAAsBvP,EAAQvB,OAAQuB,GAC3DA,EAAQvB,MACjB,GA3BA,IAOIyR,EAPAC,EAAQd,EAAWjZ,SAAS8D,KAAK8F,EAAS3J,GAW9C,OAHIgZ,EAAWlP,YACboP,EAAqB1W,KAAKwW,GAErBrP,EA4BP,SAASlG,EAAYJ,GACnB,OA2WJ,SAAqBqB,EAAQrB,GAC3B,MAAMiL,EAAajL,EAAMlB,MAAMoM,OACzBC,EAAmBnL,EAAMlB,MAAM2J,aAC/B2C,EAAWpL,EAAMM,IAAI4K,OACrBG,EAAiBrL,EAAMM,IAAImI,aAEjC,IAAIuC,EACJ,GAAIC,IAAeG,EAEjBJ,EAAO,CAAC3J,EAAO4J,GAAYlJ,MAAMoJ,EAAkBE,QAC9C,CAEL,GADAL,EAAO3J,EAAOU,MAAMkJ,EAAYG,GAC5BD,GAAoB,EAAG,CACzB,MAAMuL,EAAO1L,EAAK,GACE,kBAAT0L,EACT1L,EAAK,GAAK0L,EAAK3U,MAAMoJ,GAGrBH,EAAK2L,OAET,CACItL,EAAiB,GAEnBL,EAAK7L,KAAKkC,EAAO+J,GAAUrJ,MAAM,EAAGsJ,GAExC,CACA,OAAOL,CACT,CAtYW4L,CAAYvV,EAAQrB,EAC7B,CAGA,SAASR,IAEP,MAAM,aACJiJ,EAAY,OACZyC,EAAM,KACNqG,EAAI,OACJrQ,EAAM,OACNsH,GACED,EACJ,MAAO,CACLE,eACAyC,SACAqG,OACArQ,SACAsH,SAEJ,CAuBA,SAAS+N,IAEP,IAAIM,EACJ,KAAOtO,EAAM2C,OAAS7J,EAAO7D,QAAQ,CACnC,MAAMqS,EAAQxO,EAAOkH,EAAM2C,QAG3B,GAAqB,kBAAV2E,EAKT,IAJAgH,EAAatO,EAAM2C,OACf3C,EAAME,aAAe,IACvBF,EAAME,aAAe,GAEhBF,EAAM2C,SAAW2L,GAActO,EAAME,aAAeoH,EAAMrS,QAC/DsZ,EAAGjH,EAAMjO,WAAW2G,EAAME,oBAG5BqO,EAAGjH,EAEP,CACF,CAUA,SAASiH,EAAGvZ,GACVuY,OAAWlX,EACX4X,EAAejZ,EACfkZ,EAAQA,EAAMlZ,EAChB,CAwEA,SAAS6Y,EAAkBW,EAAG/M,GAC5BA,EAAKgN,SACP,CAUA,SAASf,EAAiBgB,EAAUjB,GAClC,OAeA,SAActV,EAAYkG,EAAasQ,GAErC,IAAIC,EAEAC,EAEAtZ,EAEAkM,EACJ,OAAOyB,MAAM4L,QAAQ3W,GACrB4W,EAAuB5W,GAAc,aAAcA,EAEnD4W,EAAuB,CAAC,IAUxB,SAA+BC,GAC7B,OAAOzY,EAGP,SAASA,EAAMvB,GACb,MAAMqP,EAAgB,OAATrP,GAAiBga,EAAIha,GAC5BmP,EAAe,OAATnP,GAAiBga,EAAI1W,KAKjC,OAAOyW,EAJM,IAGT7L,MAAM4L,QAAQzK,GAAQA,EAAOA,EAAO,CAACA,GAAQ,MAASnB,MAAM4L,QAAQ3K,GAAOA,EAAMA,EAAM,CAACA,GAAO,IAC5F4K,CAA6B/Z,EACtC,CACF,CAvBiEka,CAAsB/W,GAiCvF,SAAS4W,EAAuB/M,GAG9B,OAFA4M,EAAmB5M,EACnB6M,EAAiB,EACG,IAAhB7M,EAAK/M,OACA0Z,EAEFQ,EAAgBnN,EAAK6M,GAC9B,CAUA,SAASM,EAAgBxB,GACvB,OAGA,SAAe3Y,GAKbyM,EAgER,WACE,MAAM2N,EAAanY,IACboY,EAAgBtR,EAAQ3G,SACxBkY,EAAwBvR,EAAQxI,iBAChCga,EAAmBxR,EAAQvB,OAAOvH,OAClCua,EAAatM,MAAMC,KAAKzO,GAC9B,MAAO,CACLyO,KAAMoM,EACNd,WASF,SAASA,IACPzO,EAAQoP,EACRrR,EAAQ3G,SAAWiY,EACnBtR,EAAQxI,iBAAmB+Z,EAC3BvR,EAAQvB,OAAOvH,OAASsa,EACxB7a,EAAQ8a,EACRhC,GACF,CACF,CAzFeiC,GACPla,EAAmBoY,EACdA,EAAUrX,UACbyH,EAAQxI,iBAAmBoY,GAK7B,GAAIA,EAAUpT,MAAQwD,EAAQhH,OAAOoB,WAAWE,QAAQC,KAAK4U,SAASS,EAAUpT,MAC9E,OAAOrC,EAAIlD,GAEb,OAAO2Y,EAAUxZ,SAAS8D,KAI1BwV,EAAS9Z,OAAOwK,OAAOxK,OAAOwY,OAAOpO,GAAU0P,GAAU1P,EAAS3J,EAASS,EAAIqD,EAJxEyV,CAI6E3Y,EACtF,CACF,CAGA,SAASH,EAAGG,GAGV,OAFAuY,GAAW,EACXmB,EAASnZ,EAAkBkM,GACpBpD,CACT,CAGA,SAASnG,EAAIlD,GAGX,OAFAuY,GAAW,EACX9L,EAAKgN,YACCI,EAAiBD,EAAiB3Z,OAC/Bka,EAAgBP,EAAiBC,IAEnCF,CACT,CACF,CACF,CAUA,SAASf,EAAUD,EAAWxK,GACxBwK,EAAUzP,aAAeoP,EAAqBJ,SAASS,IACzDL,EAAqB1W,KAAK+W,GAExBA,EAAU3P,UACZtB,EAAAA,EAAAA,GAAOqB,EAAQvB,OAAQ2G,EAAMpF,EAAQvB,OAAOvH,OAASkO,EAAMwK,EAAU3P,QAAQD,EAAQvB,OAAOhD,MAAM2J,GAAOpF,IAEvG4P,EAAUpR,YACZwB,EAAQvB,OAASmR,EAAUpR,UAAUwB,EAAQvB,OAAQuB,GAEzD,CA0CA,SAASyP,IACHxN,EAAMgJ,QAAQqE,GAAerN,EAAMrH,OAAS,IAC9CqH,EAAMrH,OAAS0U,EAAYrN,EAAMgJ,MACjChJ,EAAMC,QAAUoN,EAAYrN,EAAMgJ,MAAQ,EAE9C,CACF,CCteO,SAAS4G,EAAM3D,GACpB,MAAM4D,EAAW5D,GAAW,CAAC,EAKvBlV,EAAS,CACboB,YAJF4T,EAAAA,EAAAA,GAAkB,CAAC+D,KAAuBD,EAASnL,YAAc,KAK/DrH,QAAS8O,EAAO9O,GAChBgK,QAAS,GACTjP,SAAU+T,EAAO/T,GACjBpB,KAAMmV,EAAOnV,GACbhB,KAAM,CAAC,EACPsQ,OAAQ6F,EAAO7F,GACf7F,KAAM0L,EAAO1L,IAEf,OAAO1J,EAQP,SAASoV,EAAO7O,GACd,OAEA,SAAiB6F,GACf,OAAO6I,EAAgBjV,EAAQuG,EAAS6F,EAC1C,CACF,CACF,C,kBCrDA,IAEII,EAFavP,EAAQ,MAER6F,CAAW,MAE5BC,EAAOjG,QAAU0P,C,kBCJjB,IAEIC,EAFaxP,EAAQ,MAEL6F,CAAW,cAE/BC,EAAOjG,QAAU2P,C,YCIjB1J,EAAOjG,QARP,SAAkBC,GAChB,OAAiB,OAAVA,QAA4BuC,IAAVvC,EACrB,GACA,WAAYA,EACZA,EACA,CAACA,EACP,C,kBCNA,IAAIG,EAAeD,EAAQ,OAEvBoS,EAAa,CACf7L,KAAM,aACNpG,SAGF,SAA4BC,EAASS,GACnC,OAEA,SAAeG,GAIb,OAHAZ,EAAQ8C,MAAM,cACd9C,EAAQ0C,QAAQ9B,GAChBZ,EAAQmD,KAAK,cACNtD,EAAaG,EAASS,EAAI,aACnC,CACF,GAEAiF,EAAOjG,QAAUuS,C,kBClBjB,IAAIrS,EAAqBC,EAAQ,OAC7B+N,EAAgB/N,EAAQ,OACxBgN,EAAahN,EAAQ,OACrBC,EAAeD,EAAQ,OAEvB+R,EAAe,CACjBxL,KAAM,eACNpG,SAmBF,SAA8BC,EAASS,EAAIqD,GACzC,OAAO9D,EAAQe,QAAQib,EAA0BtQ,EAAa5H,GAE9D,SAAS4H,EAAY9K,GACnB,OAAa,OAATA,EACKH,EAAGG,GAGRjB,EAAmBiB,GACdZ,EAAQe,QAAQib,EAA0BtQ,EAAajL,EAAvDT,CAA2DY,IAGpEZ,EAAQ8C,MAAM,iBACPmG,EAAQrI,GACjB,CAEA,SAASqI,EAAQrI,GACf,OAAa,OAATA,GAAiBjB,EAAmBiB,IACtCZ,EAAQmD,KAAK,iBACNuI,EAAY9K,KAGrBZ,EAAQ0C,QAAQ9B,GACTqI,EACT,CACF,EA3CEW,QAOF,SAA6BxB,EAAQuB,GACnC,IAAI/I,EAAO,CACTyH,KAAM,eACNlG,MAAOiG,EAAO,GAAG,GAAGjG,MACpBwB,IAAKyE,EAAOA,EAAOvH,OAAS,GAAG,GAAG8C,KAIpC,OAFAgK,EAAcvF,EAAQ,EAAG,EAAG,CAAC,CAAC,QAASxH,EAAM+I,KAC7CgE,EAAcvF,EAAQA,EAAOvH,OAAQ,EAAG,CAAC,CAAC,OAAQD,EAAM+I,KACjDvB,CACT,GAdI4T,EAA2B,CAC7Bjc,SA0CF,SAAiCC,EAASS,EAAIqD,GAC5C,IAAI1D,EAAOC,KACX,OAAOR,EAAaG,GAEpB,SAAS0L,EAAY9K,GACnB,GAAIjB,EAAmBiB,GAIrB,OAHAZ,EAAQ8C,MAAM,cACd9C,EAAQ0C,QAAQ9B,GAChBZ,EAAQmD,KAAK,cACNtD,EAAaG,EAAS0L,EAAa,aAAc,GAG1D,OAAOkB,EAAWxM,EAAKgI,OAAQ,cAAgB,EAAItE,EAAIlD,GAAQH,EAAGG,EACpE,GAX0C,aAAc,EAY1D,EAvDEsB,SAAS,GAyDXwD,EAAOjG,QAAUkS,C,kBCrEjB,IAAI5H,EAASnK,EAAQ,OACjBD,EAAqBC,EAAQ,OAC7BqW,EAAcrW,EAAQ,OACtB+N,EAAgB/N,EAAQ,OACxBiQ,EAAWjQ,EAAQ,OACnBkK,EAAalK,EAAQ,OACrB+Z,EAAkB/Z,EAAQ,OAC1BoM,EAAUpM,EAAQ,OAClBqa,EAAcra,EAAQ,OAiT1B8F,EAAOjG,QAxSP,SAAyBkD,EAAQqW,EAAYjK,GAC3C,IAAInD,EAAQmD,EACR/C,EAAQ+C,GACR,CACE6F,KAAM,EACNrQ,OAAQ,EACRsH,OAAQ,GAEVoN,EAAc,CAAC,EACfC,EAAuB,GACvBxU,EAAS,GACTpE,EAAQ,GAERN,EAAU,CACZ0C,QAyGF,SAAiB9B,GACXjB,EAAmBiB,IACrBgL,EAAMgJ,OACNhJ,EAAMrH,OAAS,EACfqH,EAAMC,SAAoB,IAAVjL,EAAc,EAAI,EAClCwY,MACmB,IAAVxY,IACTgL,EAAMrH,SACNqH,EAAMC,UAGJD,EAAME,aAAe,EACvBF,EAAM2C,UAEN3C,EAAME,eAEFF,EAAME,eAAiBpH,EAAOkH,EAAM2C,QAAQ1N,SAC9C+K,EAAME,cAAgB,EACtBF,EAAM2C,WAIV5E,EAAQ3G,SAAWpC,CACrB,EA/HEkC,MAiIF,SAAeuF,EAAMgR,GACnB,IAAIhW,EAAQgW,GAAU,CAAC,EAKvB,OAJAhW,EAAMgF,KAAOA,EACbhF,EAAMlB,MAAQU,IACd8G,EAAQvB,OAAO5F,KAAK,CAAC,QAASa,EAAOsG,IACrCrJ,EAAMkC,KAAKa,GACJA,CACT,EAvIEF,KAyIF,SAAckF,GACZ,IAAIhF,EAAQ/C,EAAMkV,MAGlB,OAFAnS,EAAMM,IAAMd,IACZ8G,EAAQvB,OAAO5F,KAAK,CAAC,OAAQa,EAAOsG,IAC7BtG,CACT,EA7IEtC,QAASuY,GA+IX,SAA+BC,EAAWlM,GACxCmM,EAAUD,EAAWlM,EAAK0B,KAC5B,IAhJEjN,MAAOwX,EAAiBG,GACxBlY,UAAW+X,EAAiBG,EAAmB,CAC7ClY,WAAW,IAEbK,KAAM0X,EAAiBG,EAAmB,CACxC7X,MAAM,KAIN+H,EAAU,CACZ3G,SAAU,KACVoF,OAAQ,GACRzF,OAAQA,EACRc,YAAaA,EACbkM,eAgCF,SAAwBtM,GACtB,OAAOsW,EAAgBlW,EAAYJ,GACrC,EAjCER,IAAKA,EACLU,WA0CF,SAAc7D,GACZuZ,EAAYvZ,EAAMkV,MAAQlV,EAAM6E,OAChC6U,GACF,EA5CE5V,MAaF,SAAe4B,GAIb,GAHAV,EAASuR,EAAYvR,EAAQU,GAC7BwU,IAEkC,OAA9BlV,EAAOA,EAAO7D,OAAS,GACzB,MAAO,GAMT,OAHA2Y,EAAUR,EAAY,GAEtBrP,EAAQvB,OAAS0B,EAAWoP,EAAsBvP,EAAQvB,OAAQuB,GAC3DA,EAAQvB,MACjB,GAtBI0R,EAAQd,EAAWjZ,SAAS8D,KAAK8F,EAAS3J,GAQ9C,OANIgZ,EAAWlP,YACboP,EAAqB1W,KAAKwW,GAG5BpN,EAAM2C,OAAS,EACf3C,EAAME,cAAgB,EACfnC,EAsBP,SAASlG,EAAYJ,GACnB,OAAO4W,EAAYvV,EAAQrB,EAC7B,CAEA,SAASR,IACP,OAAOmJ,EAAQJ,EACjB,CAeA,SAASgO,IAIP,IAHA,IAAIM,EACAhH,EAEGtH,EAAM2C,OAAS7J,EAAO7D,QAG3B,GAAqB,kBAFrBqS,EAAQxO,EAAOkH,EAAM2C,SASnB,IANA2L,EAAatO,EAAM2C,OAEf3C,EAAME,aAAe,IACvBF,EAAME,aAAe,GAIrBF,EAAM2C,SAAW2L,GACjBtO,EAAME,aAAeoH,EAAMrS,QAE3BsZ,EAAGjH,EAAMjO,WAAW2G,EAAME,oBAG5BqO,EAAGjH,EAGT,CAEA,SAASiH,EAAGvZ,GACVkZ,EAAQA,EAAMlZ,EAChB,CA+CA,SAAS6Y,EAAkBF,EAAWlM,GACpCA,EAAKgN,SACP,CAEA,SAASf,EAAiBgB,EAAUjB,GAClC,OAGA,SAActV,EAAYkG,EAAasQ,GACrC,IAAIC,EACAC,EACAtZ,EACAkM,EACJ,OAAOtJ,EAAWhE,UAAY,WAAYgE,EACtC4W,EAAuB9K,EAAS9L,IAGpC,SAA+BnD,GAC7B,GAAIA,KAAQmD,GAAc,QAAQA,EAChC,OAAO4W,EACL5W,EAAWG,KAEP2L,EAAS9L,EAAWnD,IAAOkX,OAAOjI,EAAS9L,EAAWG,OACtDH,EAAWnD,GAJV+Z,CAKL/Z,GAGJ,OAAO2Z,EAAW3Z,EACpB,EAEA,SAAS+Z,EAAuB/M,GAG9B,OAFA4M,EAAmB5M,EAEZmN,EAAgBnN,EADvB6M,EAAiB,GAEnB,CAEA,SAASM,EAAgBxB,GACvB,OAEA,SAAe3Y,GAKbyM,EA2DR,WACE,IAAI2N,EAAanY,IACboY,EAAgBtR,EAAQ3G,SACxBkY,EAAwBvR,EAAQxI,iBAChCga,EAAmBxR,EAAQvB,OAAOvH,OAClCua,EAAatM,MAAMC,KAAKzO,GAC5B,MAAO,CACL+Z,QAASA,EACTtL,KAAMoM,GAGR,SAASd,IACPzO,EAAQoP,EACRrR,EAAQ3G,SAAWiY,EACnBtR,EAAQxI,iBAAmB+Z,EAC3BvR,EAAQvB,OAAOvH,OAASsa,EACxB7a,EAAQ8a,EACRhC,GACF,CACF,CA9EeiC,GACPla,EAAmBoY,EAEdA,EAAUrX,UACbyH,EAAQxI,iBAAmBoY,GAG7B,GACEA,EAAUpT,MACVwD,EAAQhH,OAAOoB,WAAWE,QAAQC,KAAKC,QAAQoV,EAAUpT,OAAS,EAElE,OAAOrC,IAGT,OAAOyV,EAAUxZ,SAAS8D,KACxBwV,EAAStP,EAAO,CAAC,EAAGJ,EAAS0P,GAAU1P,EACvC3J,EACAS,EACAqD,EAJKyV,CAKL3Y,EACJ,CACF,CAEA,SAASH,EAAGG,GAEV,OADA0Z,EAASnZ,EAAkBkM,GACpBpD,CACT,CAEA,SAASnG,EAAIlD,GAGX,OAFAyM,EAAKgN,YAECI,EAAiBD,EAAiB3Z,OAC/Bka,EAAgBP,EAAiBC,IAGnCF,CACT,CACF,CACF,CAEA,SAASf,EAAUD,EAAWxK,GACxBwK,EAAUzP,YAAcoP,EAAqB/U,QAAQoV,GAAa,GACpEL,EAAqB1W,KAAK+W,GAGxBA,EAAU3P,SACZ+D,EACEhE,EAAQvB,OACR2G,EACApF,EAAQvB,OAAOvH,OAASkO,EACxBwK,EAAU3P,QAAQD,EAAQvB,OAAOhD,MAAM2J,GAAOpF,IAI9C4P,EAAUpR,YACZwB,EAAQvB,OAASmR,EAAUpR,UAAUwB,EAAQvB,OAAQuB,GAEzD,CAuBA,SAASyP,IACHxN,EAAMgJ,QAAQqE,GAAerN,EAAMrH,OAAS,IAC9CqH,EAAMrH,OAAS0U,EAAYrN,EAAMgJ,MACjChJ,EAAMC,QAAUoN,EAAYrN,EAAMgJ,MAAQ,EAE9C,CACF,C,kBCvTA,IAAIjV,EAAqBC,EAAQ,OAC7BC,EAAeD,EAAQ,OAuE3B8F,EAAOjG,QArEP,SAAsBO,EAASS,EAAIqD,EAAKuE,EAAMgK,EAAYC,GACxD,IAAIhM,EACJ,OAEA,SAAe1F,GAMb,OALAZ,EAAQ8C,MAAMuF,GACdrI,EAAQ8C,MAAMuP,GACdrS,EAAQ0C,QAAQ9B,GAChBZ,EAAQmD,KAAKkP,GACb/L,EAAkB,KAAT1F,EAAc,GAAKA,EACrBqb,CACT,EAEA,SAASA,EAAkBrb,GACzB,OAAIA,IAAS0F,GACXtG,EAAQ8C,MAAMuP,GACdrS,EAAQ0C,QAAQ9B,GAChBZ,EAAQmD,KAAKkP,GACbrS,EAAQmD,KAAKkF,GACN5H,IAGTT,EAAQ8C,MAAMwP,GACP4J,EAAatb,GACtB,CAEA,SAASsb,EAAatb,GACpB,OAAIA,IAAS0F,GACXtG,EAAQmD,KAAKmP,GACN2J,EAAkB3V,IAGd,OAAT1F,EACKkD,EAAIlD,GAGTjB,EAAmBiB,IACrBZ,EAAQ8C,MAAM,cACd9C,EAAQ0C,QAAQ9B,GAChBZ,EAAQmD,KAAK,cACNtD,EAAaG,EAASkc,EAAc,gBAG7Clc,EAAQ8C,MAAM,cAAe,CAC3BC,YAAa,WAERoZ,EAAMvb,GACf,CAEA,SAASub,EAAMvb,GACb,OAAIA,IAAS0F,GAAmB,OAAT1F,GAAiBjB,EAAmBiB,IACzDZ,EAAQmD,KAAK,eACN+Y,EAAatb,KAGtBZ,EAAQ0C,QAAQ9B,GACA,KAATA,EAAcwb,EAAcD,EACrC,CAEA,SAASC,EAAYxb,GACnB,OAAIA,IAAS0F,GAAmB,KAAT1F,GACrBZ,EAAQ0C,QAAQ9B,GACTub,GAGFA,EAAMvb,EACf,CACF,C,YClEA8E,EAAOjG,QAJP,SAAmCmB,GACjC,OAAOA,EAAO,GAAc,KAATA,CACrB,C,YCaA8E,EAAOjG,QAfP,SAA6BC,GAC3B,OACEA,EACG2c,QAAQ,cAAe,KACvBA,QAAQ,SAAU,IAMlBvV,cACAwV,aAEP,C","sources":["../../node_modules/remark/node_modules/micromark/dist/initialize/document.js","../../node_modules/remark-parse/node_modules/micromark/lib/preprocess.js","../../node_modules/remark/node_modules/micromark/dist/character/unicode-punctuation.js","../../node_modules/remark/node_modules/micromark/dist/tokenize/html-flow.js","../../node_modules/remark/node_modules/micromark/dist/tokenize/autolink.js","../../node_modules/remark/node_modules/micromark/dist/initialize/flow.js","../../node_modules/remark/node_modules/micromark/dist/constant/from-char-code.js","../../node_modules/remark/node_modules/micromark/dist/constant/html-raw-names.js","../../node_modules/remark-parse/node_modules/micromark/lib/postprocess.js","../../node_modules/remark/node_modules/micromark/dist/character/markdown-space.js","../../node_modules/remark/node_modules/micromark/dist/tokenize/thematic-break.js","../../node_modules/remark/node_modules/micromark/dist/util/resolve-all.js","../../node_modules/remark/node_modules/micromark/dist/constant/assign.js","../../node_modules/remark/node_modules/micromark/dist/tokenize/html-text.js","../../node_modules/remark/node_modules/micromark/dist/util/classify-character.js","../../node_modules/remark/node_modules/micromark/dist/util/move-point.js","../../node_modules/remark/node_modules/micromark/dist/util/shallow.js","../../node_modules/remark/node_modules/micromark/dist/tokenize/setext-underline.js","../../node_modules/remark/node_modules/micromark/dist/tokenize/label-start-link.js","../../node_modules/remark/node_modules/micromark/dist/tokenize/character-escape.js","../../node_modules/remark/node_modules/micromark/dist/constant/splice.js","../../node_modules/remark/node_modules/micromark/dist/tokenize/code-fenced.js","../../node_modules/remark/node_modules/micromark/dist/tokenize/partial-blank-line.js","../../node_modules/remark/node_modules/micromark/dist/util/regex-check.js","../../node_modules/remark/node_modules/micromark/dist/constant/html-block-names.js","../../node_modules/remark/node_modules/micromark/dist/character/markdown-line-ending.js","../../node_modules/remark/node_modules/micromark/dist/util/chunked-push.js","../../node_modules/remark/node_modules/micromark/dist/util/prefix-size.js","../../node_modules/remark/node_modules/micromark/dist/tokenize/hard-break-escape.js","../../node_modules/remark/node_modules/micromark/dist/tokenize/factory-space.js","../../node_modules/micromark/lib/preprocess.js","../../node_modules/remark/node_modules/micromark/dist/util/slice-chunks.js","../../node_modules/remark/node_modules/micromark/dist/util/chunked-splice.js","../../node_modules/remark/node_modules/micromark/dist/character/ascii-control.js","../../node_modules/remark/node_modules/micromark/dist/tokenize/character-reference.js","../../node_modules/remark/node_modules/micromark/dist/util/combine-extensions.js","../../node_modules/remark/node_modules/micromark/dist/tokenize/content.js","../../node_modules/remark/node_modules/micromark/dist/util/size-chunks.js","../../node_modules/remark/node_modules/micromark/dist/constant/has-own-property.js","../../node_modules/remark/node_modules/micromark/dist/character/ascii-atext.js","../../node_modules/remark/node_modules/micromark/dist/tokenize/list.js","../../node_modules/remark/node_modules/micromark/dist/constructs.js","../../node_modules/remark/node_modules/micromark/dist/tokenize/factory-label.js","../../node_modules/remark/node_modules/micromark/dist/character/ascii-punctuation.js","../../node_modules/remark/node_modules/micromark/dist/character/ascii-alphanumeric.js","../../node_modules/micromark/lib/postprocess.js","../../node_modules/remark/node_modules/micromark/dist/tokenize/definition.js","../../node_modules/remark/node_modules/micromark/dist/character/unicode-whitespace.js","../../node_modules/remark/node_modules/micromark/dist/util/serialize-chunks.js","../../node_modules/remark/node_modules/micromark/dist/preprocess.js","../../node_modules/remark/node_modules/micromark/dist/tokenize/code-text.js","../../node_modules/remark/node_modules/micromark/dist/tokenize/factory-destination.js","../../node_modules/remark/node_modules/micromark/dist/initialize/text.js","../../node_modules/remark/node_modules/micromark/dist/character/ascii-alpha.js","../../node_modules/remark/node_modules/micromark/dist/util/subtokenize.js","../../node_modules/remark/node_modules/micromark/dist/tokenize/factory-whitespace.js","../../node_modules/remark/node_modules/micromark/dist/tokenize/attention.js","../../node_modules/remark/node_modules/micromark/dist/tokenize/heading-atx.js","../../node_modules/remark/node_modules/micromark/dist/tokenize/label-end.js","../../node_modules/remark/node_modules/micromark/dist/postprocess.js","../../node_modules/remark/node_modules/micromark/dist/initialize/content.js","../../node_modules/remark/node_modules/micromark/dist/parse.js","../../node_modules/remark/node_modules/micromark/dist/tokenize/block-quote.js","../../node_modules/remark/node_modules/micromark/dist/tokenize/label-start-image.js","../../node_modules/remark/node_modules/micromark/dist/constant/unicode-punctuation-regex.js","../../node_modules/micromark/lib/initialize/content.js","../../node_modules/micromark/lib/initialize/document.js","../../node_modules/micromark/lib/initialize/flow.js","../../node_modules/micromark/lib/initialize/text.js","../../node_modules/micromark/lib/create-tokenizer.js","../../node_modules/micromark/lib/constructs.js","../../node_modules/micromark/lib/parse.js","../../node_modules/remark/node_modules/micromark/dist/util/safe-from-int.js","../../node_modules/remark-parse/node_modules/micromark/lib/initialize/content.js","../../node_modules/remark-parse/node_modules/micromark/lib/initialize/document.js","../../node_modules/remark-parse/node_modules/micromark/lib/initialize/flow.js","../../node_modules/remark-parse/node_modules/micromark/lib/initialize/text.js","../../node_modules/remark-parse/node_modules/micromark/lib/constructs.js","../../node_modules/remark-parse/node_modules/micromark/lib/create-tokenizer.js","../../node_modules/remark-parse/node_modules/micromark/lib/parse.js","../../node_modules/remark/node_modules/micromark/dist/character/ascii-digit.js","../../node_modules/remark/node_modules/micromark/dist/character/ascii-hex-digit.js","../../node_modules/remark/node_modules/micromark/dist/util/miniflat.js","../../node_modules/remark/node_modules/micromark/dist/tokenize/line-ending.js","../../node_modules/remark/node_modules/micromark/dist/tokenize/code-indented.js","../../node_modules/remark/node_modules/micromark/dist/util/create-tokenizer.js","../../node_modules/remark/node_modules/micromark/dist/tokenize/factory-title.js","../../node_modules/remark/node_modules/micromark/dist/character/markdown-line-ending-or-space.js","../../node_modules/remark/node_modules/micromark/dist/util/normalize-identifier.js"],"sourcesContent":["'use strict'\n\nObject.defineProperty(exports, '__esModule', {value: true})\n\nvar markdownLineEnding = require('../character/markdown-line-ending.js')\nvar factorySpace = require('../tokenize/factory-space.js')\nvar partialBlankLine = require('../tokenize/partial-blank-line.js')\n\nvar tokenize = initializeDocument\nvar containerConstruct = {\n  tokenize: tokenizeContainer\n}\nvar lazyFlowConstruct = {\n  tokenize: tokenizeLazyFlow\n}\n\nfunction initializeDocument(effects) {\n  var self = this\n  var stack = []\n  var continued = 0\n  var inspectConstruct = {\n    tokenize: tokenizeInspect,\n    partial: true\n  }\n  var inspectResult\n  var childFlow\n  var childToken\n  return start\n\n  function start(code) {\n    if (continued < stack.length) {\n      self.containerState = stack[continued][1]\n      return effects.attempt(\n        stack[continued][0].continuation,\n        documentContinue,\n        documentContinued\n      )(code)\n    }\n\n    return documentContinued(code)\n  }\n\n  function documentContinue(code) {\n    continued++\n    return start(code)\n  }\n\n  function documentContinued(code) {\n    // If were in a concrete construct (such as when expecting another line of\n    // HTML, or we resulted in lazy content), we can immediately start flow.\n    if (inspectResult && inspectResult.flowContinue) {\n      return flowStart(code)\n    }\n\n    self.interrupt =\n      childFlow &&\n      childFlow.currentConstruct &&\n      childFlow.currentConstruct.interruptible\n    self.containerState = {}\n    return effects.attempt(\n      containerConstruct,\n      containerContinue,\n      flowStart\n    )(code)\n  }\n\n  function containerContinue(code) {\n    stack.push([self.currentConstruct, self.containerState])\n    self.containerState = undefined\n    return documentContinued(code)\n  }\n\n  function flowStart(code) {\n    if (code === null) {\n      exitContainers(0, true)\n      effects.consume(code)\n      return\n    }\n\n    childFlow = childFlow || self.parser.flow(self.now())\n    effects.enter('chunkFlow', {\n      contentType: 'flow',\n      previous: childToken,\n      _tokenizer: childFlow\n    })\n    return flowContinue(code)\n  }\n\n  function flowContinue(code) {\n    if (code === null) {\n      continueFlow(effects.exit('chunkFlow'))\n      return flowStart(code)\n    }\n\n    if (markdownLineEnding(code)) {\n      effects.consume(code)\n      continueFlow(effects.exit('chunkFlow'))\n      return effects.check(inspectConstruct, documentAfterPeek)\n    }\n\n    effects.consume(code)\n    return flowContinue\n  }\n\n  function documentAfterPeek(code) {\n    exitContainers(\n      inspectResult.continued,\n      inspectResult && inspectResult.flowEnd\n    )\n    continued = 0\n    return start(code)\n  }\n\n  function continueFlow(token) {\n    if (childToken) childToken.next = token\n    childToken = token\n    childFlow.lazy = inspectResult && inspectResult.lazy\n    childFlow.defineSkip(token.start)\n    childFlow.write(self.sliceStream(token))\n  }\n\n  function exitContainers(size, end) {\n    var index = stack.length // Close the flow.\n\n    if (childFlow && end) {\n      childFlow.write([null])\n      childToken = childFlow = undefined\n    } // Exit open containers.\n\n    while (index-- > size) {\n      self.containerState = stack[index][1]\n      stack[index][0].exit.call(self, effects)\n    }\n\n    stack.length = size\n  }\n\n  function tokenizeInspect(effects, ok) {\n    var subcontinued = 0\n    inspectResult = {}\n    return inspectStart\n\n    function inspectStart(code) {\n      if (subcontinued < stack.length) {\n        self.containerState = stack[subcontinued][1]\n        return effects.attempt(\n          stack[subcontinued][0].continuation,\n          inspectContinue,\n          inspectLess\n        )(code)\n      } // If were continued but in a concrete flow, we cant have more\n      // containers.\n\n      if (childFlow.currentConstruct && childFlow.currentConstruct.concrete) {\n        inspectResult.flowContinue = true\n        return inspectDone(code)\n      }\n\n      self.interrupt =\n        childFlow.currentConstruct && childFlow.currentConstruct.interruptible\n      self.containerState = {}\n      return effects.attempt(\n        containerConstruct,\n        inspectFlowEnd,\n        inspectDone\n      )(code)\n    }\n\n    function inspectContinue(code) {\n      subcontinued++\n      return self.containerState._closeFlow\n        ? inspectFlowEnd(code)\n        : inspectStart(code)\n    }\n\n    function inspectLess(code) {\n      if (childFlow.currentConstruct && childFlow.currentConstruct.lazy) {\n        // Maybe another container?\n        self.containerState = {}\n        return effects.attempt(\n          containerConstruct,\n          inspectFlowEnd, // Maybe flow, or a blank line?\n          effects.attempt(\n            lazyFlowConstruct,\n            inspectFlowEnd,\n            effects.check(partialBlankLine, inspectFlowEnd, inspectLazy)\n          )\n        )(code)\n      } // Otherwise were interrupting.\n\n      return inspectFlowEnd(code)\n    }\n\n    function inspectLazy(code) {\n      // Act as if all containers are continued.\n      subcontinued = stack.length\n      inspectResult.lazy = true\n      inspectResult.flowContinue = true\n      return inspectDone(code)\n    } // Were done with flow if we have more containers, or an interruption.\n\n    function inspectFlowEnd(code) {\n      inspectResult.flowEnd = true\n      return inspectDone(code)\n    }\n\n    function inspectDone(code) {\n      inspectResult.continued = subcontinued\n      self.interrupt = self.containerState = undefined\n      return ok(code)\n    }\n  }\n}\n\nfunction tokenizeContainer(effects, ok, nok) {\n  return factorySpace(\n    effects,\n    effects.attempt(this.parser.constructs.document, ok, nok),\n    'linePrefix',\n    this.parser.constructs.disable.null.indexOf('codeIndented') > -1\n      ? undefined\n      : 4\n  )\n}\n\nfunction tokenizeLazyFlow(effects, ok, nok) {\n  return factorySpace(\n    effects,\n    effects.lazy(this.parser.constructs.flow, ok, nok),\n    'linePrefix',\n    this.parser.constructs.disable.null.indexOf('codeIndented') > -1\n      ? undefined\n      : 4\n  )\n}\n\nexports.tokenize = tokenize\n","/**\n * @import {Chunk, Code, Encoding, Value} from 'micromark-util-types'\n */\n\n/**\n * @callback Preprocessor\n *   Preprocess a value.\n * @param {Value} value\n *   Value.\n * @param {Encoding | null | undefined} [encoding]\n *   Encoding when `value` is a typed array (optional).\n * @param {boolean | null | undefined} [end=false]\n *   Whether this is the last chunk (default: `false`).\n * @returns {Array<Chunk>}\n *   Chunks.\n */\n\nconst search = /[\\0\\t\\n\\r]/g;\n\n/**\n * @returns {Preprocessor}\n *   Preprocess a value.\n */\nexport function preprocess() {\n  let column = 1;\n  let buffer = '';\n  /** @type {boolean | undefined} */\n  let start = true;\n  /** @type {boolean | undefined} */\n  let atCarriageReturn;\n  return preprocessor;\n\n  /** @type {Preprocessor} */\n  // eslint-disable-next-line complexity\n  function preprocessor(value, encoding, end) {\n    /** @type {Array<Chunk>} */\n    const chunks = [];\n    /** @type {RegExpMatchArray | null} */\n    let match;\n    /** @type {number} */\n    let next;\n    /** @type {number} */\n    let startPosition;\n    /** @type {number} */\n    let endPosition;\n    /** @type {Code} */\n    let code;\n    value = buffer + (typeof value === 'string' ? value.toString() : new TextDecoder(encoding || undefined).decode(value));\n    startPosition = 0;\n    buffer = '';\n    if (start) {\n      // To do: `markdown-rs` actually parses BOMs (byte order mark).\n      if (value.charCodeAt(0) === 65279) {\n        startPosition++;\n      }\n      start = undefined;\n    }\n    while (startPosition < value.length) {\n      search.lastIndex = startPosition;\n      match = search.exec(value);\n      endPosition = match && match.index !== undefined ? match.index : value.length;\n      code = value.charCodeAt(endPosition);\n      if (!match) {\n        buffer = value.slice(startPosition);\n        break;\n      }\n      if (code === 10 && startPosition === endPosition && atCarriageReturn) {\n        chunks.push(-3);\n        atCarriageReturn = undefined;\n      } else {\n        if (atCarriageReturn) {\n          chunks.push(-5);\n          atCarriageReturn = undefined;\n        }\n        if (startPosition < endPosition) {\n          chunks.push(value.slice(startPosition, endPosition));\n          column += endPosition - startPosition;\n        }\n        switch (code) {\n          case 0:\n            {\n              chunks.push(65533);\n              column++;\n              break;\n            }\n          case 9:\n            {\n              next = Math.ceil(column / 4) * 4;\n              chunks.push(-2);\n              while (column++ < next) chunks.push(-1);\n              break;\n            }\n          case 10:\n            {\n              chunks.push(-4);\n              column = 1;\n              break;\n            }\n          default:\n            {\n              atCarriageReturn = true;\n              column = 1;\n            }\n        }\n      }\n      startPosition = endPosition + 1;\n    }\n    if (end) {\n      if (atCarriageReturn) chunks.push(-5);\n      if (buffer) chunks.push(buffer);\n      chunks.push(null);\n    }\n    return chunks;\n  }\n}","'use strict'\n\nvar unicodePunctuationRegex = require('../constant/unicode-punctuation-regex.js')\nvar regexCheck = require('../util/regex-check.js')\n\n// In fact adds to the bundle size.\n\nvar unicodePunctuation = regexCheck(unicodePunctuationRegex)\n\nmodule.exports = unicodePunctuation\n","'use strict'\n\nvar asciiAlpha = require('../character/ascii-alpha.js')\nvar asciiAlphanumeric = require('../character/ascii-alphanumeric.js')\nvar markdownLineEnding = require('../character/markdown-line-ending.js')\nvar markdownLineEndingOrSpace = require('../character/markdown-line-ending-or-space.js')\nvar markdownSpace = require('../character/markdown-space.js')\nvar fromCharCode = require('../constant/from-char-code.js')\nvar htmlBlockNames = require('../constant/html-block-names.js')\nvar htmlRawNames = require('../constant/html-raw-names.js')\nvar partialBlankLine = require('./partial-blank-line.js')\n\nvar htmlFlow = {\n  name: 'htmlFlow',\n  tokenize: tokenizeHtmlFlow,\n  resolveTo: resolveToHtmlFlow,\n  concrete: true\n}\nvar nextBlankConstruct = {\n  tokenize: tokenizeNextBlank,\n  partial: true\n}\n\nfunction resolveToHtmlFlow(events) {\n  var index = events.length\n\n  while (index--) {\n    if (events[index][0] === 'enter' && events[index][1].type === 'htmlFlow') {\n      break\n    }\n  }\n\n  if (index > 1 && events[index - 2][1].type === 'linePrefix') {\n    // Add the prefix start to the HTML token.\n    events[index][1].start = events[index - 2][1].start // Add the prefix start to the HTML line token.\n\n    events[index + 1][1].start = events[index - 2][1].start // Remove the line prefix.\n\n    events.splice(index - 2, 2)\n  }\n\n  return events\n}\n\nfunction tokenizeHtmlFlow(effects, ok, nok) {\n  var self = this\n  var kind\n  var startTag\n  var buffer\n  var index\n  var marker\n  return start\n\n  function start(code) {\n    effects.enter('htmlFlow')\n    effects.enter('htmlFlowData')\n    effects.consume(code)\n    return open\n  }\n\n  function open(code) {\n    if (code === 33) {\n      effects.consume(code)\n      return declarationStart\n    }\n\n    if (code === 47) {\n      effects.consume(code)\n      return tagCloseStart\n    }\n\n    if (code === 63) {\n      effects.consume(code)\n      kind = 3 // While were in an instruction instead of a declaration, were on a `?`\n      // right now, so we do need to search for `>`, similar to declarations.\n\n      return self.interrupt ? ok : continuationDeclarationInside\n    }\n\n    if (asciiAlpha(code)) {\n      effects.consume(code)\n      buffer = fromCharCode(code)\n      startTag = true\n      return tagName\n    }\n\n    return nok(code)\n  }\n\n  function declarationStart(code) {\n    if (code === 45) {\n      effects.consume(code)\n      kind = 2\n      return commentOpenInside\n    }\n\n    if (code === 91) {\n      effects.consume(code)\n      kind = 5\n      buffer = 'CDATA['\n      index = 0\n      return cdataOpenInside\n    }\n\n    if (asciiAlpha(code)) {\n      effects.consume(code)\n      kind = 4\n      return self.interrupt ? ok : continuationDeclarationInside\n    }\n\n    return nok(code)\n  }\n\n  function commentOpenInside(code) {\n    if (code === 45) {\n      effects.consume(code)\n      return self.interrupt ? ok : continuationDeclarationInside\n    }\n\n    return nok(code)\n  }\n\n  function cdataOpenInside(code) {\n    if (code === buffer.charCodeAt(index++)) {\n      effects.consume(code)\n      return index === buffer.length\n        ? self.interrupt\n          ? ok\n          : continuation\n        : cdataOpenInside\n    }\n\n    return nok(code)\n  }\n\n  function tagCloseStart(code) {\n    if (asciiAlpha(code)) {\n      effects.consume(code)\n      buffer = fromCharCode(code)\n      return tagName\n    }\n\n    return nok(code)\n  }\n\n  function tagName(code) {\n    if (\n      code === null ||\n      code === 47 ||\n      code === 62 ||\n      markdownLineEndingOrSpace(code)\n    ) {\n      if (\n        code !== 47 &&\n        startTag &&\n        htmlRawNames.indexOf(buffer.toLowerCase()) > -1\n      ) {\n        kind = 1\n        return self.interrupt ? ok(code) : continuation(code)\n      }\n\n      if (htmlBlockNames.indexOf(buffer.toLowerCase()) > -1) {\n        kind = 6\n\n        if (code === 47) {\n          effects.consume(code)\n          return basicSelfClosing\n        }\n\n        return self.interrupt ? ok(code) : continuation(code)\n      }\n\n      kind = 7 // Do not support complete HTML when interrupting.\n\n      return self.interrupt\n        ? nok(code)\n        : startTag\n        ? completeAttributeNameBefore(code)\n        : completeClosingTagAfter(code)\n    }\n\n    if (code === 45 || asciiAlphanumeric(code)) {\n      effects.consume(code)\n      buffer += fromCharCode(code)\n      return tagName\n    }\n\n    return nok(code)\n  }\n\n  function basicSelfClosing(code) {\n    if (code === 62) {\n      effects.consume(code)\n      return self.interrupt ? ok : continuation\n    }\n\n    return nok(code)\n  }\n\n  function completeClosingTagAfter(code) {\n    if (markdownSpace(code)) {\n      effects.consume(code)\n      return completeClosingTagAfter\n    }\n\n    return completeEnd(code)\n  }\n\n  function completeAttributeNameBefore(code) {\n    if (code === 47) {\n      effects.consume(code)\n      return completeEnd\n    }\n\n    if (code === 58 || code === 95 || asciiAlpha(code)) {\n      effects.consume(code)\n      return completeAttributeName\n    }\n\n    if (markdownSpace(code)) {\n      effects.consume(code)\n      return completeAttributeNameBefore\n    }\n\n    return completeEnd(code)\n  }\n\n  function completeAttributeName(code) {\n    if (\n      code === 45 ||\n      code === 46 ||\n      code === 58 ||\n      code === 95 ||\n      asciiAlphanumeric(code)\n    ) {\n      effects.consume(code)\n      return completeAttributeName\n    }\n\n    return completeAttributeNameAfter(code)\n  }\n\n  function completeAttributeNameAfter(code) {\n    if (code === 61) {\n      effects.consume(code)\n      return completeAttributeValueBefore\n    }\n\n    if (markdownSpace(code)) {\n      effects.consume(code)\n      return completeAttributeNameAfter\n    }\n\n    return completeAttributeNameBefore(code)\n  }\n\n  function completeAttributeValueBefore(code) {\n    if (\n      code === null ||\n      code === 60 ||\n      code === 61 ||\n      code === 62 ||\n      code === 96\n    ) {\n      return nok(code)\n    }\n\n    if (code === 34 || code === 39) {\n      effects.consume(code)\n      marker = code\n      return completeAttributeValueQuoted\n    }\n\n    if (markdownSpace(code)) {\n      effects.consume(code)\n      return completeAttributeValueBefore\n    }\n\n    marker = undefined\n    return completeAttributeValueUnquoted(code)\n  }\n\n  function completeAttributeValueQuoted(code) {\n    if (code === marker) {\n      effects.consume(code)\n      return completeAttributeValueQuotedAfter\n    }\n\n    if (code === null || markdownLineEnding(code)) {\n      return nok(code)\n    }\n\n    effects.consume(code)\n    return completeAttributeValueQuoted\n  }\n\n  function completeAttributeValueUnquoted(code) {\n    if (\n      code === null ||\n      code === 34 ||\n      code === 39 ||\n      code === 60 ||\n      code === 61 ||\n      code === 62 ||\n      code === 96 ||\n      markdownLineEndingOrSpace(code)\n    ) {\n      return completeAttributeNameAfter(code)\n    }\n\n    effects.consume(code)\n    return completeAttributeValueUnquoted\n  }\n\n  function completeAttributeValueQuotedAfter(code) {\n    if (code === 47 || code === 62 || markdownSpace(code)) {\n      return completeAttributeNameBefore(code)\n    }\n\n    return nok(code)\n  }\n\n  function completeEnd(code) {\n    if (code === 62) {\n      effects.consume(code)\n      return completeAfter\n    }\n\n    return nok(code)\n  }\n\n  function completeAfter(code) {\n    if (markdownSpace(code)) {\n      effects.consume(code)\n      return completeAfter\n    }\n\n    return code === null || markdownLineEnding(code)\n      ? continuation(code)\n      : nok(code)\n  }\n\n  function continuation(code) {\n    if (code === 45 && kind === 2) {\n      effects.consume(code)\n      return continuationCommentInside\n    }\n\n    if (code === 60 && kind === 1) {\n      effects.consume(code)\n      return continuationRawTagOpen\n    }\n\n    if (code === 62 && kind === 4) {\n      effects.consume(code)\n      return continuationClose\n    }\n\n    if (code === 63 && kind === 3) {\n      effects.consume(code)\n      return continuationDeclarationInside\n    }\n\n    if (code === 93 && kind === 5) {\n      effects.consume(code)\n      return continuationCharacterDataInside\n    }\n\n    if (markdownLineEnding(code) && (kind === 6 || kind === 7)) {\n      return effects.check(\n        nextBlankConstruct,\n        continuationClose,\n        continuationAtLineEnding\n      )(code)\n    }\n\n    if (code === null || markdownLineEnding(code)) {\n      return continuationAtLineEnding(code)\n    }\n\n    effects.consume(code)\n    return continuation\n  }\n\n  function continuationAtLineEnding(code) {\n    effects.exit('htmlFlowData')\n    return htmlContinueStart(code)\n  }\n\n  function htmlContinueStart(code) {\n    if (code === null) {\n      return done(code)\n    }\n\n    if (markdownLineEnding(code)) {\n      effects.enter('lineEnding')\n      effects.consume(code)\n      effects.exit('lineEnding')\n      return htmlContinueStart\n    }\n\n    effects.enter('htmlFlowData')\n    return continuation(code)\n  }\n\n  function continuationCommentInside(code) {\n    if (code === 45) {\n      effects.consume(code)\n      return continuationDeclarationInside\n    }\n\n    return continuation(code)\n  }\n\n  function continuationRawTagOpen(code) {\n    if (code === 47) {\n      effects.consume(code)\n      buffer = ''\n      return continuationRawEndTag\n    }\n\n    return continuation(code)\n  }\n\n  function continuationRawEndTag(code) {\n    if (code === 62 && htmlRawNames.indexOf(buffer.toLowerCase()) > -1) {\n      effects.consume(code)\n      return continuationClose\n    }\n\n    if (asciiAlpha(code) && buffer.length < 8) {\n      effects.consume(code)\n      buffer += fromCharCode(code)\n      return continuationRawEndTag\n    }\n\n    return continuation(code)\n  }\n\n  function continuationCharacterDataInside(code) {\n    if (code === 93) {\n      effects.consume(code)\n      return continuationDeclarationInside\n    }\n\n    return continuation(code)\n  }\n\n  function continuationDeclarationInside(code) {\n    if (code === 62) {\n      effects.consume(code)\n      return continuationClose\n    }\n\n    return continuation(code)\n  }\n\n  function continuationClose(code) {\n    if (code === null || markdownLineEnding(code)) {\n      effects.exit('htmlFlowData')\n      return done(code)\n    }\n\n    effects.consume(code)\n    return continuationClose\n  }\n\n  function done(code) {\n    effects.exit('htmlFlow')\n    return ok(code)\n  }\n}\n\nfunction tokenizeNextBlank(effects, ok, nok) {\n  return start\n\n  function start(code) {\n    effects.exit('htmlFlowData')\n    effects.enter('lineEndingBlank')\n    effects.consume(code)\n    effects.exit('lineEndingBlank')\n    return effects.attempt(partialBlankLine, ok, nok)\n  }\n}\n\nmodule.exports = htmlFlow\n","'use strict'\n\nvar asciiAlpha = require('../character/ascii-alpha.js')\nvar asciiAlphanumeric = require('../character/ascii-alphanumeric.js')\nvar asciiAtext = require('../character/ascii-atext.js')\nvar asciiControl = require('../character/ascii-control.js')\n\nvar autolink = {\n  name: 'autolink',\n  tokenize: tokenizeAutolink\n}\n\nfunction tokenizeAutolink(effects, ok, nok) {\n  var size = 1\n  return start\n\n  function start(code) {\n    effects.enter('autolink')\n    effects.enter('autolinkMarker')\n    effects.consume(code)\n    effects.exit('autolinkMarker')\n    effects.enter('autolinkProtocol')\n    return open\n  }\n\n  function open(code) {\n    if (asciiAlpha(code)) {\n      effects.consume(code)\n      return schemeOrEmailAtext\n    }\n\n    return asciiAtext(code) ? emailAtext(code) : nok(code)\n  }\n\n  function schemeOrEmailAtext(code) {\n    return code === 43 || code === 45 || code === 46 || asciiAlphanumeric(code)\n      ? schemeInsideOrEmailAtext(code)\n      : emailAtext(code)\n  }\n\n  function schemeInsideOrEmailAtext(code) {\n    if (code === 58) {\n      effects.consume(code)\n      return urlInside\n    }\n\n    if (\n      (code === 43 || code === 45 || code === 46 || asciiAlphanumeric(code)) &&\n      size++ < 32\n    ) {\n      effects.consume(code)\n      return schemeInsideOrEmailAtext\n    }\n\n    return emailAtext(code)\n  }\n\n  function urlInside(code) {\n    if (code === 62) {\n      effects.exit('autolinkProtocol')\n      return end(code)\n    }\n\n    if (code === 32 || code === 60 || asciiControl(code)) {\n      return nok(code)\n    }\n\n    effects.consume(code)\n    return urlInside\n  }\n\n  function emailAtext(code) {\n    if (code === 64) {\n      effects.consume(code)\n      size = 0\n      return emailAtSignOrDot\n    }\n\n    if (asciiAtext(code)) {\n      effects.consume(code)\n      return emailAtext\n    }\n\n    return nok(code)\n  }\n\n  function emailAtSignOrDot(code) {\n    return asciiAlphanumeric(code) ? emailLabel(code) : nok(code)\n  }\n\n  function emailLabel(code) {\n    if (code === 46) {\n      effects.consume(code)\n      size = 0\n      return emailAtSignOrDot\n    }\n\n    if (code === 62) {\n      // Exit, then change the type.\n      effects.exit('autolinkProtocol').type = 'autolinkEmail'\n      return end(code)\n    }\n\n    return emailValue(code)\n  }\n\n  function emailValue(code) {\n    if ((code === 45 || asciiAlphanumeric(code)) && size++ < 63) {\n      effects.consume(code)\n      return code === 45 ? emailValue : emailLabel\n    }\n\n    return nok(code)\n  }\n\n  function end(code) {\n    effects.enter('autolinkMarker')\n    effects.consume(code)\n    effects.exit('autolinkMarker')\n    effects.exit('autolink')\n    return ok\n  }\n}\n\nmodule.exports = autolink\n","'use strict'\n\nObject.defineProperty(exports, '__esModule', {value: true})\n\nvar content = require('../tokenize/content.js')\nvar factorySpace = require('../tokenize/factory-space.js')\nvar partialBlankLine = require('../tokenize/partial-blank-line.js')\n\nvar tokenize = initializeFlow\n\nfunction initializeFlow(effects) {\n  var self = this\n  var initial = effects.attempt(\n    // Try to parse a blank line.\n    partialBlankLine,\n    atBlankEnding, // Try to parse initial flow (essentially, only code).\n    effects.attempt(\n      this.parser.constructs.flowInitial,\n      afterConstruct,\n      factorySpace(\n        effects,\n        effects.attempt(\n          this.parser.constructs.flow,\n          afterConstruct,\n          effects.attempt(content, afterConstruct)\n        ),\n        'linePrefix'\n      )\n    )\n  )\n  return initial\n\n  function atBlankEnding(code) {\n    if (code === null) {\n      effects.consume(code)\n      return\n    }\n\n    effects.enter('lineEndingBlank')\n    effects.consume(code)\n    effects.exit('lineEndingBlank')\n    self.currentConstruct = undefined\n    return initial\n  }\n\n  function afterConstruct(code) {\n    if (code === null) {\n      effects.consume(code)\n      return\n    }\n\n    effects.enter('lineEnding')\n    effects.consume(code)\n    effects.exit('lineEnding')\n    self.currentConstruct = undefined\n    return initial\n  }\n}\n\nexports.tokenize = tokenize\n","'use strict'\n\nvar fromCharCode = String.fromCharCode\n\nmodule.exports = fromCharCode\n","'use strict'\n\n// This module is copied from <https://spec.commonmark.org/0.29/#html-blocks>.\nvar raws = ['pre', 'script', 'style', 'textarea']\n\nmodule.exports = raws\n","/**\n * @import {Event} from 'micromark-util-types'\n */\n\nimport { subtokenize } from 'micromark-util-subtokenize';\n\n/**\n * @param {Array<Event>} events\n *   Events.\n * @returns {Array<Event>}\n *   Events.\n */\nexport function postprocess(events) {\n  while (!subtokenize(events)) {\n    // Empty\n  }\n  return events;\n}","'use strict'\n\nfunction markdownSpace(code) {\n  return code === -2 || code === -1 || code === 32\n}\n\nmodule.exports = markdownSpace\n","'use strict'\n\nvar markdownLineEnding = require('../character/markdown-line-ending.js')\nvar markdownSpace = require('../character/markdown-space.js')\nvar factorySpace = require('./factory-space.js')\n\nvar thematicBreak = {\n  name: 'thematicBreak',\n  tokenize: tokenizeThematicBreak\n}\n\nfunction tokenizeThematicBreak(effects, ok, nok) {\n  var size = 0\n  var marker\n  return start\n\n  function start(code) {\n    effects.enter('thematicBreak')\n    marker = code\n    return atBreak(code)\n  }\n\n  function atBreak(code) {\n    if (code === marker) {\n      effects.enter('thematicBreakSequence')\n      return sequence(code)\n    }\n\n    if (markdownSpace(code)) {\n      return factorySpace(effects, atBreak, 'whitespace')(code)\n    }\n\n    if (size < 3 || (code !== null && !markdownLineEnding(code))) {\n      return nok(code)\n    }\n\n    effects.exit('thematicBreak')\n    return ok(code)\n  }\n\n  function sequence(code) {\n    if (code === marker) {\n      effects.consume(code)\n      size++\n      return sequence\n    }\n\n    effects.exit('thematicBreakSequence')\n    return atBreak(code)\n  }\n}\n\nmodule.exports = thematicBreak\n","'use strict'\n\nfunction resolveAll(constructs, events, context) {\n  var called = []\n  var index = -1\n  var resolve\n\n  while (++index < constructs.length) {\n    resolve = constructs[index].resolveAll\n\n    if (resolve && called.indexOf(resolve) < 0) {\n      events = resolve(events, context)\n      called.push(resolve)\n    }\n  }\n\n  return events\n}\n\nmodule.exports = resolveAll\n","'use strict'\n\nvar assign = Object.assign\n\nmodule.exports = assign\n","'use strict'\n\nvar asciiAlpha = require('../character/ascii-alpha.js')\nvar asciiAlphanumeric = require('../character/ascii-alphanumeric.js')\nvar markdownLineEnding = require('../character/markdown-line-ending.js')\nvar markdownLineEndingOrSpace = require('../character/markdown-line-ending-or-space.js')\nvar markdownSpace = require('../character/markdown-space.js')\nvar factorySpace = require('./factory-space.js')\n\nvar htmlText = {\n  name: 'htmlText',\n  tokenize: tokenizeHtmlText\n}\n\nfunction tokenizeHtmlText(effects, ok, nok) {\n  var self = this\n  var marker\n  var buffer\n  var index\n  var returnState\n  return start\n\n  function start(code) {\n    effects.enter('htmlText')\n    effects.enter('htmlTextData')\n    effects.consume(code)\n    return open\n  }\n\n  function open(code) {\n    if (code === 33) {\n      effects.consume(code)\n      return declarationOpen\n    }\n\n    if (code === 47) {\n      effects.consume(code)\n      return tagCloseStart\n    }\n\n    if (code === 63) {\n      effects.consume(code)\n      return instruction\n    }\n\n    if (asciiAlpha(code)) {\n      effects.consume(code)\n      return tagOpen\n    }\n\n    return nok(code)\n  }\n\n  function declarationOpen(code) {\n    if (code === 45) {\n      effects.consume(code)\n      return commentOpen\n    }\n\n    if (code === 91) {\n      effects.consume(code)\n      buffer = 'CDATA['\n      index = 0\n      return cdataOpen\n    }\n\n    if (asciiAlpha(code)) {\n      effects.consume(code)\n      return declaration\n    }\n\n    return nok(code)\n  }\n\n  function commentOpen(code) {\n    if (code === 45) {\n      effects.consume(code)\n      return commentStart\n    }\n\n    return nok(code)\n  }\n\n  function commentStart(code) {\n    if (code === null || code === 62) {\n      return nok(code)\n    }\n\n    if (code === 45) {\n      effects.consume(code)\n      return commentStartDash\n    }\n\n    return comment(code)\n  }\n\n  function commentStartDash(code) {\n    if (code === null || code === 62) {\n      return nok(code)\n    }\n\n    return comment(code)\n  }\n\n  function comment(code) {\n    if (code === null) {\n      return nok(code)\n    }\n\n    if (code === 45) {\n      effects.consume(code)\n      return commentClose\n    }\n\n    if (markdownLineEnding(code)) {\n      returnState = comment\n      return atLineEnding(code)\n    }\n\n    effects.consume(code)\n    return comment\n  }\n\n  function commentClose(code) {\n    if (code === 45) {\n      effects.consume(code)\n      return end\n    }\n\n    return comment(code)\n  }\n\n  function cdataOpen(code) {\n    if (code === buffer.charCodeAt(index++)) {\n      effects.consume(code)\n      return index === buffer.length ? cdata : cdataOpen\n    }\n\n    return nok(code)\n  }\n\n  function cdata(code) {\n    if (code === null) {\n      return nok(code)\n    }\n\n    if (code === 93) {\n      effects.consume(code)\n      return cdataClose\n    }\n\n    if (markdownLineEnding(code)) {\n      returnState = cdata\n      return atLineEnding(code)\n    }\n\n    effects.consume(code)\n    return cdata\n  }\n\n  function cdataClose(code) {\n    if (code === 93) {\n      effects.consume(code)\n      return cdataEnd\n    }\n\n    return cdata(code)\n  }\n\n  function cdataEnd(code) {\n    if (code === 62) {\n      return end(code)\n    }\n\n    if (code === 93) {\n      effects.consume(code)\n      return cdataEnd\n    }\n\n    return cdata(code)\n  }\n\n  function declaration(code) {\n    if (code === null || code === 62) {\n      return end(code)\n    }\n\n    if (markdownLineEnding(code)) {\n      returnState = declaration\n      return atLineEnding(code)\n    }\n\n    effects.consume(code)\n    return declaration\n  }\n\n  function instruction(code) {\n    if (code === null) {\n      return nok(code)\n    }\n\n    if (code === 63) {\n      effects.consume(code)\n      return instructionClose\n    }\n\n    if (markdownLineEnding(code)) {\n      returnState = instruction\n      return atLineEnding(code)\n    }\n\n    effects.consume(code)\n    return instruction\n  }\n\n  function instructionClose(code) {\n    return code === 62 ? end(code) : instruction(code)\n  }\n\n  function tagCloseStart(code) {\n    if (asciiAlpha(code)) {\n      effects.consume(code)\n      return tagClose\n    }\n\n    return nok(code)\n  }\n\n  function tagClose(code) {\n    if (code === 45 || asciiAlphanumeric(code)) {\n      effects.consume(code)\n      return tagClose\n    }\n\n    return tagCloseBetween(code)\n  }\n\n  function tagCloseBetween(code) {\n    if (markdownLineEnding(code)) {\n      returnState = tagCloseBetween\n      return atLineEnding(code)\n    }\n\n    if (markdownSpace(code)) {\n      effects.consume(code)\n      return tagCloseBetween\n    }\n\n    return end(code)\n  }\n\n  function tagOpen(code) {\n    if (code === 45 || asciiAlphanumeric(code)) {\n      effects.consume(code)\n      return tagOpen\n    }\n\n    if (code === 47 || code === 62 || markdownLineEndingOrSpace(code)) {\n      return tagOpenBetween(code)\n    }\n\n    return nok(code)\n  }\n\n  function tagOpenBetween(code) {\n    if (code === 47) {\n      effects.consume(code)\n      return end\n    }\n\n    if (code === 58 || code === 95 || asciiAlpha(code)) {\n      effects.consume(code)\n      return tagOpenAttributeName\n    }\n\n    if (markdownLineEnding(code)) {\n      returnState = tagOpenBetween\n      return atLineEnding(code)\n    }\n\n    if (markdownSpace(code)) {\n      effects.consume(code)\n      return tagOpenBetween\n    }\n\n    return end(code)\n  }\n\n  function tagOpenAttributeName(code) {\n    if (\n      code === 45 ||\n      code === 46 ||\n      code === 58 ||\n      code === 95 ||\n      asciiAlphanumeric(code)\n    ) {\n      effects.consume(code)\n      return tagOpenAttributeName\n    }\n\n    return tagOpenAttributeNameAfter(code)\n  }\n\n  function tagOpenAttributeNameAfter(code) {\n    if (code === 61) {\n      effects.consume(code)\n      return tagOpenAttributeValueBefore\n    }\n\n    if (markdownLineEnding(code)) {\n      returnState = tagOpenAttributeNameAfter\n      return atLineEnding(code)\n    }\n\n    if (markdownSpace(code)) {\n      effects.consume(code)\n      return tagOpenAttributeNameAfter\n    }\n\n    return tagOpenBetween(code)\n  }\n\n  function tagOpenAttributeValueBefore(code) {\n    if (\n      code === null ||\n      code === 60 ||\n      code === 61 ||\n      code === 62 ||\n      code === 96\n    ) {\n      return nok(code)\n    }\n\n    if (code === 34 || code === 39) {\n      effects.consume(code)\n      marker = code\n      return tagOpenAttributeValueQuoted\n    }\n\n    if (markdownLineEnding(code)) {\n      returnState = tagOpenAttributeValueBefore\n      return atLineEnding(code)\n    }\n\n    if (markdownSpace(code)) {\n      effects.consume(code)\n      return tagOpenAttributeValueBefore\n    }\n\n    effects.consume(code)\n    marker = undefined\n    return tagOpenAttributeValueUnquoted\n  }\n\n  function tagOpenAttributeValueQuoted(code) {\n    if (code === marker) {\n      effects.consume(code)\n      return tagOpenAttributeValueQuotedAfter\n    }\n\n    if (code === null) {\n      return nok(code)\n    }\n\n    if (markdownLineEnding(code)) {\n      returnState = tagOpenAttributeValueQuoted\n      return atLineEnding(code)\n    }\n\n    effects.consume(code)\n    return tagOpenAttributeValueQuoted\n  }\n\n  function tagOpenAttributeValueQuotedAfter(code) {\n    if (code === 62 || code === 47 || markdownLineEndingOrSpace(code)) {\n      return tagOpenBetween(code)\n    }\n\n    return nok(code)\n  }\n\n  function tagOpenAttributeValueUnquoted(code) {\n    if (\n      code === null ||\n      code === 34 ||\n      code === 39 ||\n      code === 60 ||\n      code === 61 ||\n      code === 96\n    ) {\n      return nok(code)\n    }\n\n    if (code === 62 || markdownLineEndingOrSpace(code)) {\n      return tagOpenBetween(code)\n    }\n\n    effects.consume(code)\n    return tagOpenAttributeValueUnquoted\n  } // We cant have blank lines in content, so no need to worry about empty\n  // tokens.\n\n  function atLineEnding(code) {\n    effects.exit('htmlTextData')\n    effects.enter('lineEnding')\n    effects.consume(code)\n    effects.exit('lineEnding')\n    return factorySpace(\n      effects,\n      afterPrefix,\n      'linePrefix',\n      self.parser.constructs.disable.null.indexOf('codeIndented') > -1\n        ? undefined\n        : 4\n    )\n  }\n\n  function afterPrefix(code) {\n    effects.enter('htmlTextData')\n    return returnState(code)\n  }\n\n  function end(code) {\n    if (code === 62) {\n      effects.consume(code)\n      effects.exit('htmlTextData')\n      effects.exit('htmlText')\n      return ok\n    }\n\n    return nok(code)\n  }\n}\n\nmodule.exports = htmlText\n","'use strict'\n\nvar markdownLineEndingOrSpace = require('../character/markdown-line-ending-or-space.js')\nvar unicodePunctuation = require('../character/unicode-punctuation.js')\nvar unicodeWhitespace = require('../character/unicode-whitespace.js')\n\n// Classify whether a character is unicode whitespace, unicode punctuation, or\n// anything else.\n// Used for attention (emphasis, strong), whose sequences can open or close\n// based on the class of surrounding characters.\nfunction classifyCharacter(code) {\n  if (\n    code === null ||\n    markdownLineEndingOrSpace(code) ||\n    unicodeWhitespace(code)\n  ) {\n    return 1\n  }\n\n  if (unicodePunctuation(code)) {\n    return 2\n  }\n}\n\nmodule.exports = classifyCharacter\n","'use strict'\n\n// chunks (replacement characters, tabs, or line endings).\n\nfunction movePoint(point, offset) {\n  point.column += offset\n  point.offset += offset\n  point._bufferIndex += offset\n  return point\n}\n\nmodule.exports = movePoint\n","'use strict'\n\nvar assign = require('../constant/assign.js')\n\nfunction shallow(object) {\n  return assign({}, object)\n}\n\nmodule.exports = shallow\n","'use strict'\n\nvar markdownLineEnding = require('../character/markdown-line-ending.js')\nvar shallow = require('../util/shallow.js')\nvar factorySpace = require('./factory-space.js')\n\nvar setextUnderline = {\n  name: 'setextUnderline',\n  tokenize: tokenizeSetextUnderline,\n  resolveTo: resolveToSetextUnderline\n}\n\nfunction resolveToSetextUnderline(events, context) {\n  var index = events.length\n  var content\n  var text\n  var definition\n  var heading // Find the opening of the content.\n  // Itll always exist: we dont tokenize if it isnt there.\n\n  while (index--) {\n    if (events[index][0] === 'enter') {\n      if (events[index][1].type === 'content') {\n        content = index\n        break\n      }\n\n      if (events[index][1].type === 'paragraph') {\n        text = index\n      }\n    } // Exit\n    else {\n      if (events[index][1].type === 'content') {\n        // Remove the content end (if needed well add it later)\n        events.splice(index, 1)\n      }\n\n      if (!definition && events[index][1].type === 'definition') {\n        definition = index\n      }\n    }\n  }\n\n  heading = {\n    type: 'setextHeading',\n    start: shallow(events[text][1].start),\n    end: shallow(events[events.length - 1][1].end)\n  } // Change the paragraph to setext heading text.\n\n  events[text][1].type = 'setextHeadingText' // If we have definitions in the content, well keep on having content,\n  // but we need move it.\n\n  if (definition) {\n    events.splice(text, 0, ['enter', heading, context])\n    events.splice(definition + 1, 0, ['exit', events[content][1], context])\n    events[content][1].end = shallow(events[definition][1].end)\n  } else {\n    events[content][1] = heading\n  } // Add the heading exit at the end.\n\n  events.push(['exit', heading, context])\n  return events\n}\n\nfunction tokenizeSetextUnderline(effects, ok, nok) {\n  var self = this\n  var index = self.events.length\n  var marker\n  var paragraph // Find an opening.\n\n  while (index--) {\n    // Skip enter/exit of line ending, line prefix, and content.\n    // We can now either have a definition or a paragraph.\n    if (\n      self.events[index][1].type !== 'lineEnding' &&\n      self.events[index][1].type !== 'linePrefix' &&\n      self.events[index][1].type !== 'content'\n    ) {\n      paragraph = self.events[index][1].type === 'paragraph'\n      break\n    }\n  }\n\n  return start\n\n  function start(code) {\n    if (!self.lazy && (self.interrupt || paragraph)) {\n      effects.enter('setextHeadingLine')\n      effects.enter('setextHeadingLineSequence')\n      marker = code\n      return closingSequence(code)\n    }\n\n    return nok(code)\n  }\n\n  function closingSequence(code) {\n    if (code === marker) {\n      effects.consume(code)\n      return closingSequence\n    }\n\n    effects.exit('setextHeadingLineSequence')\n    return factorySpace(effects, closingSequenceEnd, 'lineSuffix')(code)\n  }\n\n  function closingSequenceEnd(code) {\n    if (code === null || markdownLineEnding(code)) {\n      effects.exit('setextHeadingLine')\n      return ok(code)\n    }\n\n    return nok(code)\n  }\n}\n\nmodule.exports = setextUnderline\n","'use strict'\n\nvar labelEnd = require('./label-end.js')\n\nvar labelStartLink = {\n  name: 'labelStartLink',\n  tokenize: tokenizeLabelStartLink,\n  resolveAll: labelEnd.resolveAll\n}\n\nfunction tokenizeLabelStartLink(effects, ok, nok) {\n  var self = this\n  return start\n\n  function start(code) {\n    effects.enter('labelLink')\n    effects.enter('labelMarker')\n    effects.consume(code)\n    effects.exit('labelMarker')\n    effects.exit('labelLink')\n    return after\n  }\n\n  function after(code) {\n    /* c8 ignore next */\n    return code === 94 &&\n      /* c8 ignore next */\n      '_hiddenFootnoteSupport' in self.parser.constructs\n      ? /* c8 ignore next */\n        nok(code)\n      : ok(code)\n  }\n}\n\nmodule.exports = labelStartLink\n","'use strict'\n\nvar asciiPunctuation = require('../character/ascii-punctuation.js')\n\nvar characterEscape = {\n  name: 'characterEscape',\n  tokenize: tokenizeCharacterEscape\n}\n\nfunction tokenizeCharacterEscape(effects, ok, nok) {\n  return start\n\n  function start(code) {\n    effects.enter('characterEscape')\n    effects.enter('escapeMarker')\n    effects.consume(code)\n    effects.exit('escapeMarker')\n    return open\n  }\n\n  function open(code) {\n    if (asciiPunctuation(code)) {\n      effects.enter('characterEscapeValue')\n      effects.consume(code)\n      effects.exit('characterEscapeValue')\n      effects.exit('characterEscape')\n      return ok\n    }\n\n    return nok(code)\n  }\n}\n\nmodule.exports = characterEscape\n","'use strict'\n\nvar splice = [].splice\n\nmodule.exports = splice\n","'use strict'\n\nvar markdownLineEnding = require('../character/markdown-line-ending.js')\nvar markdownLineEndingOrSpace = require('../character/markdown-line-ending-or-space.js')\nvar prefixSize = require('../util/prefix-size.js')\nvar factorySpace = require('./factory-space.js')\n\nvar codeFenced = {\n  name: 'codeFenced',\n  tokenize: tokenizeCodeFenced,\n  concrete: true\n}\n\nfunction tokenizeCodeFenced(effects, ok, nok) {\n  var self = this\n  var closingFenceConstruct = {\n    tokenize: tokenizeClosingFence,\n    partial: true\n  }\n  var initialPrefix = prefixSize(this.events, 'linePrefix')\n  var sizeOpen = 0\n  var marker\n  return start\n\n  function start(code) {\n    effects.enter('codeFenced')\n    effects.enter('codeFencedFence')\n    effects.enter('codeFencedFenceSequence')\n    marker = code\n    return sequenceOpen(code)\n  }\n\n  function sequenceOpen(code) {\n    if (code === marker) {\n      effects.consume(code)\n      sizeOpen++\n      return sequenceOpen\n    }\n\n    effects.exit('codeFencedFenceSequence')\n    return sizeOpen < 3\n      ? nok(code)\n      : factorySpace(effects, infoOpen, 'whitespace')(code)\n  }\n\n  function infoOpen(code) {\n    if (code === null || markdownLineEnding(code)) {\n      return openAfter(code)\n    }\n\n    effects.enter('codeFencedFenceInfo')\n    effects.enter('chunkString', {\n      contentType: 'string'\n    })\n    return info(code)\n  }\n\n  function info(code) {\n    if (code === null || markdownLineEndingOrSpace(code)) {\n      effects.exit('chunkString')\n      effects.exit('codeFencedFenceInfo')\n      return factorySpace(effects, infoAfter, 'whitespace')(code)\n    }\n\n    if (code === 96 && code === marker) return nok(code)\n    effects.consume(code)\n    return info\n  }\n\n  function infoAfter(code) {\n    if (code === null || markdownLineEnding(code)) {\n      return openAfter(code)\n    }\n\n    effects.enter('codeFencedFenceMeta')\n    effects.enter('chunkString', {\n      contentType: 'string'\n    })\n    return meta(code)\n  }\n\n  function meta(code) {\n    if (code === null || markdownLineEnding(code)) {\n      effects.exit('chunkString')\n      effects.exit('codeFencedFenceMeta')\n      return openAfter(code)\n    }\n\n    if (code === 96 && code === marker) return nok(code)\n    effects.consume(code)\n    return meta\n  }\n\n  function openAfter(code) {\n    effects.exit('codeFencedFence')\n    return self.interrupt ? ok(code) : content(code)\n  }\n\n  function content(code) {\n    if (code === null) {\n      return after(code)\n    }\n\n    if (markdownLineEnding(code)) {\n      effects.enter('lineEnding')\n      effects.consume(code)\n      effects.exit('lineEnding')\n      return effects.attempt(\n        closingFenceConstruct,\n        after,\n        initialPrefix\n          ? factorySpace(effects, content, 'linePrefix', initialPrefix + 1)\n          : content\n      )\n    }\n\n    effects.enter('codeFlowValue')\n    return contentContinue(code)\n  }\n\n  function contentContinue(code) {\n    if (code === null || markdownLineEnding(code)) {\n      effects.exit('codeFlowValue')\n      return content(code)\n    }\n\n    effects.consume(code)\n    return contentContinue\n  }\n\n  function after(code) {\n    effects.exit('codeFenced')\n    return ok(code)\n  }\n\n  function tokenizeClosingFence(effects, ok, nok) {\n    var size = 0\n    return factorySpace(\n      effects,\n      closingSequenceStart,\n      'linePrefix',\n      this.parser.constructs.disable.null.indexOf('codeIndented') > -1\n        ? undefined\n        : 4\n    )\n\n    function closingSequenceStart(code) {\n      effects.enter('codeFencedFence')\n      effects.enter('codeFencedFenceSequence')\n      return closingSequence(code)\n    }\n\n    function closingSequence(code) {\n      if (code === marker) {\n        effects.consume(code)\n        size++\n        return closingSequence\n      }\n\n      if (size < sizeOpen) return nok(code)\n      effects.exit('codeFencedFenceSequence')\n      return factorySpace(effects, closingSequenceEnd, 'whitespace')(code)\n    }\n\n    function closingSequenceEnd(code) {\n      if (code === null || markdownLineEnding(code)) {\n        effects.exit('codeFencedFence')\n        return ok(code)\n      }\n\n      return nok(code)\n    }\n  }\n}\n\nmodule.exports = codeFenced\n","'use strict'\n\nvar markdownLineEnding = require('../character/markdown-line-ending.js')\nvar factorySpace = require('./factory-space.js')\n\nvar partialBlankLine = {\n  tokenize: tokenizePartialBlankLine,\n  partial: true\n}\n\nfunction tokenizePartialBlankLine(effects, ok, nok) {\n  return factorySpace(effects, afterWhitespace, 'linePrefix')\n\n  function afterWhitespace(code) {\n    return code === null || markdownLineEnding(code) ? ok(code) : nok(code)\n  }\n}\n\nmodule.exports = partialBlankLine\n","'use strict'\n\nvar fromCharCode = require('../constant/from-char-code.js')\n\nfunction regexCheck(regex) {\n  return check\n\n  function check(code) {\n    return regex.test(fromCharCode(code))\n  }\n}\n\nmodule.exports = regexCheck\n","'use strict'\n\n// This module is copied from <https://spec.commonmark.org/0.29/#html-blocks>.\nvar basics = [\n  'address',\n  'article',\n  'aside',\n  'base',\n  'basefont',\n  'blockquote',\n  'body',\n  'caption',\n  'center',\n  'col',\n  'colgroup',\n  'dd',\n  'details',\n  'dialog',\n  'dir',\n  'div',\n  'dl',\n  'dt',\n  'fieldset',\n  'figcaption',\n  'figure',\n  'footer',\n  'form',\n  'frame',\n  'frameset',\n  'h1',\n  'h2',\n  'h3',\n  'h4',\n  'h5',\n  'h6',\n  'head',\n  'header',\n  'hr',\n  'html',\n  'iframe',\n  'legend',\n  'li',\n  'link',\n  'main',\n  'menu',\n  'menuitem',\n  'nav',\n  'noframes',\n  'ol',\n  'optgroup',\n  'option',\n  'p',\n  'param',\n  'section',\n  'source',\n  'summary',\n  'table',\n  'tbody',\n  'td',\n  'tfoot',\n  'th',\n  'thead',\n  'title',\n  'tr',\n  'track',\n  'ul'\n]\n\nmodule.exports = basics\n","'use strict'\n\nfunction markdownLineEnding(code) {\n  return code < -2\n}\n\nmodule.exports = markdownLineEnding\n","'use strict'\n\nvar chunkedSplice = require('./chunked-splice.js')\n\nfunction chunkedPush(list, items) {\n  if (list.length) {\n    chunkedSplice(list, list.length, 0, items)\n    return list\n  }\n\n  return items\n}\n\nmodule.exports = chunkedPush\n","'use strict'\n\nvar sizeChunks = require('./size-chunks.js')\n\nfunction prefixSize(events, type) {\n  var tail = events[events.length - 1]\n  if (!tail || tail[1].type !== type) return 0\n  return sizeChunks(tail[2].sliceStream(tail[1]))\n}\n\nmodule.exports = prefixSize\n","'use strict'\n\nvar markdownLineEnding = require('../character/markdown-line-ending.js')\n\nvar hardBreakEscape = {\n  name: 'hardBreakEscape',\n  tokenize: tokenizeHardBreakEscape\n}\n\nfunction tokenizeHardBreakEscape(effects, ok, nok) {\n  return start\n\n  function start(code) {\n    effects.enter('hardBreakEscape')\n    effects.enter('escapeMarker')\n    effects.consume(code)\n    return open\n  }\n\n  function open(code) {\n    if (markdownLineEnding(code)) {\n      effects.exit('escapeMarker')\n      effects.exit('hardBreakEscape')\n      return ok(code)\n    }\n\n    return nok(code)\n  }\n}\n\nmodule.exports = hardBreakEscape\n","'use strict'\n\nvar markdownSpace = require('../character/markdown-space.js')\n\nfunction spaceFactory(effects, ok, type, max) {\n  var limit = max ? max - 1 : Infinity\n  var size = 0\n  return start\n\n  function start(code) {\n    if (markdownSpace(code)) {\n      effects.enter(type)\n      return prefix(code)\n    }\n\n    return ok(code)\n  }\n\n  function prefix(code) {\n    if (markdownSpace(code) && size++ < limit) {\n      effects.consume(code)\n      return prefix\n    }\n\n    effects.exit(type)\n    return ok(code)\n  }\n}\n\nmodule.exports = spaceFactory\n","/**\n * @typedef {import('micromark-util-types').Chunk} Chunk\n * @typedef {import('micromark-util-types').Code} Code\n * @typedef {import('micromark-util-types').Encoding} Encoding\n * @typedef {import('micromark-util-types').Value} Value\n */\n\n/**\n * @callback Preprocessor\n * @param {Value} value\n * @param {Encoding | null | undefined} [encoding]\n * @param {boolean | null | undefined} [end=false]\n * @returns {Array<Chunk>}\n */\n\nconst search = /[\\0\\t\\n\\r]/g\n\n/**\n * @returns {Preprocessor}\n */\nexport function preprocess() {\n  let column = 1\n  let buffer = ''\n  /** @type {boolean | undefined} */\n  let start = true\n  /** @type {boolean | undefined} */\n  let atCarriageReturn\n  return preprocessor\n\n  /** @type {Preprocessor} */\n  function preprocessor(value, encoding, end) {\n    /** @type {Array<Chunk>} */\n    const chunks = []\n    /** @type {RegExpMatchArray | null} */\n    let match\n    /** @type {number} */\n    let next\n    /** @type {number} */\n    let startPosition\n    /** @type {number} */\n    let endPosition\n    /** @type {Code} */\n    let code\n\n    // @ts-expect-error `Buffer` does allow an encoding.\n    value = buffer + value.toString(encoding)\n    startPosition = 0\n    buffer = ''\n    if (start) {\n      // To do: `markdown-rs` actually parses BOMs (byte order mark).\n      if (value.charCodeAt(0) === 65279) {\n        startPosition++\n      }\n      start = undefined\n    }\n    while (startPosition < value.length) {\n      search.lastIndex = startPosition\n      match = search.exec(value)\n      endPosition =\n        match && match.index !== undefined ? match.index : value.length\n      code = value.charCodeAt(endPosition)\n      if (!match) {\n        buffer = value.slice(startPosition)\n        break\n      }\n      if (code === 10 && startPosition === endPosition && atCarriageReturn) {\n        chunks.push(-3)\n        atCarriageReturn = undefined\n      } else {\n        if (atCarriageReturn) {\n          chunks.push(-5)\n          atCarriageReturn = undefined\n        }\n        if (startPosition < endPosition) {\n          chunks.push(value.slice(startPosition, endPosition))\n          column += endPosition - startPosition\n        }\n        switch (code) {\n          case 0: {\n            chunks.push(65533)\n            column++\n            break\n          }\n          case 9: {\n            next = Math.ceil(column / 4) * 4\n            chunks.push(-2)\n            while (column++ < next) chunks.push(-1)\n            break\n          }\n          case 10: {\n            chunks.push(-4)\n            column = 1\n            break\n          }\n          default: {\n            atCarriageReturn = true\n            column = 1\n          }\n        }\n      }\n      startPosition = endPosition + 1\n    }\n    if (end) {\n      if (atCarriageReturn) chunks.push(-5)\n      if (buffer) chunks.push(buffer)\n      chunks.push(null)\n    }\n    return chunks\n  }\n}\n","'use strict'\n\nfunction sliceChunks(chunks, token) {\n  var startIndex = token.start._index\n  var startBufferIndex = token.start._bufferIndex\n  var endIndex = token.end._index\n  var endBufferIndex = token.end._bufferIndex\n  var view\n\n  if (startIndex === endIndex) {\n    view = [chunks[startIndex].slice(startBufferIndex, endBufferIndex)]\n  } else {\n    view = chunks.slice(startIndex, endIndex)\n\n    if (startBufferIndex > -1) {\n      view[0] = view[0].slice(startBufferIndex)\n    }\n\n    if (endBufferIndex > 0) {\n      view.push(chunks[endIndex].slice(0, endBufferIndex))\n    }\n  }\n\n  return view\n}\n\nmodule.exports = sliceChunks\n","'use strict'\n\nvar splice = require('../constant/splice.js')\n\n// causes a stack overflow in V8 when trying to insert 100k items for instance.\n\nfunction chunkedSplice(list, start, remove, items) {\n  var end = list.length\n  var chunkStart = 0\n  var parameters // Make start between zero and `end` (included).\n\n  if (start < 0) {\n    start = -start > end ? 0 : end + start\n  } else {\n    start = start > end ? end : start\n  }\n\n  remove = remove > 0 ? remove : 0 // No need to chunk the items if theres only a couple (10k) items.\n\n  if (items.length < 10000) {\n    parameters = Array.from(items)\n    parameters.unshift(start, remove)\n    splice.apply(list, parameters)\n  } else {\n    // Delete `remove` items starting from `start`\n    if (remove) splice.apply(list, [start, remove]) // Insert the items in chunks to not cause stack overflows.\n\n    while (chunkStart < items.length) {\n      parameters = items.slice(chunkStart, chunkStart + 10000)\n      parameters.unshift(start, 0)\n      splice.apply(list, parameters)\n      chunkStart += 10000\n      start += 10000\n    }\n  }\n}\n\nmodule.exports = chunkedSplice\n","'use strict'\n\n// Note: EOF is seen as ASCII control here, because `null < 32 == true`.\nfunction asciiControl(code) {\n  return (\n    // Special whitespace codes (which have negative values), C0 and Control\n    // character DEL\n    code < 32 || code === 127\n  )\n}\n\nmodule.exports = asciiControl\n","'use strict'\n\nvar decodeEntity = require('parse-entities/decode-entity.js')\nvar asciiAlphanumeric = require('../character/ascii-alphanumeric.js')\nvar asciiDigit = require('../character/ascii-digit.js')\nvar asciiHexDigit = require('../character/ascii-hex-digit.js')\n\nfunction _interopDefaultLegacy(e) {\n  return e && typeof e === 'object' && 'default' in e ? e : {default: e}\n}\n\nvar decodeEntity__default = /*#__PURE__*/ _interopDefaultLegacy(decodeEntity)\n\nvar characterReference = {\n  name: 'characterReference',\n  tokenize: tokenizeCharacterReference\n}\n\nfunction tokenizeCharacterReference(effects, ok, nok) {\n  var self = this\n  var size = 0\n  var max\n  var test\n  return start\n\n  function start(code) {\n    effects.enter('characterReference')\n    effects.enter('characterReferenceMarker')\n    effects.consume(code)\n    effects.exit('characterReferenceMarker')\n    return open\n  }\n\n  function open(code) {\n    if (code === 35) {\n      effects.enter('characterReferenceMarkerNumeric')\n      effects.consume(code)\n      effects.exit('characterReferenceMarkerNumeric')\n      return numeric\n    }\n\n    effects.enter('characterReferenceValue')\n    max = 31\n    test = asciiAlphanumeric\n    return value(code)\n  }\n\n  function numeric(code) {\n    if (code === 88 || code === 120) {\n      effects.enter('characterReferenceMarkerHexadecimal')\n      effects.consume(code)\n      effects.exit('characterReferenceMarkerHexadecimal')\n      effects.enter('characterReferenceValue')\n      max = 6\n      test = asciiHexDigit\n      return value\n    }\n\n    effects.enter('characterReferenceValue')\n    max = 7\n    test = asciiDigit\n    return value(code)\n  }\n\n  function value(code) {\n    var token\n\n    if (code === 59 && size) {\n      token = effects.exit('characterReferenceValue')\n\n      if (\n        test === asciiAlphanumeric &&\n        !decodeEntity__default['default'](self.sliceSerialize(token))\n      ) {\n        return nok(code)\n      }\n\n      effects.enter('characterReferenceMarker')\n      effects.consume(code)\n      effects.exit('characterReferenceMarker')\n      effects.exit('characterReference')\n      return ok\n    }\n\n    if (test(code) && size++ < max) {\n      effects.consume(code)\n      return value\n    }\n\n    return nok(code)\n  }\n}\n\nmodule.exports = characterReference\n","'use strict'\n\nvar hasOwnProperty = require('../constant/has-own-property.js')\nvar chunkedSplice = require('./chunked-splice.js')\nvar miniflat = require('./miniflat.js')\n\nfunction combineExtensions(extensions) {\n  var all = {}\n  var index = -1\n\n  while (++index < extensions.length) {\n    extension(all, extensions[index])\n  }\n\n  return all\n}\n\nfunction extension(all, extension) {\n  var hook\n  var left\n  var right\n  var code\n\n  for (hook in extension) {\n    left = hasOwnProperty.call(all, hook) ? all[hook] : (all[hook] = {})\n    right = extension[hook]\n\n    for (code in right) {\n      left[code] = constructs(\n        miniflat(right[code]),\n        hasOwnProperty.call(left, code) ? left[code] : []\n      )\n    }\n  }\n}\n\nfunction constructs(list, existing) {\n  var index = -1\n  var before = []\n\n  while (++index < list.length) {\n    ;(list[index].add === 'after' ? existing : before).push(list[index])\n  }\n\n  chunkedSplice(existing, 0, 0, before)\n  return existing\n}\n\nmodule.exports = combineExtensions\n","'use strict'\n\nvar markdownLineEnding = require('../character/markdown-line-ending.js')\nvar prefixSize = require('../util/prefix-size.js')\nvar subtokenize = require('../util/subtokenize.js')\nvar factorySpace = require('./factory-space.js')\n\n// No name because it must not be turned off.\nvar content = {\n  tokenize: tokenizeContent,\n  resolve: resolveContent,\n  interruptible: true,\n  lazy: true\n}\nvar continuationConstruct = {\n  tokenize: tokenizeContinuation,\n  partial: true\n} // Content is transparent: its parsed right now. That way, definitions are also\n// parsed right now: before text in paragraphs (specifically, media) are parsed.\n\nfunction resolveContent(events) {\n  subtokenize(events)\n  return events\n}\n\nfunction tokenizeContent(effects, ok) {\n  var previous\n  return start\n\n  function start(code) {\n    effects.enter('content')\n    previous = effects.enter('chunkContent', {\n      contentType: 'content'\n    })\n    return data(code)\n  }\n\n  function data(code) {\n    if (code === null) {\n      return contentEnd(code)\n    }\n\n    if (markdownLineEnding(code)) {\n      return effects.check(\n        continuationConstruct,\n        contentContinue,\n        contentEnd\n      )(code)\n    } // Data.\n\n    effects.consume(code)\n    return data\n  }\n\n  function contentEnd(code) {\n    effects.exit('chunkContent')\n    effects.exit('content')\n    return ok(code)\n  }\n\n  function contentContinue(code) {\n    effects.consume(code)\n    effects.exit('chunkContent')\n    previous = previous.next = effects.enter('chunkContent', {\n      contentType: 'content',\n      previous: previous\n    })\n    return data\n  }\n}\n\nfunction tokenizeContinuation(effects, ok, nok) {\n  var self = this\n  return startLookahead\n\n  function startLookahead(code) {\n    effects.enter('lineEnding')\n    effects.consume(code)\n    effects.exit('lineEnding')\n    return factorySpace(effects, prefixed, 'linePrefix')\n  }\n\n  function prefixed(code) {\n    if (code === null || markdownLineEnding(code)) {\n      return nok(code)\n    }\n\n    if (\n      self.parser.constructs.disable.null.indexOf('codeIndented') > -1 ||\n      prefixSize(self.events, 'linePrefix') < 4\n    ) {\n      return effects.interrupt(self.parser.constructs.flow, nok, ok)(code)\n    }\n\n    return ok(code)\n  }\n}\n\nmodule.exports = content\n","'use strict'\n\n// Counts tabs based on their expanded size, and CR+LF as one character.\n\nfunction sizeChunks(chunks) {\n  var index = -1\n  var size = 0\n\n  while (++index < chunks.length) {\n    size += typeof chunks[index] === 'string' ? chunks[index].length : 1\n  }\n\n  return size\n}\n\nmodule.exports = sizeChunks\n","'use strict'\n\nvar own = {}.hasOwnProperty\n\nmodule.exports = own\n","'use strict'\n\nvar regexCheck = require('../util/regex-check.js')\n\nvar asciiAtext = regexCheck(/[#-'*+\\--9=?A-Z^-~]/)\n\nmodule.exports = asciiAtext\n","'use strict'\n\nvar asciiDigit = require('../character/ascii-digit.js')\nvar markdownSpace = require('../character/markdown-space.js')\nvar prefixSize = require('../util/prefix-size.js')\nvar sizeChunks = require('../util/size-chunks.js')\nvar factorySpace = require('./factory-space.js')\nvar partialBlankLine = require('./partial-blank-line.js')\nvar thematicBreak = require('./thematic-break.js')\n\nvar list = {\n  name: 'list',\n  tokenize: tokenizeListStart,\n  continuation: {\n    tokenize: tokenizeListContinuation\n  },\n  exit: tokenizeListEnd\n}\nvar listItemPrefixWhitespaceConstruct = {\n  tokenize: tokenizeListItemPrefixWhitespace,\n  partial: true\n}\nvar indentConstruct = {\n  tokenize: tokenizeIndent,\n  partial: true\n}\n\nfunction tokenizeListStart(effects, ok, nok) {\n  var self = this\n  var initialSize = prefixSize(self.events, 'linePrefix')\n  var size = 0\n  return start\n\n  function start(code) {\n    var kind =\n      self.containerState.type ||\n      (code === 42 || code === 43 || code === 45\n        ? 'listUnordered'\n        : 'listOrdered')\n\n    if (\n      kind === 'listUnordered'\n        ? !self.containerState.marker || code === self.containerState.marker\n        : asciiDigit(code)\n    ) {\n      if (!self.containerState.type) {\n        self.containerState.type = kind\n        effects.enter(kind, {\n          _container: true\n        })\n      }\n\n      if (kind === 'listUnordered') {\n        effects.enter('listItemPrefix')\n        return code === 42 || code === 45\n          ? effects.check(thematicBreak, nok, atMarker)(code)\n          : atMarker(code)\n      }\n\n      if (!self.interrupt || code === 49) {\n        effects.enter('listItemPrefix')\n        effects.enter('listItemValue')\n        return inside(code)\n      }\n    }\n\n    return nok(code)\n  }\n\n  function inside(code) {\n    if (asciiDigit(code) && ++size < 10) {\n      effects.consume(code)\n      return inside\n    }\n\n    if (\n      (!self.interrupt || size < 2) &&\n      (self.containerState.marker\n        ? code === self.containerState.marker\n        : code === 41 || code === 46)\n    ) {\n      effects.exit('listItemValue')\n      return atMarker(code)\n    }\n\n    return nok(code)\n  }\n\n  function atMarker(code) {\n    effects.enter('listItemMarker')\n    effects.consume(code)\n    effects.exit('listItemMarker')\n    self.containerState.marker = self.containerState.marker || code\n    return effects.check(\n      partialBlankLine, // Cant be empty when interrupting.\n      self.interrupt ? nok : onBlank,\n      effects.attempt(\n        listItemPrefixWhitespaceConstruct,\n        endOfPrefix,\n        otherPrefix\n      )\n    )\n  }\n\n  function onBlank(code) {\n    self.containerState.initialBlankLine = true\n    initialSize++\n    return endOfPrefix(code)\n  }\n\n  function otherPrefix(code) {\n    if (markdownSpace(code)) {\n      effects.enter('listItemPrefixWhitespace')\n      effects.consume(code)\n      effects.exit('listItemPrefixWhitespace')\n      return endOfPrefix\n    }\n\n    return nok(code)\n  }\n\n  function endOfPrefix(code) {\n    self.containerState.size =\n      initialSize + sizeChunks(self.sliceStream(effects.exit('listItemPrefix')))\n    return ok(code)\n  }\n}\n\nfunction tokenizeListContinuation(effects, ok, nok) {\n  var self = this\n  self.containerState._closeFlow = undefined\n  return effects.check(partialBlankLine, onBlank, notBlank)\n\n  function onBlank(code) {\n    self.containerState.furtherBlankLines =\n      self.containerState.furtherBlankLines ||\n      self.containerState.initialBlankLine // We have a blank line.\n    // Still, try to consume at most the items size.\n\n    return factorySpace(\n      effects,\n      ok,\n      'listItemIndent',\n      self.containerState.size + 1\n    )(code)\n  }\n\n  function notBlank(code) {\n    if (self.containerState.furtherBlankLines || !markdownSpace(code)) {\n      self.containerState.furtherBlankLines = self.containerState.initialBlankLine = undefined\n      return notInCurrentItem(code)\n    }\n\n    self.containerState.furtherBlankLines = self.containerState.initialBlankLine = undefined\n    return effects.attempt(indentConstruct, ok, notInCurrentItem)(code)\n  }\n\n  function notInCurrentItem(code) {\n    // While we do continue, we signal that the flow should be closed.\n    self.containerState._closeFlow = true // As were closing flow, were no longer interrupting.\n\n    self.interrupt = undefined\n    return factorySpace(\n      effects,\n      effects.attempt(list, ok, nok),\n      'linePrefix',\n      self.parser.constructs.disable.null.indexOf('codeIndented') > -1\n        ? undefined\n        : 4\n    )(code)\n  }\n}\n\nfunction tokenizeIndent(effects, ok, nok) {\n  var self = this\n  return factorySpace(\n    effects,\n    afterPrefix,\n    'listItemIndent',\n    self.containerState.size + 1\n  )\n\n  function afterPrefix(code) {\n    return prefixSize(self.events, 'listItemIndent') ===\n      self.containerState.size\n      ? ok(code)\n      : nok(code)\n  }\n}\n\nfunction tokenizeListEnd(effects) {\n  effects.exit(this.containerState.type)\n}\n\nfunction tokenizeListItemPrefixWhitespace(effects, ok, nok) {\n  var self = this\n  return factorySpace(\n    effects,\n    afterPrefix,\n    'listItemPrefixWhitespace',\n    self.parser.constructs.disable.null.indexOf('codeIndented') > -1\n      ? undefined\n      : 4 + 1\n  )\n\n  function afterPrefix(code) {\n    return markdownSpace(code) ||\n      !prefixSize(self.events, 'listItemPrefixWhitespace')\n      ? nok(code)\n      : ok(code)\n  }\n}\n\nmodule.exports = list\n","'use strict'\n\nObject.defineProperty(exports, '__esModule', {value: true})\n\nvar text$1 = require('./initialize/text.js')\nvar attention = require('./tokenize/attention.js')\nvar autolink = require('./tokenize/autolink.js')\nvar blockQuote = require('./tokenize/block-quote.js')\nvar characterEscape = require('./tokenize/character-escape.js')\nvar characterReference = require('./tokenize/character-reference.js')\nvar codeFenced = require('./tokenize/code-fenced.js')\nvar codeIndented = require('./tokenize/code-indented.js')\nvar codeText = require('./tokenize/code-text.js')\nvar definition = require('./tokenize/definition.js')\nvar hardBreakEscape = require('./tokenize/hard-break-escape.js')\nvar headingAtx = require('./tokenize/heading-atx.js')\nvar htmlFlow = require('./tokenize/html-flow.js')\nvar htmlText = require('./tokenize/html-text.js')\nvar labelEnd = require('./tokenize/label-end.js')\nvar labelStartImage = require('./tokenize/label-start-image.js')\nvar labelStartLink = require('./tokenize/label-start-link.js')\nvar lineEnding = require('./tokenize/line-ending.js')\nvar list = require('./tokenize/list.js')\nvar setextUnderline = require('./tokenize/setext-underline.js')\nvar thematicBreak = require('./tokenize/thematic-break.js')\n\nvar document = {\n  42: list,\n  // Asterisk\n  43: list,\n  // Plus sign\n  45: list,\n  // Dash\n  48: list,\n  // 0\n  49: list,\n  // 1\n  50: list,\n  // 2\n  51: list,\n  // 3\n  52: list,\n  // 4\n  53: list,\n  // 5\n  54: list,\n  // 6\n  55: list,\n  // 7\n  56: list,\n  // 8\n  57: list,\n  // 9\n  62: blockQuote // Greater than\n}\nvar contentInitial = {\n  91: definition // Left square bracket\n}\nvar flowInitial = {\n  '-2': codeIndented,\n  // Horizontal tab\n  '-1': codeIndented,\n  // Virtual space\n  32: codeIndented // Space\n}\nvar flow = {\n  35: headingAtx,\n  // Number sign\n  42: thematicBreak,\n  // Asterisk\n  45: [setextUnderline, thematicBreak],\n  // Dash\n  60: htmlFlow,\n  // Less than\n  61: setextUnderline,\n  // Equals to\n  95: thematicBreak,\n  // Underscore\n  96: codeFenced,\n  // Grave accent\n  126: codeFenced // Tilde\n}\nvar string = {\n  38: characterReference,\n  // Ampersand\n  92: characterEscape // Backslash\n}\nvar text = {\n  '-5': lineEnding,\n  // Carriage return\n  '-4': lineEnding,\n  // Line feed\n  '-3': lineEnding,\n  // Carriage return + line feed\n  33: labelStartImage,\n  // Exclamation mark\n  38: characterReference,\n  // Ampersand\n  42: attention,\n  // Asterisk\n  60: [autolink, htmlText],\n  // Less than\n  91: labelStartLink,\n  // Left square bracket\n  92: [hardBreakEscape, characterEscape],\n  // Backslash\n  93: labelEnd,\n  // Right square bracket\n  95: attention,\n  // Underscore\n  96: codeText // Grave accent\n}\nvar insideSpan = {\n  null: [attention, text$1.resolver]\n}\nvar disable = {\n  null: []\n}\n\nexports.contentInitial = contentInitial\nexports.disable = disable\nexports.document = document\nexports.flow = flow\nexports.flowInitial = flowInitial\nexports.insideSpan = insideSpan\nexports.string = string\nexports.text = text\n","'use strict'\n\nvar markdownLineEnding = require('../character/markdown-line-ending.js')\nvar markdownSpace = require('../character/markdown-space.js')\n\n// eslint-disable-next-line max-params\nfunction labelFactory(effects, ok, nok, type, markerType, stringType) {\n  var self = this\n  var size = 0\n  var data\n  return start\n\n  function start(code) {\n    effects.enter(type)\n    effects.enter(markerType)\n    effects.consume(code)\n    effects.exit(markerType)\n    effects.enter(stringType)\n    return atBreak\n  }\n\n  function atBreak(code) {\n    if (\n      code === null ||\n      code === 91 ||\n      (code === 93 && !data) ||\n      /* c8 ignore next */\n      (code === 94 &&\n        /* c8 ignore next */\n        !size &&\n        /* c8 ignore next */\n        '_hiddenFootnoteSupport' in self.parser.constructs) ||\n      size > 999\n    ) {\n      return nok(code)\n    }\n\n    if (code === 93) {\n      effects.exit(stringType)\n      effects.enter(markerType)\n      effects.consume(code)\n      effects.exit(markerType)\n      effects.exit(type)\n      return ok\n    }\n\n    if (markdownLineEnding(code)) {\n      effects.enter('lineEnding')\n      effects.consume(code)\n      effects.exit('lineEnding')\n      return atBreak\n    }\n\n    effects.enter('chunkString', {\n      contentType: 'string'\n    })\n    return label(code)\n  }\n\n  function label(code) {\n    if (\n      code === null ||\n      code === 91 ||\n      code === 93 ||\n      markdownLineEnding(code) ||\n      size++ > 999\n    ) {\n      effects.exit('chunkString')\n      return atBreak(code)\n    }\n\n    effects.consume(code)\n    data = data || !markdownSpace(code)\n    return code === 92 ? labelEscape : label\n  }\n\n  function labelEscape(code) {\n    if (code === 91 || code === 92 || code === 93) {\n      effects.consume(code)\n      size++\n      return label\n    }\n\n    return label(code)\n  }\n}\n\nmodule.exports = labelFactory\n","'use strict'\n\nvar regexCheck = require('../util/regex-check.js')\n\nvar asciiPunctuation = regexCheck(/[!-/:-@[-`{-~]/)\n\nmodule.exports = asciiPunctuation\n","'use strict'\n\nvar regexCheck = require('../util/regex-check.js')\n\nvar asciiAlphanumeric = regexCheck(/[\\dA-Za-z]/)\n\nmodule.exports = asciiAlphanumeric\n","/**\n * @typedef {import('micromark-util-types').Event} Event\n */\n\nimport {subtokenize} from 'micromark-util-subtokenize'\n\n/**\n * @param {Array<Event>} events\n * @returns {Array<Event>}\n */\nexport function postprocess(events) {\n  while (!subtokenize(events)) {\n    // Empty\n  }\n  return events\n}\n","'use strict'\n\nvar markdownLineEnding = require('../character/markdown-line-ending.js')\nvar markdownLineEndingOrSpace = require('../character/markdown-line-ending-or-space.js')\nvar normalizeIdentifier = require('../util/normalize-identifier.js')\nvar factoryDestination = require('./factory-destination.js')\nvar factoryLabel = require('./factory-label.js')\nvar factorySpace = require('./factory-space.js')\nvar factoryWhitespace = require('./factory-whitespace.js')\nvar factoryTitle = require('./factory-title.js')\n\nvar definition = {\n  name: 'definition',\n  tokenize: tokenizeDefinition\n}\nvar titleConstruct = {\n  tokenize: tokenizeTitle,\n  partial: true\n}\n\nfunction tokenizeDefinition(effects, ok, nok) {\n  var self = this\n  var identifier\n  return start\n\n  function start(code) {\n    effects.enter('definition')\n    return factoryLabel.call(\n      self,\n      effects,\n      labelAfter,\n      nok,\n      'definitionLabel',\n      'definitionLabelMarker',\n      'definitionLabelString'\n    )(code)\n  }\n\n  function labelAfter(code) {\n    identifier = normalizeIdentifier(\n      self.sliceSerialize(self.events[self.events.length - 1][1]).slice(1, -1)\n    )\n\n    if (code === 58) {\n      effects.enter('definitionMarker')\n      effects.consume(code)\n      effects.exit('definitionMarker') // Note: blank lines cant exist in content.\n\n      return factoryWhitespace(\n        effects,\n        factoryDestination(\n          effects,\n          effects.attempt(\n            titleConstruct,\n            factorySpace(effects, after, 'whitespace'),\n            factorySpace(effects, after, 'whitespace')\n          ),\n          nok,\n          'definitionDestination',\n          'definitionDestinationLiteral',\n          'definitionDestinationLiteralMarker',\n          'definitionDestinationRaw',\n          'definitionDestinationString'\n        )\n      )\n    }\n\n    return nok(code)\n  }\n\n  function after(code) {\n    if (code === null || markdownLineEnding(code)) {\n      effects.exit('definition')\n\n      if (self.parser.defined.indexOf(identifier) < 0) {\n        self.parser.defined.push(identifier)\n      }\n\n      return ok(code)\n    }\n\n    return nok(code)\n  }\n}\n\nfunction tokenizeTitle(effects, ok, nok) {\n  return start\n\n  function start(code) {\n    return markdownLineEndingOrSpace(code)\n      ? factoryWhitespace(effects, before)(code)\n      : nok(code)\n  }\n\n  function before(code) {\n    if (code === 34 || code === 39 || code === 40) {\n      return factoryTitle(\n        effects,\n        factorySpace(effects, after, 'whitespace'),\n        nok,\n        'definitionTitle',\n        'definitionTitleMarker',\n        'definitionTitleString'\n      )(code)\n    }\n\n    return nok(code)\n  }\n\n  function after(code) {\n    return code === null || markdownLineEnding(code) ? ok(code) : nok(code)\n  }\n}\n\nmodule.exports = definition\n","'use strict'\n\nvar regexCheck = require('../util/regex-check.js')\n\nvar unicodeWhitespace = regexCheck(/\\s/)\n\nmodule.exports = unicodeWhitespace\n","'use strict'\n\nvar fromCharCode = require('../constant/from-char-code.js')\n\nfunction serializeChunks(chunks) {\n  var index = -1\n  var result = []\n  var chunk\n  var value\n  var atTab\n\n  while (++index < chunks.length) {\n    chunk = chunks[index]\n\n    if (typeof chunk === 'string') {\n      value = chunk\n    } else if (chunk === -5) {\n      value = '\\r'\n    } else if (chunk === -4) {\n      value = '\\n'\n    } else if (chunk === -3) {\n      value = '\\r' + '\\n'\n    } else if (chunk === -2) {\n      value = '\\t'\n    } else if (chunk === -1) {\n      if (atTab) continue\n      value = ' '\n    } else {\n      // Currently only replacement character.\n      value = fromCharCode(chunk)\n    }\n\n    atTab = chunk === -2\n    result.push(value)\n  }\n\n  return result.join('')\n}\n\nmodule.exports = serializeChunks\n","'use strict'\n\nvar search = /[\\0\\t\\n\\r]/g\n\nfunction preprocess() {\n  var start = true\n  var column = 1\n  var buffer = ''\n  var atCarriageReturn\n  return preprocessor\n\n  function preprocessor(value, encoding, end) {\n    var chunks = []\n    var match\n    var next\n    var startPosition\n    var endPosition\n    var code\n    value = buffer + value.toString(encoding)\n    startPosition = 0\n    buffer = ''\n\n    if (start) {\n      if (value.charCodeAt(0) === 65279) {\n        startPosition++\n      }\n\n      start = undefined\n    }\n\n    while (startPosition < value.length) {\n      search.lastIndex = startPosition\n      match = search.exec(value)\n      endPosition = match ? match.index : value.length\n      code = value.charCodeAt(endPosition)\n\n      if (!match) {\n        buffer = value.slice(startPosition)\n        break\n      }\n\n      if (code === 10 && startPosition === endPosition && atCarriageReturn) {\n        chunks.push(-3)\n        atCarriageReturn = undefined\n      } else {\n        if (atCarriageReturn) {\n          chunks.push(-5)\n          atCarriageReturn = undefined\n        }\n\n        if (startPosition < endPosition) {\n          chunks.push(value.slice(startPosition, endPosition))\n          column += endPosition - startPosition\n        }\n\n        if (code === 0) {\n          chunks.push(65533)\n          column++\n        } else if (code === 9) {\n          next = Math.ceil(column / 4) * 4\n          chunks.push(-2)\n\n          while (column++ < next) chunks.push(-1)\n        } else if (code === 10) {\n          chunks.push(-4)\n          column = 1\n        } // Must be carriage return.\n        else {\n          atCarriageReturn = true\n          column = 1\n        }\n      }\n\n      startPosition = endPosition + 1\n    }\n\n    if (end) {\n      if (atCarriageReturn) chunks.push(-5)\n      if (buffer) chunks.push(buffer)\n      chunks.push(null)\n    }\n\n    return chunks\n  }\n}\n\nmodule.exports = preprocess\n","'use strict'\n\nvar markdownLineEnding = require('../character/markdown-line-ending.js')\n\nvar codeText = {\n  name: 'codeText',\n  tokenize: tokenizeCodeText,\n  resolve: resolveCodeText,\n  previous: previous\n}\n\nfunction resolveCodeText(events) {\n  var tailExitIndex = events.length - 4\n  var headEnterIndex = 3\n  var index\n  var enter // If we start and end with an EOL or a space.\n\n  if (\n    (events[headEnterIndex][1].type === 'lineEnding' ||\n      events[headEnterIndex][1].type === 'space') &&\n    (events[tailExitIndex][1].type === 'lineEnding' ||\n      events[tailExitIndex][1].type === 'space')\n  ) {\n    index = headEnterIndex // And we have data.\n\n    while (++index < tailExitIndex) {\n      if (events[index][1].type === 'codeTextData') {\n        // Then we have padding.\n        events[tailExitIndex][1].type = events[headEnterIndex][1].type =\n          'codeTextPadding'\n        headEnterIndex += 2\n        tailExitIndex -= 2\n        break\n      }\n    }\n  } // Merge adjacent spaces and data.\n\n  index = headEnterIndex - 1\n  tailExitIndex++\n\n  while (++index <= tailExitIndex) {\n    if (enter === undefined) {\n      if (index !== tailExitIndex && events[index][1].type !== 'lineEnding') {\n        enter = index\n      }\n    } else if (\n      index === tailExitIndex ||\n      events[index][1].type === 'lineEnding'\n    ) {\n      events[enter][1].type = 'codeTextData'\n\n      if (index !== enter + 2) {\n        events[enter][1].end = events[index - 1][1].end\n        events.splice(enter + 2, index - enter - 2)\n        tailExitIndex -= index - enter - 2\n        index = enter + 2\n      }\n\n      enter = undefined\n    }\n  }\n\n  return events\n}\n\nfunction previous(code) {\n  // If there is a previous code, there will always be a tail.\n  return (\n    code !== 96 ||\n    this.events[this.events.length - 1][1].type === 'characterEscape'\n  )\n}\n\nfunction tokenizeCodeText(effects, ok, nok) {\n  var sizeOpen = 0\n  var size\n  var token\n  return start\n\n  function start(code) {\n    effects.enter('codeText')\n    effects.enter('codeTextSequence')\n    return openingSequence(code)\n  }\n\n  function openingSequence(code) {\n    if (code === 96) {\n      effects.consume(code)\n      sizeOpen++\n      return openingSequence\n    }\n\n    effects.exit('codeTextSequence')\n    return gap(code)\n  }\n\n  function gap(code) {\n    // EOF.\n    if (code === null) {\n      return nok(code)\n    } // Closing fence?\n    // Could also be data.\n\n    if (code === 96) {\n      token = effects.enter('codeTextSequence')\n      size = 0\n      return closingSequence(code)\n    } // Tabs dont work, and virtual spaces dont make sense.\n\n    if (code === 32) {\n      effects.enter('space')\n      effects.consume(code)\n      effects.exit('space')\n      return gap\n    }\n\n    if (markdownLineEnding(code)) {\n      effects.enter('lineEnding')\n      effects.consume(code)\n      effects.exit('lineEnding')\n      return gap\n    } // Data.\n\n    effects.enter('codeTextData')\n    return data(code)\n  } // In code.\n\n  function data(code) {\n    if (\n      code === null ||\n      code === 32 ||\n      code === 96 ||\n      markdownLineEnding(code)\n    ) {\n      effects.exit('codeTextData')\n      return gap(code)\n    }\n\n    effects.consume(code)\n    return data\n  } // Closing fence.\n\n  function closingSequence(code) {\n    // More.\n    if (code === 96) {\n      effects.consume(code)\n      size++\n      return closingSequence\n    } // Done!\n\n    if (size === sizeOpen) {\n      effects.exit('codeTextSequence')\n      effects.exit('codeText')\n      return ok(code)\n    } // More or less accents: mark as data.\n\n    token.type = 'codeTextData'\n    return data(code)\n  }\n}\n\nmodule.exports = codeText\n","'use strict'\n\nvar asciiControl = require('../character/ascii-control.js')\nvar markdownLineEndingOrSpace = require('../character/markdown-line-ending-or-space.js')\nvar markdownLineEnding = require('../character/markdown-line-ending.js')\n\n// eslint-disable-next-line max-params\nfunction destinationFactory(\n  effects,\n  ok,\n  nok,\n  type,\n  literalType,\n  literalMarkerType,\n  rawType,\n  stringType,\n  max\n) {\n  var limit = max || Infinity\n  var balance = 0\n  return start\n\n  function start(code) {\n    if (code === 60) {\n      effects.enter(type)\n      effects.enter(literalType)\n      effects.enter(literalMarkerType)\n      effects.consume(code)\n      effects.exit(literalMarkerType)\n      return destinationEnclosedBefore\n    }\n\n    if (asciiControl(code) || code === 41) {\n      return nok(code)\n    }\n\n    effects.enter(type)\n    effects.enter(rawType)\n    effects.enter(stringType)\n    effects.enter('chunkString', {\n      contentType: 'string'\n    })\n    return destinationRaw(code)\n  }\n\n  function destinationEnclosedBefore(code) {\n    if (code === 62) {\n      effects.enter(literalMarkerType)\n      effects.consume(code)\n      effects.exit(literalMarkerType)\n      effects.exit(literalType)\n      effects.exit(type)\n      return ok\n    }\n\n    effects.enter(stringType)\n    effects.enter('chunkString', {\n      contentType: 'string'\n    })\n    return destinationEnclosed(code)\n  }\n\n  function destinationEnclosed(code) {\n    if (code === 62) {\n      effects.exit('chunkString')\n      effects.exit(stringType)\n      return destinationEnclosedBefore(code)\n    }\n\n    if (code === null || code === 60 || markdownLineEnding(code)) {\n      return nok(code)\n    }\n\n    effects.consume(code)\n    return code === 92 ? destinationEnclosedEscape : destinationEnclosed\n  }\n\n  function destinationEnclosedEscape(code) {\n    if (code === 60 || code === 62 || code === 92) {\n      effects.consume(code)\n      return destinationEnclosed\n    }\n\n    return destinationEnclosed(code)\n  }\n\n  function destinationRaw(code) {\n    if (code === 40) {\n      if (++balance > limit) return nok(code)\n      effects.consume(code)\n      return destinationRaw\n    }\n\n    if (code === 41) {\n      if (!balance--) {\n        effects.exit('chunkString')\n        effects.exit(stringType)\n        effects.exit(rawType)\n        effects.exit(type)\n        return ok(code)\n      }\n\n      effects.consume(code)\n      return destinationRaw\n    }\n\n    if (code === null || markdownLineEndingOrSpace(code)) {\n      if (balance) return nok(code)\n      effects.exit('chunkString')\n      effects.exit(stringType)\n      effects.exit(rawType)\n      effects.exit(type)\n      return ok(code)\n    }\n\n    if (asciiControl(code)) return nok(code)\n    effects.consume(code)\n    return code === 92 ? destinationRawEscape : destinationRaw\n  }\n\n  function destinationRawEscape(code) {\n    if (code === 40 || code === 41 || code === 92) {\n      effects.consume(code)\n      return destinationRaw\n    }\n\n    return destinationRaw(code)\n  }\n}\n\nmodule.exports = destinationFactory\n","'use strict'\n\nObject.defineProperty(exports, '__esModule', {value: true})\n\nvar assign = require('../constant/assign.js')\nvar shallow = require('../util/shallow.js')\n\nvar text = initializeFactory('text')\nvar string = initializeFactory('string')\nvar resolver = {\n  resolveAll: createResolver()\n}\n\nfunction initializeFactory(field) {\n  return {\n    tokenize: initializeText,\n    resolveAll: createResolver(\n      field === 'text' ? resolveAllLineSuffixes : undefined\n    )\n  }\n\n  function initializeText(effects) {\n    var self = this\n    var constructs = this.parser.constructs[field]\n    var text = effects.attempt(constructs, start, notText)\n    return start\n\n    function start(code) {\n      return atBreak(code) ? text(code) : notText(code)\n    }\n\n    function notText(code) {\n      if (code === null) {\n        effects.consume(code)\n        return\n      }\n\n      effects.enter('data')\n      effects.consume(code)\n      return data\n    }\n\n    function data(code) {\n      if (atBreak(code)) {\n        effects.exit('data')\n        return text(code)\n      } // Data.\n\n      effects.consume(code)\n      return data\n    }\n\n    function atBreak(code) {\n      var list = constructs[code]\n      var index = -1\n\n      if (code === null) {\n        return true\n      }\n\n      if (list) {\n        while (++index < list.length) {\n          if (\n            !list[index].previous ||\n            list[index].previous.call(self, self.previous)\n          ) {\n            return true\n          }\n        }\n      }\n    }\n  }\n}\n\nfunction createResolver(extraResolver) {\n  return resolveAllText\n\n  function resolveAllText(events, context) {\n    var index = -1\n    var enter // A rather boring computation (to merge adjacent `data` events) which\n    // improves mm performance by 29%.\n\n    while (++index <= events.length) {\n      if (enter === undefined) {\n        if (events[index] && events[index][1].type === 'data') {\n          enter = index\n          index++\n        }\n      } else if (!events[index] || events[index][1].type !== 'data') {\n        // Dont do anything if there is one data token.\n        if (index !== enter + 2) {\n          events[enter][1].end = events[index - 1][1].end\n          events.splice(enter + 2, index - enter - 2)\n          index = enter + 2\n        }\n\n        enter = undefined\n      }\n    }\n\n    return extraResolver ? extraResolver(events, context) : events\n  }\n} // A rather ugly set of instructions which again looks at chunks in the input\n// stream.\n// The reason to do this here is that it is *much* faster to parse in reverse.\n// And that we cant hook into `null` to split the line suffix before an EOF.\n// To do: figure out if we can make this into a clean utility, or even in core.\n// As it will be useful for GFMs literal autolink extension (and maybe even\n// tables?)\n\nfunction resolveAllLineSuffixes(events, context) {\n  var eventIndex = -1\n  var chunks\n  var data\n  var chunk\n  var index\n  var bufferIndex\n  var size\n  var tabs\n  var token\n\n  while (++eventIndex <= events.length) {\n    if (\n      (eventIndex === events.length ||\n        events[eventIndex][1].type === 'lineEnding') &&\n      events[eventIndex - 1][1].type === 'data'\n    ) {\n      data = events[eventIndex - 1][1]\n      chunks = context.sliceStream(data)\n      index = chunks.length\n      bufferIndex = -1\n      size = 0\n      tabs = undefined\n\n      while (index--) {\n        chunk = chunks[index]\n\n        if (typeof chunk === 'string') {\n          bufferIndex = chunk.length\n\n          while (chunk.charCodeAt(bufferIndex - 1) === 32) {\n            size++\n            bufferIndex--\n          }\n\n          if (bufferIndex) break\n          bufferIndex = -1\n        } // Number\n        else if (chunk === -2) {\n          tabs = true\n          size++\n        } else if (chunk === -1);\n        else {\n          // Replacement character, exit.\n          index++\n          break\n        }\n      }\n\n      if (size) {\n        token = {\n          type:\n            eventIndex === events.length || tabs || size < 2\n              ? 'lineSuffix'\n              : 'hardBreakTrailing',\n          start: {\n            line: data.end.line,\n            column: data.end.column - size,\n            offset: data.end.offset - size,\n            _index: data.start._index + index,\n            _bufferIndex: index\n              ? bufferIndex\n              : data.start._bufferIndex + bufferIndex\n          },\n          end: shallow(data.end)\n        }\n        data.end = shallow(token.start)\n\n        if (data.start.offset === data.end.offset) {\n          assign(data, token)\n        } else {\n          events.splice(\n            eventIndex,\n            0,\n            ['enter', token, context],\n            ['exit', token, context]\n          )\n          eventIndex += 2\n        }\n      }\n\n      eventIndex++\n    }\n  }\n\n  return events\n}\n\nexports.resolver = resolver\nexports.string = string\nexports.text = text\n","'use strict'\n\nvar regexCheck = require('../util/regex-check.js')\n\nvar asciiAlpha = regexCheck(/[A-Za-z]/)\n\nmodule.exports = asciiAlpha\n","'use strict'\n\nvar assign = require('../constant/assign.js')\nvar chunkedSplice = require('./chunked-splice.js')\nvar shallow = require('./shallow.js')\n\nfunction subtokenize(events) {\n  var jumps = {}\n  var index = -1\n  var event\n  var lineIndex\n  var otherIndex\n  var otherEvent\n  var parameters\n  var subevents\n  var more\n\n  while (++index < events.length) {\n    while (index in jumps) {\n      index = jumps[index]\n    }\n\n    event = events[index] // Add a hook for the GFM tasklist extension, which needs to know if text\n    // is in the first content of a list item.\n\n    if (\n      index &&\n      event[1].type === 'chunkFlow' &&\n      events[index - 1][1].type === 'listItemPrefix'\n    ) {\n      subevents = event[1]._tokenizer.events\n      otherIndex = 0\n\n      if (\n        otherIndex < subevents.length &&\n        subevents[otherIndex][1].type === 'lineEndingBlank'\n      ) {\n        otherIndex += 2\n      }\n\n      if (\n        otherIndex < subevents.length &&\n        subevents[otherIndex][1].type === 'content'\n      ) {\n        while (++otherIndex < subevents.length) {\n          if (subevents[otherIndex][1].type === 'content') {\n            break\n          }\n\n          if (subevents[otherIndex][1].type === 'chunkText') {\n            subevents[otherIndex][1].isInFirstContentOfListItem = true\n            otherIndex++\n          }\n        }\n      }\n    } // Enter.\n\n    if (event[0] === 'enter') {\n      if (event[1].contentType) {\n        assign(jumps, subcontent(events, index))\n        index = jumps[index]\n        more = true\n      }\n    } // Exit.\n    else if (event[1]._container || event[1]._movePreviousLineEndings) {\n      otherIndex = index\n      lineIndex = undefined\n\n      while (otherIndex--) {\n        otherEvent = events[otherIndex]\n\n        if (\n          otherEvent[1].type === 'lineEnding' ||\n          otherEvent[1].type === 'lineEndingBlank'\n        ) {\n          if (otherEvent[0] === 'enter') {\n            if (lineIndex) {\n              events[lineIndex][1].type = 'lineEndingBlank'\n            }\n\n            otherEvent[1].type = 'lineEnding'\n            lineIndex = otherIndex\n          }\n        } else {\n          break\n        }\n      }\n\n      if (lineIndex) {\n        // Fix position.\n        event[1].end = shallow(events[lineIndex][1].start) // Switch container exit w/ line endings.\n\n        parameters = events.slice(lineIndex, index)\n        parameters.unshift(event)\n        chunkedSplice(events, lineIndex, index - lineIndex + 1, parameters)\n      }\n    }\n  }\n\n  return !more\n}\n\nfunction subcontent(events, eventIndex) {\n  var token = events[eventIndex][1]\n  var context = events[eventIndex][2]\n  var startPosition = eventIndex - 1\n  var startPositions = []\n  var tokenizer =\n    token._tokenizer || context.parser[token.contentType](token.start)\n  var childEvents = tokenizer.events\n  var jumps = []\n  var gaps = {}\n  var stream\n  var previous\n  var index\n  var entered\n  var end\n  var adjust // Loop forward through the linked tokens to pass them in order to the\n  // subtokenizer.\n\n  while (token) {\n    // Find the position of the event for this token.\n    while (events[++startPosition][1] !== token) {\n      // Empty.\n    }\n\n    startPositions.push(startPosition)\n\n    if (!token._tokenizer) {\n      stream = context.sliceStream(token)\n\n      if (!token.next) {\n        stream.push(null)\n      }\n\n      if (previous) {\n        tokenizer.defineSkip(token.start)\n      }\n\n      if (token.isInFirstContentOfListItem) {\n        tokenizer._gfmTasklistFirstContentOfListItem = true\n      }\n\n      tokenizer.write(stream)\n\n      if (token.isInFirstContentOfListItem) {\n        tokenizer._gfmTasklistFirstContentOfListItem = undefined\n      }\n    } // Unravel the next token.\n\n    previous = token\n    token = token.next\n  } // Now, loop back through all events (and linked tokens), to figure out which\n  // parts belong where.\n\n  token = previous\n  index = childEvents.length\n\n  while (index--) {\n    // Make sure weve at least seen something (final eol is part of the last\n    // token).\n    if (childEvents[index][0] === 'enter') {\n      entered = true\n    } else if (\n      // Find a void token that includes a break.\n      entered &&\n      childEvents[index][1].type === childEvents[index - 1][1].type &&\n      childEvents[index][1].start.line !== childEvents[index][1].end.line\n    ) {\n      add(childEvents.slice(index + 1, end))\n      // Help GC.\n      token._tokenizer = token.next = undefined\n      token = token.previous\n      end = index + 1\n    }\n  }\n\n  // Help GC.\n  tokenizer.events = token._tokenizer = token.next = undefined // Do head:\n\n  add(childEvents.slice(0, end))\n  index = -1\n  adjust = 0\n\n  while (++index < jumps.length) {\n    gaps[adjust + jumps[index][0]] = adjust + jumps[index][1]\n    adjust += jumps[index][1] - jumps[index][0] - 1\n  }\n\n  return gaps\n\n  function add(slice) {\n    var start = startPositions.pop()\n    jumps.unshift([start, start + slice.length - 1])\n    chunkedSplice(events, start, 2, slice)\n  }\n}\n\nmodule.exports = subtokenize\n","'use strict'\n\nvar markdownLineEnding = require('../character/markdown-line-ending.js')\nvar markdownSpace = require('../character/markdown-space.js')\nvar factorySpace = require('./factory-space.js')\n\nfunction whitespaceFactory(effects, ok) {\n  var seen\n  return start\n\n  function start(code) {\n    if (markdownLineEnding(code)) {\n      effects.enter('lineEnding')\n      effects.consume(code)\n      effects.exit('lineEnding')\n      seen = true\n      return start\n    }\n\n    if (markdownSpace(code)) {\n      return factorySpace(\n        effects,\n        start,\n        seen ? 'linePrefix' : 'lineSuffix'\n      )(code)\n    }\n\n    return ok(code)\n  }\n}\n\nmodule.exports = whitespaceFactory\n","'use strict'\n\nvar chunkedPush = require('../util/chunked-push.js')\nvar chunkedSplice = require('../util/chunked-splice.js')\nvar classifyCharacter = require('../util/classify-character.js')\nvar movePoint = require('../util/move-point.js')\nvar resolveAll = require('../util/resolve-all.js')\nvar shallow = require('../util/shallow.js')\n\nvar attention = {\n  name: 'attention',\n  tokenize: tokenizeAttention,\n  resolveAll: resolveAllAttention\n}\n\nfunction resolveAllAttention(events, context) {\n  var index = -1\n  var open\n  var group\n  var text\n  var openingSequence\n  var closingSequence\n  var use\n  var nextEvents\n  var offset // Walk through all events.\n  //\n  // Note: performance of this is fine on an mb of normal markdown, but its\n  // a bottleneck for malicious stuff.\n\n  while (++index < events.length) {\n    // Find a token that can close.\n    if (\n      events[index][0] === 'enter' &&\n      events[index][1].type === 'attentionSequence' &&\n      events[index][1]._close\n    ) {\n      open = index // Now walk back to find an opener.\n\n      while (open--) {\n        // Find a token that can open the closer.\n        if (\n          events[open][0] === 'exit' &&\n          events[open][1].type === 'attentionSequence' &&\n          events[open][1]._open && // If the markers are the same:\n          context.sliceSerialize(events[open][1]).charCodeAt(0) ===\n            context.sliceSerialize(events[index][1]).charCodeAt(0)\n        ) {\n          // If the opening can close or the closing can open,\n          // and the close size *is not* a multiple of three,\n          // but the sum of the opening and closing size *is* multiple of three,\n          // then dont match.\n          if (\n            (events[open][1]._close || events[index][1]._open) &&\n            (events[index][1].end.offset - events[index][1].start.offset) % 3 &&\n            !(\n              (events[open][1].end.offset -\n                events[open][1].start.offset +\n                events[index][1].end.offset -\n                events[index][1].start.offset) %\n              3\n            )\n          ) {\n            continue\n          } // Number of markers to use from the sequence.\n\n          use =\n            events[open][1].end.offset - events[open][1].start.offset > 1 &&\n            events[index][1].end.offset - events[index][1].start.offset > 1\n              ? 2\n              : 1\n          openingSequence = {\n            type: use > 1 ? 'strongSequence' : 'emphasisSequence',\n            start: movePoint(shallow(events[open][1].end), -use),\n            end: shallow(events[open][1].end)\n          }\n          closingSequence = {\n            type: use > 1 ? 'strongSequence' : 'emphasisSequence',\n            start: shallow(events[index][1].start),\n            end: movePoint(shallow(events[index][1].start), use)\n          }\n          text = {\n            type: use > 1 ? 'strongText' : 'emphasisText',\n            start: shallow(events[open][1].end),\n            end: shallow(events[index][1].start)\n          }\n          group = {\n            type: use > 1 ? 'strong' : 'emphasis',\n            start: shallow(openingSequence.start),\n            end: shallow(closingSequence.end)\n          }\n          events[open][1].end = shallow(openingSequence.start)\n          events[index][1].start = shallow(closingSequence.end)\n          nextEvents = [] // If there are more markers in the opening, add them before.\n\n          if (events[open][1].end.offset - events[open][1].start.offset) {\n            nextEvents = chunkedPush(nextEvents, [\n              ['enter', events[open][1], context],\n              ['exit', events[open][1], context]\n            ])\n          } // Opening.\n\n          nextEvents = chunkedPush(nextEvents, [\n            ['enter', group, context],\n            ['enter', openingSequence, context],\n            ['exit', openingSequence, context],\n            ['enter', text, context]\n          ]) // Between.\n\n          nextEvents = chunkedPush(\n            nextEvents,\n            resolveAll(\n              context.parser.constructs.insideSpan.null,\n              events.slice(open + 1, index),\n              context\n            )\n          ) // Closing.\n\n          nextEvents = chunkedPush(nextEvents, [\n            ['exit', text, context],\n            ['enter', closingSequence, context],\n            ['exit', closingSequence, context],\n            ['exit', group, context]\n          ]) // If there are more markers in the closing, add them after.\n\n          if (events[index][1].end.offset - events[index][1].start.offset) {\n            offset = 2\n            nextEvents = chunkedPush(nextEvents, [\n              ['enter', events[index][1], context],\n              ['exit', events[index][1], context]\n            ])\n          } else {\n            offset = 0\n          }\n\n          chunkedSplice(events, open - 1, index - open + 3, nextEvents)\n          index = open + nextEvents.length - offset - 2\n          break\n        }\n      }\n    }\n  } // Remove remaining sequences.\n\n  index = -1\n\n  while (++index < events.length) {\n    if (events[index][1].type === 'attentionSequence') {\n      events[index][1].type = 'data'\n    }\n  }\n\n  return events\n}\n\nfunction tokenizeAttention(effects, ok) {\n  var before = classifyCharacter(this.previous)\n  var marker\n  return start\n\n  function start(code) {\n    effects.enter('attentionSequence')\n    marker = code\n    return sequence(code)\n  }\n\n  function sequence(code) {\n    var token\n    var after\n    var open\n    var close\n\n    if (code === marker) {\n      effects.consume(code)\n      return sequence\n    }\n\n    token = effects.exit('attentionSequence')\n    after = classifyCharacter(code)\n    open = !after || (after === 2 && before)\n    close = !before || (before === 2 && after)\n    token._open = marker === 42 ? open : open && (before || !close)\n    token._close = marker === 42 ? close : close && (after || !open)\n    return ok(code)\n  }\n}\n\nmodule.exports = attention\n","'use strict'\n\nvar markdownLineEnding = require('../character/markdown-line-ending.js')\nvar markdownLineEndingOrSpace = require('../character/markdown-line-ending-or-space.js')\nvar markdownSpace = require('../character/markdown-space.js')\nvar chunkedSplice = require('../util/chunked-splice.js')\nvar factorySpace = require('./factory-space.js')\n\nvar headingAtx = {\n  name: 'headingAtx',\n  tokenize: tokenizeHeadingAtx,\n  resolve: resolveHeadingAtx\n}\n\nfunction resolveHeadingAtx(events, context) {\n  var contentEnd = events.length - 2\n  var contentStart = 3\n  var content\n  var text // Prefix whitespace, part of the opening.\n\n  if (events[contentStart][1].type === 'whitespace') {\n    contentStart += 2\n  } // Suffix whitespace, part of the closing.\n\n  if (\n    contentEnd - 2 > contentStart &&\n    events[contentEnd][1].type === 'whitespace'\n  ) {\n    contentEnd -= 2\n  }\n\n  if (\n    events[contentEnd][1].type === 'atxHeadingSequence' &&\n    (contentStart === contentEnd - 1 ||\n      (contentEnd - 4 > contentStart &&\n        events[contentEnd - 2][1].type === 'whitespace'))\n  ) {\n    contentEnd -= contentStart + 1 === contentEnd ? 2 : 4\n  }\n\n  if (contentEnd > contentStart) {\n    content = {\n      type: 'atxHeadingText',\n      start: events[contentStart][1].start,\n      end: events[contentEnd][1].end\n    }\n    text = {\n      type: 'chunkText',\n      start: events[contentStart][1].start,\n      end: events[contentEnd][1].end,\n      contentType: 'text'\n    }\n    chunkedSplice(events, contentStart, contentEnd - contentStart + 1, [\n      ['enter', content, context],\n      ['enter', text, context],\n      ['exit', text, context],\n      ['exit', content, context]\n    ])\n  }\n\n  return events\n}\n\nfunction tokenizeHeadingAtx(effects, ok, nok) {\n  var self = this\n  var size = 0\n  return start\n\n  function start(code) {\n    effects.enter('atxHeading')\n    effects.enter('atxHeadingSequence')\n    return fenceOpenInside(code)\n  }\n\n  function fenceOpenInside(code) {\n    if (code === 35 && size++ < 6) {\n      effects.consume(code)\n      return fenceOpenInside\n    }\n\n    if (code === null || markdownLineEndingOrSpace(code)) {\n      effects.exit('atxHeadingSequence')\n      return self.interrupt ? ok(code) : headingBreak(code)\n    }\n\n    return nok(code)\n  }\n\n  function headingBreak(code) {\n    if (code === 35) {\n      effects.enter('atxHeadingSequence')\n      return sequence(code)\n    }\n\n    if (code === null || markdownLineEnding(code)) {\n      effects.exit('atxHeading')\n      return ok(code)\n    }\n\n    if (markdownSpace(code)) {\n      return factorySpace(effects, headingBreak, 'whitespace')(code)\n    }\n\n    effects.enter('atxHeadingText')\n    return data(code)\n  }\n\n  function sequence(code) {\n    if (code === 35) {\n      effects.consume(code)\n      return sequence\n    }\n\n    effects.exit('atxHeadingSequence')\n    return headingBreak(code)\n  }\n\n  function data(code) {\n    if (code === null || code === 35 || markdownLineEndingOrSpace(code)) {\n      effects.exit('atxHeadingText')\n      return headingBreak(code)\n    }\n\n    effects.consume(code)\n    return data\n  }\n}\n\nmodule.exports = headingAtx\n","'use strict'\n\nvar markdownLineEndingOrSpace = require('../character/markdown-line-ending-or-space.js')\nvar chunkedPush = require('../util/chunked-push.js')\nvar chunkedSplice = require('../util/chunked-splice.js')\nvar normalizeIdentifier = require('../util/normalize-identifier.js')\nvar resolveAll = require('../util/resolve-all.js')\nvar shallow = require('../util/shallow.js')\nvar factoryDestination = require('./factory-destination.js')\nvar factoryLabel = require('./factory-label.js')\nvar factoryTitle = require('./factory-title.js')\nvar factoryWhitespace = require('./factory-whitespace.js')\n\nvar labelEnd = {\n  name: 'labelEnd',\n  tokenize: tokenizeLabelEnd,\n  resolveTo: resolveToLabelEnd,\n  resolveAll: resolveAllLabelEnd\n}\nvar resourceConstruct = {\n  tokenize: tokenizeResource\n}\nvar fullReferenceConstruct = {\n  tokenize: tokenizeFullReference\n}\nvar collapsedReferenceConstruct = {\n  tokenize: tokenizeCollapsedReference\n}\n\nfunction resolveAllLabelEnd(events) {\n  var index = -1\n  var token\n\n  while (++index < events.length) {\n    token = events[index][1]\n\n    if (\n      !token._used &&\n      (token.type === 'labelImage' ||\n        token.type === 'labelLink' ||\n        token.type === 'labelEnd')\n    ) {\n      // Remove the marker.\n      events.splice(index + 1, token.type === 'labelImage' ? 4 : 2)\n      token.type = 'data'\n      index++\n    }\n  }\n\n  return events\n}\n\nfunction resolveToLabelEnd(events, context) {\n  var index = events.length\n  var offset = 0\n  var group\n  var label\n  var text\n  var token\n  var open\n  var close\n  var media // Find an opening.\n\n  while (index--) {\n    token = events[index][1]\n\n    if (open) {\n      // If we see another link, or inactive link label, weve been here before.\n      if (\n        token.type === 'link' ||\n        (token.type === 'labelLink' && token._inactive)\n      ) {\n        break\n      } // Mark other link openings as inactive, as we cant have links in\n      // links.\n\n      if (events[index][0] === 'enter' && token.type === 'labelLink') {\n        token._inactive = true\n      }\n    } else if (close) {\n      if (\n        events[index][0] === 'enter' &&\n        (token.type === 'labelImage' || token.type === 'labelLink') &&\n        !token._balanced\n      ) {\n        open = index\n\n        if (token.type !== 'labelLink') {\n          offset = 2\n          break\n        }\n      }\n    } else if (token.type === 'labelEnd') {\n      close = index\n    }\n  }\n\n  group = {\n    type: events[open][1].type === 'labelLink' ? 'link' : 'image',\n    start: shallow(events[open][1].start),\n    end: shallow(events[events.length - 1][1].end)\n  }\n  label = {\n    type: 'label',\n    start: shallow(events[open][1].start),\n    end: shallow(events[close][1].end)\n  }\n  text = {\n    type: 'labelText',\n    start: shallow(events[open + offset + 2][1].end),\n    end: shallow(events[close - 2][1].start)\n  }\n  media = [\n    ['enter', group, context],\n    ['enter', label, context]\n  ] // Opening marker.\n\n  media = chunkedPush(media, events.slice(open + 1, open + offset + 3)) // Text open.\n\n  media = chunkedPush(media, [['enter', text, context]]) // Between.\n\n  media = chunkedPush(\n    media,\n    resolveAll(\n      context.parser.constructs.insideSpan.null,\n      events.slice(open + offset + 4, close - 3),\n      context\n    )\n  ) // Text close, marker close, label close.\n\n  media = chunkedPush(media, [\n    ['exit', text, context],\n    events[close - 2],\n    events[close - 1],\n    ['exit', label, context]\n  ]) // Reference, resource, or so.\n\n  media = chunkedPush(media, events.slice(close + 1)) // Media close.\n\n  media = chunkedPush(media, [['exit', group, context]])\n  chunkedSplice(events, open, events.length, media)\n  return events\n}\n\nfunction tokenizeLabelEnd(effects, ok, nok) {\n  var self = this\n  var index = self.events.length\n  var labelStart\n  var defined // Find an opening.\n\n  while (index--) {\n    if (\n      (self.events[index][1].type === 'labelImage' ||\n        self.events[index][1].type === 'labelLink') &&\n      !self.events[index][1]._balanced\n    ) {\n      labelStart = self.events[index][1]\n      break\n    }\n  }\n\n  return start\n\n  function start(code) {\n    if (!labelStart) {\n      return nok(code)\n    } // Its a balanced bracket, but contains a link.\n\n    if (labelStart._inactive) return balanced(code)\n    defined =\n      self.parser.defined.indexOf(\n        normalizeIdentifier(\n          self.sliceSerialize({\n            start: labelStart.end,\n            end: self.now()\n          })\n        )\n      ) > -1\n    effects.enter('labelEnd')\n    effects.enter('labelMarker')\n    effects.consume(code)\n    effects.exit('labelMarker')\n    effects.exit('labelEnd')\n    return afterLabelEnd\n  }\n\n  function afterLabelEnd(code) {\n    // Resource: `[asd](fgh)`.\n    if (code === 40) {\n      return effects.attempt(\n        resourceConstruct,\n        ok,\n        defined ? ok : balanced\n      )(code)\n    } // Collapsed (`[asd][]`) or full (`[asd][fgh]`) reference?\n\n    if (code === 91) {\n      return effects.attempt(\n        fullReferenceConstruct,\n        ok,\n        defined\n          ? effects.attempt(collapsedReferenceConstruct, ok, balanced)\n          : balanced\n      )(code)\n    } // Shortcut reference: `[asd]`?\n\n    return defined ? ok(code) : balanced(code)\n  }\n\n  function balanced(code) {\n    labelStart._balanced = true\n    return nok(code)\n  }\n}\n\nfunction tokenizeResource(effects, ok, nok) {\n  return start\n\n  function start(code) {\n    effects.enter('resource')\n    effects.enter('resourceMarker')\n    effects.consume(code)\n    effects.exit('resourceMarker')\n    return factoryWhitespace(effects, open)\n  }\n\n  function open(code) {\n    if (code === 41) {\n      return end(code)\n    }\n\n    return factoryDestination(\n      effects,\n      destinationAfter,\n      nok,\n      'resourceDestination',\n      'resourceDestinationLiteral',\n      'resourceDestinationLiteralMarker',\n      'resourceDestinationRaw',\n      'resourceDestinationString',\n      3\n    )(code)\n  }\n\n  function destinationAfter(code) {\n    return markdownLineEndingOrSpace(code)\n      ? factoryWhitespace(effects, between)(code)\n      : end(code)\n  }\n\n  function between(code) {\n    if (code === 34 || code === 39 || code === 40) {\n      return factoryTitle(\n        effects,\n        factoryWhitespace(effects, end),\n        nok,\n        'resourceTitle',\n        'resourceTitleMarker',\n        'resourceTitleString'\n      )(code)\n    }\n\n    return end(code)\n  }\n\n  function end(code) {\n    if (code === 41) {\n      effects.enter('resourceMarker')\n      effects.consume(code)\n      effects.exit('resourceMarker')\n      effects.exit('resource')\n      return ok\n    }\n\n    return nok(code)\n  }\n}\n\nfunction tokenizeFullReference(effects, ok, nok) {\n  var self = this\n  return start\n\n  function start(code) {\n    return factoryLabel.call(\n      self,\n      effects,\n      afterLabel,\n      nok,\n      'reference',\n      'referenceMarker',\n      'referenceString'\n    )(code)\n  }\n\n  function afterLabel(code) {\n    return self.parser.defined.indexOf(\n      normalizeIdentifier(\n        self.sliceSerialize(self.events[self.events.length - 1][1]).slice(1, -1)\n      )\n    ) < 0\n      ? nok(code)\n      : ok(code)\n  }\n}\n\nfunction tokenizeCollapsedReference(effects, ok, nok) {\n  return start\n\n  function start(code) {\n    effects.enter('reference')\n    effects.enter('referenceMarker')\n    effects.consume(code)\n    effects.exit('referenceMarker')\n    return open\n  }\n\n  function open(code) {\n    if (code === 93) {\n      effects.enter('referenceMarker')\n      effects.consume(code)\n      effects.exit('referenceMarker')\n      effects.exit('reference')\n      return ok\n    }\n\n    return nok(code)\n  }\n}\n\nmodule.exports = labelEnd\n","'use strict'\n\nvar subtokenize = require('./util/subtokenize.js')\n\nfunction postprocess(events) {\n  while (!subtokenize(events)) {\n    // Empty\n  }\n\n  return events\n}\n\nmodule.exports = postprocess\n","'use strict'\n\nObject.defineProperty(exports, '__esModule', {value: true})\n\nvar markdownLineEnding = require('../character/markdown-line-ending.js')\nvar factorySpace = require('../tokenize/factory-space.js')\n\nvar tokenize = initializeContent\n\nfunction initializeContent(effects) {\n  var contentStart = effects.attempt(\n    this.parser.constructs.contentInitial,\n    afterContentStartConstruct,\n    paragraphInitial\n  )\n  var previous\n  return contentStart\n\n  function afterContentStartConstruct(code) {\n    if (code === null) {\n      effects.consume(code)\n      return\n    }\n\n    effects.enter('lineEnding')\n    effects.consume(code)\n    effects.exit('lineEnding')\n    return factorySpace(effects, contentStart, 'linePrefix')\n  }\n\n  function paragraphInitial(code) {\n    effects.enter('paragraph')\n    return lineStart(code)\n  }\n\n  function lineStart(code) {\n    var token = effects.enter('chunkText', {\n      contentType: 'text',\n      previous: previous\n    })\n\n    if (previous) {\n      previous.next = token\n    }\n\n    previous = token\n    return data(code)\n  }\n\n  function data(code) {\n    if (code === null) {\n      effects.exit('chunkText')\n      effects.exit('paragraph')\n      effects.consume(code)\n      return\n    }\n\n    if (markdownLineEnding(code)) {\n      effects.consume(code)\n      effects.exit('chunkText')\n      return lineStart\n    } // Data.\n\n    effects.consume(code)\n    return data\n  }\n}\n\nexports.tokenize = tokenize\n","'use strict'\n\nvar content = require('./initialize/content.js')\nvar document = require('./initialize/document.js')\nvar flow = require('./initialize/flow.js')\nvar text = require('./initialize/text.js')\nvar combineExtensions = require('./util/combine-extensions.js')\nvar createTokenizer = require('./util/create-tokenizer.js')\nvar miniflat = require('./util/miniflat.js')\nvar constructs = require('./constructs.js')\n\nfunction parse(options) {\n  var settings = options || {}\n  var parser = {\n    defined: [],\n    constructs: combineExtensions(\n      [constructs].concat(miniflat(settings.extensions))\n    ),\n    content: create(content),\n    document: create(document),\n    flow: create(flow),\n    string: create(text.string),\n    text: create(text.text)\n  }\n  return parser\n\n  function create(initializer) {\n    return creator\n\n    function creator(from) {\n      return createTokenizer(parser, initializer, from)\n    }\n  }\n}\n\nmodule.exports = parse\n","'use strict'\n\nvar markdownSpace = require('../character/markdown-space.js')\nvar factorySpace = require('./factory-space.js')\n\nvar blockQuote = {\n  name: 'blockQuote',\n  tokenize: tokenizeBlockQuoteStart,\n  continuation: {\n    tokenize: tokenizeBlockQuoteContinuation\n  },\n  exit: exit\n}\n\nfunction tokenizeBlockQuoteStart(effects, ok, nok) {\n  var self = this\n  return start\n\n  function start(code) {\n    if (code === 62) {\n      if (!self.containerState.open) {\n        effects.enter('blockQuote', {\n          _container: true\n        })\n        self.containerState.open = true\n      }\n\n      effects.enter('blockQuotePrefix')\n      effects.enter('blockQuoteMarker')\n      effects.consume(code)\n      effects.exit('blockQuoteMarker')\n      return after\n    }\n\n    return nok(code)\n  }\n\n  function after(code) {\n    if (markdownSpace(code)) {\n      effects.enter('blockQuotePrefixWhitespace')\n      effects.consume(code)\n      effects.exit('blockQuotePrefixWhitespace')\n      effects.exit('blockQuotePrefix')\n      return ok\n    }\n\n    effects.exit('blockQuotePrefix')\n    return ok(code)\n  }\n}\n\nfunction tokenizeBlockQuoteContinuation(effects, ok, nok) {\n  return factorySpace(\n    effects,\n    effects.attempt(blockQuote, ok, nok),\n    'linePrefix',\n    this.parser.constructs.disable.null.indexOf('codeIndented') > -1\n      ? undefined\n      : 4\n  )\n}\n\nfunction exit(effects) {\n  effects.exit('blockQuote')\n}\n\nmodule.exports = blockQuote\n","'use strict'\n\nvar labelEnd = require('./label-end.js')\n\nvar labelStartImage = {\n  name: 'labelStartImage',\n  tokenize: tokenizeLabelStartImage,\n  resolveAll: labelEnd.resolveAll\n}\n\nfunction tokenizeLabelStartImage(effects, ok, nok) {\n  var self = this\n  return start\n\n  function start(code) {\n    effects.enter('labelImage')\n    effects.enter('labelImageMarker')\n    effects.consume(code)\n    effects.exit('labelImageMarker')\n    return open\n  }\n\n  function open(code) {\n    if (code === 91) {\n      effects.enter('labelMarker')\n      effects.consume(code)\n      effects.exit('labelMarker')\n      effects.exit('labelImage')\n      return after\n    }\n\n    return nok(code)\n  }\n\n  function after(code) {\n    /* c8 ignore next */\n    return code === 94 &&\n      /* c8 ignore next */\n      '_hiddenFootnoteSupport' in self.parser.constructs\n      ? /* c8 ignore next */\n        nok(code)\n      : ok(code)\n  }\n}\n\nmodule.exports = labelStartImage\n","'use strict'\n\n// This module is generated by `script/`.\n//\n// CommonMark handles attention (emphasis, strong) markers based on what comes\n// before or after them.\n// One such difference is if those characters are Unicode punctuation.\n// This script is generated from the Unicode data.\nvar unicodePunctuation = /[!-\\/:-@\\[-`\\{-~\\xA1\\xA7\\xAB\\xB6\\xB7\\xBB\\xBF\\u037E\\u0387\\u055A-\\u055F\\u0589\\u058A\\u05BE\\u05C0\\u05C3\\u05C6\\u05F3\\u05F4\\u0609\\u060A\\u060C\\u060D\\u061B\\u061E\\u061F\\u066A-\\u066D\\u06D4\\u0700-\\u070D\\u07F7-\\u07F9\\u0830-\\u083E\\u085E\\u0964\\u0965\\u0970\\u09FD\\u0A76\\u0AF0\\u0C77\\u0C84\\u0DF4\\u0E4F\\u0E5A\\u0E5B\\u0F04-\\u0F12\\u0F14\\u0F3A-\\u0F3D\\u0F85\\u0FD0-\\u0FD4\\u0FD9\\u0FDA\\u104A-\\u104F\\u10FB\\u1360-\\u1368\\u1400\\u166E\\u169B\\u169C\\u16EB-\\u16ED\\u1735\\u1736\\u17D4-\\u17D6\\u17D8-\\u17DA\\u1800-\\u180A\\u1944\\u1945\\u1A1E\\u1A1F\\u1AA0-\\u1AA6\\u1AA8-\\u1AAD\\u1B5A-\\u1B60\\u1BFC-\\u1BFF\\u1C3B-\\u1C3F\\u1C7E\\u1C7F\\u1CC0-\\u1CC7\\u1CD3\\u2010-\\u2027\\u2030-\\u2043\\u2045-\\u2051\\u2053-\\u205E\\u207D\\u207E\\u208D\\u208E\\u2308-\\u230B\\u2329\\u232A\\u2768-\\u2775\\u27C5\\u27C6\\u27E6-\\u27EF\\u2983-\\u2998\\u29D8-\\u29DB\\u29FC\\u29FD\\u2CF9-\\u2CFC\\u2CFE\\u2CFF\\u2D70\\u2E00-\\u2E2E\\u2E30-\\u2E4F\\u2E52\\u3001-\\u3003\\u3008-\\u3011\\u3014-\\u301F\\u3030\\u303D\\u30A0\\u30FB\\uA4FE\\uA4FF\\uA60D-\\uA60F\\uA673\\uA67E\\uA6F2-\\uA6F7\\uA874-\\uA877\\uA8CE\\uA8CF\\uA8F8-\\uA8FA\\uA8FC\\uA92E\\uA92F\\uA95F\\uA9C1-\\uA9CD\\uA9DE\\uA9DF\\uAA5C-\\uAA5F\\uAADE\\uAADF\\uAAF0\\uAAF1\\uABEB\\uFD3E\\uFD3F\\uFE10-\\uFE19\\uFE30-\\uFE52\\uFE54-\\uFE61\\uFE63\\uFE68\\uFE6A\\uFE6B\\uFF01-\\uFF03\\uFF05-\\uFF0A\\uFF0C-\\uFF0F\\uFF1A\\uFF1B\\uFF1F\\uFF20\\uFF3B-\\uFF3D\\uFF3F\\uFF5B\\uFF5D\\uFF5F-\\uFF65]/\n\nmodule.exports = unicodePunctuation\n","/**\n * @typedef {import('micromark-util-types').InitialConstruct} InitialConstruct\n * @typedef {import('micromark-util-types').Initializer} Initializer\n * @typedef {import('micromark-util-types').State} State\n * @typedef {import('micromark-util-types').Token} Token\n * @typedef {import('micromark-util-types').TokenizeContext} TokenizeContext\n */\n\nimport {factorySpace} from 'micromark-factory-space'\nimport {markdownLineEnding} from 'micromark-util-character'\n/** @type {InitialConstruct} */\nexport const content = {\n  tokenize: initializeContent\n}\n\n/**\n * @this {TokenizeContext}\n * @type {Initializer}\n */\nfunction initializeContent(effects) {\n  const contentStart = effects.attempt(\n    this.parser.constructs.contentInitial,\n    afterContentStartConstruct,\n    paragraphInitial\n  )\n  /** @type {Token} */\n  let previous\n  return contentStart\n\n  /** @type {State} */\n  function afterContentStartConstruct(code) {\n    if (code === null) {\n      effects.consume(code)\n      return\n    }\n    effects.enter('lineEnding')\n    effects.consume(code)\n    effects.exit('lineEnding')\n    return factorySpace(effects, contentStart, 'linePrefix')\n  }\n\n  /** @type {State} */\n  function paragraphInitial(code) {\n    effects.enter('paragraph')\n    return lineStart(code)\n  }\n\n  /** @type {State} */\n  function lineStart(code) {\n    const token = effects.enter('chunkText', {\n      contentType: 'text',\n      previous\n    })\n    if (previous) {\n      previous.next = token\n    }\n    previous = token\n    return data(code)\n  }\n\n  /** @type {State} */\n  function data(code) {\n    if (code === null) {\n      effects.exit('chunkText')\n      effects.exit('paragraph')\n      effects.consume(code)\n      return\n    }\n    if (markdownLineEnding(code)) {\n      effects.consume(code)\n      effects.exit('chunkText')\n      return lineStart\n    }\n\n    // Data.\n    effects.consume(code)\n    return data\n  }\n}\n","/**\n * @typedef {import('micromark-util-types').Construct} Construct\n * @typedef {import('micromark-util-types').ContainerState} ContainerState\n * @typedef {import('micromark-util-types').InitialConstruct} InitialConstruct\n * @typedef {import('micromark-util-types').Initializer} Initializer\n * @typedef {import('micromark-util-types').Point} Point\n * @typedef {import('micromark-util-types').State} State\n * @typedef {import('micromark-util-types').Token} Token\n * @typedef {import('micromark-util-types').TokenizeContext} TokenizeContext\n * @typedef {import('micromark-util-types').Tokenizer} Tokenizer\n */\n\n/**\n * @typedef {[Construct, ContainerState]} StackItem\n */\n\nimport {factorySpace} from 'micromark-factory-space'\nimport {markdownLineEnding} from 'micromark-util-character'\nimport {splice} from 'micromark-util-chunked'\n/** @type {InitialConstruct} */\nexport const document = {\n  tokenize: initializeDocument\n}\n\n/** @type {Construct} */\nconst containerConstruct = {\n  tokenize: tokenizeContainer\n}\n\n/**\n * @this {TokenizeContext}\n * @type {Initializer}\n */\nfunction initializeDocument(effects) {\n  const self = this\n  /** @type {Array<StackItem>} */\n  const stack = []\n  let continued = 0\n  /** @type {TokenizeContext | undefined} */\n  let childFlow\n  /** @type {Token | undefined} */\n  let childToken\n  /** @type {number} */\n  let lineStartOffset\n  return start\n\n  /** @type {State} */\n  function start(code) {\n    // First we iterate through the open blocks, starting with the root\n    // document, and descending through last children down to the last open\n    // block.\n    // Each block imposes a condition that the line must satisfy if the block is\n    // to remain open.\n    // For example, a block quote requires a `>` character.\n    // A paragraph requires a non-blank line.\n    // In this phase we may match all or just some of the open blocks.\n    // But we cannot close unmatched blocks yet, because we may have a lazy\n    // continuation line.\n    if (continued < stack.length) {\n      const item = stack[continued]\n      self.containerState = item[1]\n      return effects.attempt(\n        item[0].continuation,\n        documentContinue,\n        checkNewContainers\n      )(code)\n    }\n\n    // Done.\n    return checkNewContainers(code)\n  }\n\n  /** @type {State} */\n  function documentContinue(code) {\n    continued++\n\n    // Note: this field is called `_closeFlow` but it also closes containers.\n    // Perhaps a good idea to rename it but its already used in the wild by\n    // extensions.\n    if (self.containerState._closeFlow) {\n      self.containerState._closeFlow = undefined\n      if (childFlow) {\n        closeFlow()\n      }\n\n      // Note: this algorithm for moving events around is similar to the\n      // algorithm when dealing with lazy lines in `writeToChild`.\n      const indexBeforeExits = self.events.length\n      let indexBeforeFlow = indexBeforeExits\n      /** @type {Point | undefined} */\n      let point\n\n      // Find the flow chunk.\n      while (indexBeforeFlow--) {\n        if (\n          self.events[indexBeforeFlow][0] === 'exit' &&\n          self.events[indexBeforeFlow][1].type === 'chunkFlow'\n        ) {\n          point = self.events[indexBeforeFlow][1].end\n          break\n        }\n      }\n      exitContainers(continued)\n\n      // Fix positions.\n      let index = indexBeforeExits\n      while (index < self.events.length) {\n        self.events[index][1].end = Object.assign({}, point)\n        index++\n      }\n\n      // Inject the exits earlier (theyre still also at the end).\n      splice(\n        self.events,\n        indexBeforeFlow + 1,\n        0,\n        self.events.slice(indexBeforeExits)\n      )\n\n      // Discard the duplicate exits.\n      self.events.length = index\n      return checkNewContainers(code)\n    }\n    return start(code)\n  }\n\n  /** @type {State} */\n  function checkNewContainers(code) {\n    // Next, after consuming the continuation markers for existing blocks, we\n    // look for new block starts (e.g. `>` for a block quote).\n    // If we encounter a new block start, we close any blocks unmatched in\n    // step 1 before creating the new block as a child of the last matched\n    // block.\n    if (continued === stack.length) {\n      // No need to `check` whether theres a container, of `exitContainers`\n      // would be moot.\n      // We can instead immediately `attempt` to parse one.\n      if (!childFlow) {\n        return documentContinued(code)\n      }\n\n      // If we have concrete content, such as block HTML or fenced code,\n      // we cant have containers pierce into them, so we can immediately\n      // start.\n      if (childFlow.currentConstruct && childFlow.currentConstruct.concrete) {\n        return flowStart(code)\n      }\n\n      // If we do have flow, it could still be a blank line,\n      // but wed be interrupting it w/ a new container if theres a current\n      // construct.\n      // To do: next major: remove `_gfmTableDynamicInterruptHack` (no longer\n      // needed in micromark-extension-gfm-table@1.0.6).\n      self.interrupt = Boolean(\n        childFlow.currentConstruct && !childFlow._gfmTableDynamicInterruptHack\n      )\n    }\n\n    // Check if there is a new container.\n    self.containerState = {}\n    return effects.check(\n      containerConstruct,\n      thereIsANewContainer,\n      thereIsNoNewContainer\n    )(code)\n  }\n\n  /** @type {State} */\n  function thereIsANewContainer(code) {\n    if (childFlow) closeFlow()\n    exitContainers(continued)\n    return documentContinued(code)\n  }\n\n  /** @type {State} */\n  function thereIsNoNewContainer(code) {\n    self.parser.lazy[self.now().line] = continued !== stack.length\n    lineStartOffset = self.now().offset\n    return flowStart(code)\n  }\n\n  /** @type {State} */\n  function documentContinued(code) {\n    // Try new containers.\n    self.containerState = {}\n    return effects.attempt(\n      containerConstruct,\n      containerContinue,\n      flowStart\n    )(code)\n  }\n\n  /** @type {State} */\n  function containerContinue(code) {\n    continued++\n    stack.push([self.currentConstruct, self.containerState])\n    // Try another.\n    return documentContinued(code)\n  }\n\n  /** @type {State} */\n  function flowStart(code) {\n    if (code === null) {\n      if (childFlow) closeFlow()\n      exitContainers(0)\n      effects.consume(code)\n      return\n    }\n    childFlow = childFlow || self.parser.flow(self.now())\n    effects.enter('chunkFlow', {\n      contentType: 'flow',\n      previous: childToken,\n      _tokenizer: childFlow\n    })\n    return flowContinue(code)\n  }\n\n  /** @type {State} */\n  function flowContinue(code) {\n    if (code === null) {\n      writeToChild(effects.exit('chunkFlow'), true)\n      exitContainers(0)\n      effects.consume(code)\n      return\n    }\n    if (markdownLineEnding(code)) {\n      effects.consume(code)\n      writeToChild(effects.exit('chunkFlow'))\n      // Get ready for the next line.\n      continued = 0\n      self.interrupt = undefined\n      return start\n    }\n    effects.consume(code)\n    return flowContinue\n  }\n\n  /**\n   * @param {Token} token\n   * @param {boolean | undefined} [eof]\n   * @returns {void}\n   */\n  function writeToChild(token, eof) {\n    const stream = self.sliceStream(token)\n    if (eof) stream.push(null)\n    token.previous = childToken\n    if (childToken) childToken.next = token\n    childToken = token\n    childFlow.defineSkip(token.start)\n    childFlow.write(stream)\n\n    // Alright, so we just added a lazy line:\n    //\n    // ```markdown\n    // > a\n    // b.\n    //\n    // Or:\n    //\n    // > ~~~c\n    // d\n    //\n    // Or:\n    //\n    // > | e |\n    // f\n    // ```\n    //\n    // The construct in the second example (fenced code) does not accept lazy\n    // lines, so it marked itself as done at the end of its first line, and\n    // then the content construct parses `d`.\n    // Most constructs in markdown match on the first line: if the first line\n    // forms a construct, a non-lazy line cant unmake it.\n    //\n    // The construct in the third example is potentially a GFM table, and\n    // those are *weird*.\n    // It *could* be a table, from the first line, if the following line\n    // matches a condition.\n    // In this case, that second line is lazy, which unmakes the first line\n    // and turns the whole into one content block.\n    //\n    // Weve now parsed the non-lazy and the lazy line, and can figure out\n    // whether the lazy line started a new flow block.\n    // If it did, we exit the current containers between the two flow blocks.\n    if (self.parser.lazy[token.start.line]) {\n      let index = childFlow.events.length\n      while (index--) {\n        if (\n          // The token starts before the line ending\n          childFlow.events[index][1].start.offset < lineStartOffset &&\n          // and either is not ended yet\n          (!childFlow.events[index][1].end ||\n            // or ends after it.\n            childFlow.events[index][1].end.offset > lineStartOffset)\n        ) {\n          // Exit: theres still something open, which means its a lazy line\n          // part of something.\n          return\n        }\n      }\n\n      // Note: this algorithm for moving events around is similar to the\n      // algorithm when closing flow in `documentContinue`.\n      const indexBeforeExits = self.events.length\n      let indexBeforeFlow = indexBeforeExits\n      /** @type {boolean | undefined} */\n      let seen\n      /** @type {Point | undefined} */\n      let point\n\n      // Find the previous chunk (the one before the lazy line).\n      while (indexBeforeFlow--) {\n        if (\n          self.events[indexBeforeFlow][0] === 'exit' &&\n          self.events[indexBeforeFlow][1].type === 'chunkFlow'\n        ) {\n          if (seen) {\n            point = self.events[indexBeforeFlow][1].end\n            break\n          }\n          seen = true\n        }\n      }\n      exitContainers(continued)\n\n      // Fix positions.\n      index = indexBeforeExits\n      while (index < self.events.length) {\n        self.events[index][1].end = Object.assign({}, point)\n        index++\n      }\n\n      // Inject the exits earlier (theyre still also at the end).\n      splice(\n        self.events,\n        indexBeforeFlow + 1,\n        0,\n        self.events.slice(indexBeforeExits)\n      )\n\n      // Discard the duplicate exits.\n      self.events.length = index\n    }\n  }\n\n  /**\n   * @param {number} size\n   * @returns {void}\n   */\n  function exitContainers(size) {\n    let index = stack.length\n\n    // Exit open containers.\n    while (index-- > size) {\n      const entry = stack[index]\n      self.containerState = entry[1]\n      entry[0].exit.call(self, effects)\n    }\n    stack.length = size\n  }\n  function closeFlow() {\n    childFlow.write([null])\n    childToken = undefined\n    childFlow = undefined\n    self.containerState._closeFlow = undefined\n  }\n}\n\n/**\n * @this {TokenizeContext}\n * @type {Tokenizer}\n */\nfunction tokenizeContainer(effects, ok, nok) {\n  // Always populated by defaults.\n\n  return factorySpace(\n    effects,\n    effects.attempt(this.parser.constructs.document, ok, nok),\n    'linePrefix',\n    this.parser.constructs.disable.null.includes('codeIndented') ? undefined : 4\n  )\n}\n","/**\n * @typedef {import('micromark-util-types').InitialConstruct} InitialConstruct\n * @typedef {import('micromark-util-types').Initializer} Initializer\n * @typedef {import('micromark-util-types').State} State\n * @typedef {import('micromark-util-types').TokenizeContext} TokenizeContext\n */\n\nimport {blankLine, content} from 'micromark-core-commonmark'\nimport {factorySpace} from 'micromark-factory-space'\nimport {markdownLineEnding} from 'micromark-util-character'\n/** @type {InitialConstruct} */\nexport const flow = {\n  tokenize: initializeFlow\n}\n\n/**\n * @this {TokenizeContext}\n * @type {Initializer}\n */\nfunction initializeFlow(effects) {\n  const self = this\n  const initial = effects.attempt(\n    // Try to parse a blank line.\n    blankLine,\n    atBlankEnding,\n    // Try to parse initial flow (essentially, only code).\n    effects.attempt(\n      this.parser.constructs.flowInitial,\n      afterConstruct,\n      factorySpace(\n        effects,\n        effects.attempt(\n          this.parser.constructs.flow,\n          afterConstruct,\n          effects.attempt(content, afterConstruct)\n        ),\n        'linePrefix'\n      )\n    )\n  )\n  return initial\n\n  /** @type {State} */\n  function atBlankEnding(code) {\n    if (code === null) {\n      effects.consume(code)\n      return\n    }\n    effects.enter('lineEndingBlank')\n    effects.consume(code)\n    effects.exit('lineEndingBlank')\n    self.currentConstruct = undefined\n    return initial\n  }\n\n  /** @type {State} */\n  function afterConstruct(code) {\n    if (code === null) {\n      effects.consume(code)\n      return\n    }\n    effects.enter('lineEnding')\n    effects.consume(code)\n    effects.exit('lineEnding')\n    self.currentConstruct = undefined\n    return initial\n  }\n}\n","/**\n * @typedef {import('micromark-util-types').Code} Code\n * @typedef {import('micromark-util-types').InitialConstruct} InitialConstruct\n * @typedef {import('micromark-util-types').Initializer} Initializer\n * @typedef {import('micromark-util-types').Resolver} Resolver\n * @typedef {import('micromark-util-types').State} State\n * @typedef {import('micromark-util-types').TokenizeContext} TokenizeContext\n */\n\nexport const resolver = {\n  resolveAll: createResolver()\n}\nexport const string = initializeFactory('string')\nexport const text = initializeFactory('text')\n\n/**\n * @param {'string' | 'text'} field\n * @returns {InitialConstruct}\n */\nfunction initializeFactory(field) {\n  return {\n    tokenize: initializeText,\n    resolveAll: createResolver(\n      field === 'text' ? resolveAllLineSuffixes : undefined\n    )\n  }\n\n  /**\n   * @this {TokenizeContext}\n   * @type {Initializer}\n   */\n  function initializeText(effects) {\n    const self = this\n    const constructs = this.parser.constructs[field]\n    const text = effects.attempt(constructs, start, notText)\n    return start\n\n    /** @type {State} */\n    function start(code) {\n      return atBreak(code) ? text(code) : notText(code)\n    }\n\n    /** @type {State} */\n    function notText(code) {\n      if (code === null) {\n        effects.consume(code)\n        return\n      }\n      effects.enter('data')\n      effects.consume(code)\n      return data\n    }\n\n    /** @type {State} */\n    function data(code) {\n      if (atBreak(code)) {\n        effects.exit('data')\n        return text(code)\n      }\n\n      // Data.\n      effects.consume(code)\n      return data\n    }\n\n    /**\n     * @param {Code} code\n     * @returns {boolean}\n     */\n    function atBreak(code) {\n      if (code === null) {\n        return true\n      }\n      const list = constructs[code]\n      let index = -1\n      if (list) {\n        // Always populated by defaults.\n\n        while (++index < list.length) {\n          const item = list[index]\n          if (!item.previous || item.previous.call(self, self.previous)) {\n            return true\n          }\n        }\n      }\n      return false\n    }\n  }\n}\n\n/**\n * @param {Resolver | undefined} [extraResolver]\n * @returns {Resolver}\n */\nfunction createResolver(extraResolver) {\n  return resolveAllText\n\n  /** @type {Resolver} */\n  function resolveAllText(events, context) {\n    let index = -1\n    /** @type {number | undefined} */\n    let enter\n\n    // A rather boring computation (to merge adjacent `data` events) which\n    // improves mm performance by 29%.\n    while (++index <= events.length) {\n      if (enter === undefined) {\n        if (events[index] && events[index][1].type === 'data') {\n          enter = index\n          index++\n        }\n      } else if (!events[index] || events[index][1].type !== 'data') {\n        // Dont do anything if there is one data token.\n        if (index !== enter + 2) {\n          events[enter][1].end = events[index - 1][1].end\n          events.splice(enter + 2, index - enter - 2)\n          index = enter + 2\n        }\n        enter = undefined\n      }\n    }\n    return extraResolver ? extraResolver(events, context) : events\n  }\n}\n\n/**\n * A rather ugly set of instructions which again looks at chunks in the input\n * stream.\n * The reason to do this here is that it is *much* faster to parse in reverse.\n * And that we cant hook into `null` to split the line suffix before an EOF.\n * To do: figure out if we can make this into a clean utility, or even in core.\n * As it will be useful for GFMs literal autolink extension (and maybe even\n * tables?)\n *\n * @type {Resolver}\n */\nfunction resolveAllLineSuffixes(events, context) {\n  let eventIndex = 0 // Skip first.\n\n  while (++eventIndex <= events.length) {\n    if (\n      (eventIndex === events.length ||\n        events[eventIndex][1].type === 'lineEnding') &&\n      events[eventIndex - 1][1].type === 'data'\n    ) {\n      const data = events[eventIndex - 1][1]\n      const chunks = context.sliceStream(data)\n      let index = chunks.length\n      let bufferIndex = -1\n      let size = 0\n      /** @type {boolean | undefined} */\n      let tabs\n      while (index--) {\n        const chunk = chunks[index]\n        if (typeof chunk === 'string') {\n          bufferIndex = chunk.length\n          while (chunk.charCodeAt(bufferIndex - 1) === 32) {\n            size++\n            bufferIndex--\n          }\n          if (bufferIndex) break\n          bufferIndex = -1\n        }\n        // Number\n        else if (chunk === -2) {\n          tabs = true\n          size++\n        } else if (chunk === -1) {\n          // Empty\n        } else {\n          // Replacement character, exit.\n          index++\n          break\n        }\n      }\n      if (size) {\n        const token = {\n          type:\n            eventIndex === events.length || tabs || size < 2\n              ? 'lineSuffix'\n              : 'hardBreakTrailing',\n          start: {\n            line: data.end.line,\n            column: data.end.column - size,\n            offset: data.end.offset - size,\n            _index: data.start._index + index,\n            _bufferIndex: index\n              ? bufferIndex\n              : data.start._bufferIndex + bufferIndex\n          },\n          end: Object.assign({}, data.end)\n        }\n        data.end = Object.assign({}, token.start)\n        if (data.start.offset === data.end.offset) {\n          Object.assign(data, token)\n        } else {\n          events.splice(\n            eventIndex,\n            0,\n            ['enter', token, context],\n            ['exit', token, context]\n          )\n          eventIndex += 2\n        }\n      }\n      eventIndex++\n    }\n  }\n  return events\n}\n","/**\n * @typedef {import('micromark-util-types').Chunk} Chunk\n * @typedef {import('micromark-util-types').Code} Code\n * @typedef {import('micromark-util-types').Construct} Construct\n * @typedef {import('micromark-util-types').ConstructRecord} ConstructRecord\n * @typedef {import('micromark-util-types').Effects} Effects\n * @typedef {import('micromark-util-types').InitialConstruct} InitialConstruct\n * @typedef {import('micromark-util-types').ParseContext} ParseContext\n * @typedef {import('micromark-util-types').Point} Point\n * @typedef {import('micromark-util-types').State} State\n * @typedef {import('micromark-util-types').Token} Token\n * @typedef {import('micromark-util-types').TokenType} TokenType\n * @typedef {import('micromark-util-types').TokenizeContext} TokenizeContext\n */\n\n/**\n * @callback Restore\n * @returns {void}\n *\n * @typedef Info\n * @property {Restore} restore\n * @property {number} from\n *\n * @callback ReturnHandle\n *   Handle a successful run.\n * @param {Construct} construct\n * @param {Info} info\n * @returns {void}\n */\n\nimport {markdownLineEnding} from 'micromark-util-character'\nimport {push, splice} from 'micromark-util-chunked'\nimport {resolveAll} from 'micromark-util-resolve-all'\n/**\n * Create a tokenizer.\n * Tokenizers deal with one type of data (e.g., containers, flow, text).\n * The parser is the object dealing with it all.\n * `initialize` works like other constructs, except that only its `tokenize`\n * function is used, in which case it doesnt receive an `ok` or `nok`.\n * `from` can be given to set the point before the first character, although\n * when further lines are indented, they must be set with `defineSkip`.\n *\n * @param {ParseContext} parser\n * @param {InitialConstruct} initialize\n * @param {Omit<Point, '_bufferIndex' | '_index'> | undefined} [from]\n * @returns {TokenizeContext}\n */\nexport function createTokenizer(parser, initialize, from) {\n  /** @type {Point} */\n  let point = Object.assign(\n    from\n      ? Object.assign({}, from)\n      : {\n          line: 1,\n          column: 1,\n          offset: 0\n        },\n    {\n      _index: 0,\n      _bufferIndex: -1\n    }\n  )\n  /** @type {Record<string, number>} */\n  const columnStart = {}\n  /** @type {Array<Construct>} */\n  const resolveAllConstructs = []\n  /** @type {Array<Chunk>} */\n  let chunks = []\n  /** @type {Array<Token>} */\n  let stack = []\n  /** @type {boolean | undefined} */\n  let consumed = true\n\n  /**\n   * Tools used for tokenizing.\n   *\n   * @type {Effects}\n   */\n  const effects = {\n    consume,\n    enter,\n    exit,\n    attempt: constructFactory(onsuccessfulconstruct),\n    check: constructFactory(onsuccessfulcheck),\n    interrupt: constructFactory(onsuccessfulcheck, {\n      interrupt: true\n    })\n  }\n\n  /**\n   * State and tools for resolving and serializing.\n   *\n   * @type {TokenizeContext}\n   */\n  const context = {\n    previous: null,\n    code: null,\n    containerState: {},\n    events: [],\n    parser,\n    sliceStream,\n    sliceSerialize,\n    now,\n    defineSkip,\n    write\n  }\n\n  /**\n   * The state function.\n   *\n   * @type {State | void}\n   */\n  let state = initialize.tokenize.call(context, effects)\n\n  /**\n   * Track which character we expect to be consumed, to catch bugs.\n   *\n   * @type {Code}\n   */\n  let expectedCode\n  if (initialize.resolveAll) {\n    resolveAllConstructs.push(initialize)\n  }\n  return context\n\n  /** @type {TokenizeContext['write']} */\n  function write(slice) {\n    chunks = push(chunks, slice)\n    main()\n\n    // Exit if were not done, resolve might change stuff.\n    if (chunks[chunks.length - 1] !== null) {\n      return []\n    }\n    addResult(initialize, 0)\n\n    // Otherwise, resolve, and exit.\n    context.events = resolveAll(resolveAllConstructs, context.events, context)\n    return context.events\n  }\n\n  //\n  // Tools.\n  //\n\n  /** @type {TokenizeContext['sliceSerialize']} */\n  function sliceSerialize(token, expandTabs) {\n    return serializeChunks(sliceStream(token), expandTabs)\n  }\n\n  /** @type {TokenizeContext['sliceStream']} */\n  function sliceStream(token) {\n    return sliceChunks(chunks, token)\n  }\n\n  /** @type {TokenizeContext['now']} */\n  function now() {\n    // This is a hot path, so we clone manually instead of `Object.assign({}, point)`\n    const {line, column, offset, _index, _bufferIndex} = point\n    return {\n      line,\n      column,\n      offset,\n      _index,\n      _bufferIndex\n    }\n  }\n\n  /** @type {TokenizeContext['defineSkip']} */\n  function defineSkip(value) {\n    columnStart[value.line] = value.column\n    accountForPotentialSkip()\n  }\n\n  //\n  // State management.\n  //\n\n  /**\n   * Main loop (note that `_index` and `_bufferIndex` in `point` are modified by\n   * `consume`).\n   * Here is where we walk through the chunks, which either include strings of\n   * several characters, or numerical character codes.\n   * The reason to do this in a loop instead of a call is so the stack can\n   * drain.\n   *\n   * @returns {void}\n   */\n  function main() {\n    /** @type {number} */\n    let chunkIndex\n    while (point._index < chunks.length) {\n      const chunk = chunks[point._index]\n\n      // If were in a buffer chunk, loop through it.\n      if (typeof chunk === 'string') {\n        chunkIndex = point._index\n        if (point._bufferIndex < 0) {\n          point._bufferIndex = 0\n        }\n        while (\n          point._index === chunkIndex &&\n          point._bufferIndex < chunk.length\n        ) {\n          go(chunk.charCodeAt(point._bufferIndex))\n        }\n      } else {\n        go(chunk)\n      }\n    }\n  }\n\n  /**\n   * Deal with one code.\n   *\n   * @param {Code} code\n   * @returns {void}\n   */\n  function go(code) {\n    consumed = undefined\n    expectedCode = code\n    state = state(code)\n  }\n\n  /** @type {Effects['consume']} */\n  function consume(code) {\n    if (markdownLineEnding(code)) {\n      point.line++\n      point.column = 1\n      point.offset += code === -3 ? 2 : 1\n      accountForPotentialSkip()\n    } else if (code !== -1) {\n      point.column++\n      point.offset++\n    }\n\n    // Not in a string chunk.\n    if (point._bufferIndex < 0) {\n      point._index++\n    } else {\n      point._bufferIndex++\n\n      // At end of string chunk.\n      // @ts-expect-error Points w/ non-negative `_bufferIndex` reference\n      // strings.\n      if (point._bufferIndex === chunks[point._index].length) {\n        point._bufferIndex = -1\n        point._index++\n      }\n    }\n\n    // Expose the previous character.\n    context.previous = code\n\n    // Mark as consumed.\n    consumed = true\n  }\n\n  /** @type {Effects['enter']} */\n  function enter(type, fields) {\n    /** @type {Token} */\n    // @ts-expect-error Patch instead of assign required fields to help GC.\n    const token = fields || {}\n    token.type = type\n    token.start = now()\n    context.events.push(['enter', token, context])\n    stack.push(token)\n    return token\n  }\n\n  /** @type {Effects['exit']} */\n  function exit(type) {\n    const token = stack.pop()\n    token.end = now()\n    context.events.push(['exit', token, context])\n    return token\n  }\n\n  /**\n   * Use results.\n   *\n   * @type {ReturnHandle}\n   */\n  function onsuccessfulconstruct(construct, info) {\n    addResult(construct, info.from)\n  }\n\n  /**\n   * Discard results.\n   *\n   * @type {ReturnHandle}\n   */\n  function onsuccessfulcheck(_, info) {\n    info.restore()\n  }\n\n  /**\n   * Factory to attempt/check/interrupt.\n   *\n   * @param {ReturnHandle} onreturn\n   * @param {{interrupt?: boolean | undefined} | undefined} [fields]\n   */\n  function constructFactory(onreturn, fields) {\n    return hook\n\n    /**\n     * Handle either an object mapping codes to constructs, a list of\n     * constructs, or a single construct.\n     *\n     * @param {Array<Construct> | Construct | ConstructRecord} constructs\n     * @param {State} returnState\n     * @param {State | undefined} [bogusState]\n     * @returns {State}\n     */\n    function hook(constructs, returnState, bogusState) {\n      /** @type {Array<Construct>} */\n      let listOfConstructs\n      /** @type {number} */\n      let constructIndex\n      /** @type {Construct} */\n      let currentConstruct\n      /** @type {Info} */\n      let info\n      return Array.isArray(constructs) /* c8 ignore next 1 */\n        ? handleListOfConstructs(constructs)\n        : 'tokenize' in constructs\n        ? // @ts-expect-error Looks like a construct.\n          handleListOfConstructs([constructs])\n        : handleMapOfConstructs(constructs)\n\n      /**\n       * Handle a list of construct.\n       *\n       * @param {ConstructRecord} map\n       * @returns {State}\n       */\n      function handleMapOfConstructs(map) {\n        return start\n\n        /** @type {State} */\n        function start(code) {\n          const def = code !== null && map[code]\n          const all = code !== null && map.null\n          const list = [\n            // To do: add more extension tests.\n            /* c8 ignore next 2 */\n            ...(Array.isArray(def) ? def : def ? [def] : []),\n            ...(Array.isArray(all) ? all : all ? [all] : [])\n          ]\n          return handleListOfConstructs(list)(code)\n        }\n      }\n\n      /**\n       * Handle a list of construct.\n       *\n       * @param {Array<Construct>} list\n       * @returns {State}\n       */\n      function handleListOfConstructs(list) {\n        listOfConstructs = list\n        constructIndex = 0\n        if (list.length === 0) {\n          return bogusState\n        }\n        return handleConstruct(list[constructIndex])\n      }\n\n      /**\n       * Handle a single construct.\n       *\n       * @param {Construct} construct\n       * @returns {State}\n       */\n      function handleConstruct(construct) {\n        return start\n\n        /** @type {State} */\n        function start(code) {\n          // To do: not needed to store if there is no bogus state, probably?\n          // Currently doesnt work because `inspect` in document does a check\n          // w/o a bogus, which doesnt make sense. But it does seem to help perf\n          // by not storing.\n          info = store()\n          currentConstruct = construct\n          if (!construct.partial) {\n            context.currentConstruct = construct\n          }\n\n          // Always populated by defaults.\n\n          if (\n            construct.name &&\n            context.parser.constructs.disable.null.includes(construct.name)\n          ) {\n            return nok(code)\n          }\n          return construct.tokenize.call(\n            // If we do have fields, create an object w/ `context` as its\n            // prototype.\n            // This allows a live binding, which is needed for `interrupt`.\n            fields ? Object.assign(Object.create(context), fields) : context,\n            effects,\n            ok,\n            nok\n          )(code)\n        }\n      }\n\n      /** @type {State} */\n      function ok(code) {\n        consumed = true\n        onreturn(currentConstruct, info)\n        return returnState\n      }\n\n      /** @type {State} */\n      function nok(code) {\n        consumed = true\n        info.restore()\n        if (++constructIndex < listOfConstructs.length) {\n          return handleConstruct(listOfConstructs[constructIndex])\n        }\n        return bogusState\n      }\n    }\n  }\n\n  /**\n   * @param {Construct} construct\n   * @param {number} from\n   * @returns {void}\n   */\n  function addResult(construct, from) {\n    if (construct.resolveAll && !resolveAllConstructs.includes(construct)) {\n      resolveAllConstructs.push(construct)\n    }\n    if (construct.resolve) {\n      splice(\n        context.events,\n        from,\n        context.events.length - from,\n        construct.resolve(context.events.slice(from), context)\n      )\n    }\n    if (construct.resolveTo) {\n      context.events = construct.resolveTo(context.events, context)\n    }\n  }\n\n  /**\n   * Store state.\n   *\n   * @returns {Info}\n   */\n  function store() {\n    const startPoint = now()\n    const startPrevious = context.previous\n    const startCurrentConstruct = context.currentConstruct\n    const startEventsIndex = context.events.length\n    const startStack = Array.from(stack)\n    return {\n      restore,\n      from: startEventsIndex\n    }\n\n    /**\n     * Restore state.\n     *\n     * @returns {void}\n     */\n    function restore() {\n      point = startPoint\n      context.previous = startPrevious\n      context.currentConstruct = startCurrentConstruct\n      context.events.length = startEventsIndex\n      stack = startStack\n      accountForPotentialSkip()\n    }\n  }\n\n  /**\n   * Move the current point a bit forward in the line when its on a column\n   * skip.\n   *\n   * @returns {void}\n   */\n  function accountForPotentialSkip() {\n    if (point.line in columnStart && point.column < 2) {\n      point.column = columnStart[point.line]\n      point.offset += columnStart[point.line] - 1\n    }\n  }\n}\n\n/**\n * Get the chunks from a slice of chunks in the range of a token.\n *\n * @param {Array<Chunk>} chunks\n * @param {Pick<Token, 'end' | 'start'>} token\n * @returns {Array<Chunk>}\n */\nfunction sliceChunks(chunks, token) {\n  const startIndex = token.start._index\n  const startBufferIndex = token.start._bufferIndex\n  const endIndex = token.end._index\n  const endBufferIndex = token.end._bufferIndex\n  /** @type {Array<Chunk>} */\n  let view\n  if (startIndex === endIndex) {\n    // @ts-expect-error `_bufferIndex` is used on string chunks.\n    view = [chunks[startIndex].slice(startBufferIndex, endBufferIndex)]\n  } else {\n    view = chunks.slice(startIndex, endIndex)\n    if (startBufferIndex > -1) {\n      const head = view[0]\n      if (typeof head === 'string') {\n        view[0] = head.slice(startBufferIndex)\n      } else {\n        view.shift()\n      }\n    }\n    if (endBufferIndex > 0) {\n      // @ts-expect-error `_bufferIndex` is used on string chunks.\n      view.push(chunks[endIndex].slice(0, endBufferIndex))\n    }\n  }\n  return view\n}\n\n/**\n * Get the string value of a slice of chunks.\n *\n * @param {Array<Chunk>} chunks\n * @param {boolean | undefined} [expandTabs=false]\n * @returns {string}\n */\nfunction serializeChunks(chunks, expandTabs) {\n  let index = -1\n  /** @type {Array<string>} */\n  const result = []\n  /** @type {boolean | undefined} */\n  let atTab\n  while (++index < chunks.length) {\n    const chunk = chunks[index]\n    /** @type {string} */\n    let value\n    if (typeof chunk === 'string') {\n      value = chunk\n    } else\n      switch (chunk) {\n        case -5: {\n          value = '\\r'\n          break\n        }\n        case -4: {\n          value = '\\n'\n          break\n        }\n        case -3: {\n          value = '\\r' + '\\n'\n          break\n        }\n        case -2: {\n          value = expandTabs ? ' ' : '\\t'\n          break\n        }\n        case -1: {\n          if (!expandTabs && atTab) continue\n          value = ' '\n          break\n        }\n        default: {\n          // Currently only replacement character.\n          value = String.fromCharCode(chunk)\n        }\n      }\n    atTab = chunk === -2\n    result.push(value)\n  }\n  return result.join('')\n}\n","/**\n * @typedef {import('micromark-util-types').Extension} Extension\n */\n\nimport {\n  attention,\n  autolink,\n  blockQuote,\n  characterEscape,\n  characterReference,\n  codeFenced,\n  codeIndented,\n  codeText,\n  definition,\n  hardBreakEscape,\n  headingAtx,\n  htmlFlow,\n  htmlText,\n  labelEnd,\n  labelStartImage,\n  labelStartLink,\n  lineEnding,\n  list,\n  setextUnderline,\n  thematicBreak\n} from 'micromark-core-commonmark'\nimport {resolver as resolveText} from './initialize/text.js'\n\n/** @satisfies {Extension['document']} */\nexport const document = {\n  [42]: list,\n  [43]: list,\n  [45]: list,\n  [48]: list,\n  [49]: list,\n  [50]: list,\n  [51]: list,\n  [52]: list,\n  [53]: list,\n  [54]: list,\n  [55]: list,\n  [56]: list,\n  [57]: list,\n  [62]: blockQuote\n}\n\n/** @satisfies {Extension['contentInitial']} */\nexport const contentInitial = {\n  [91]: definition\n}\n\n/** @satisfies {Extension['flowInitial']} */\nexport const flowInitial = {\n  [-2]: codeIndented,\n  [-1]: codeIndented,\n  [32]: codeIndented\n}\n\n/** @satisfies {Extension['flow']} */\nexport const flow = {\n  [35]: headingAtx,\n  [42]: thematicBreak,\n  [45]: [setextUnderline, thematicBreak],\n  [60]: htmlFlow,\n  [61]: setextUnderline,\n  [95]: thematicBreak,\n  [96]: codeFenced,\n  [126]: codeFenced\n}\n\n/** @satisfies {Extension['string']} */\nexport const string = {\n  [38]: characterReference,\n  [92]: characterEscape\n}\n\n/** @satisfies {Extension['text']} */\nexport const text = {\n  [-5]: lineEnding,\n  [-4]: lineEnding,\n  [-3]: lineEnding,\n  [33]: labelStartImage,\n  [38]: characterReference,\n  [42]: attention,\n  [60]: [autolink, htmlText],\n  [91]: labelStartLink,\n  [92]: [hardBreakEscape, characterEscape],\n  [93]: labelEnd,\n  [95]: attention,\n  [96]: codeText\n}\n\n/** @satisfies {Extension['insideSpan']} */\nexport const insideSpan = {\n  null: [attention, resolveText]\n}\n\n/** @satisfies {Extension['attentionMarkers']} */\nexport const attentionMarkers = {\n  null: [42, 95]\n}\n\n/** @satisfies {Extension['disable']} */\nexport const disable = {\n  null: []\n}\n","/**\n * @typedef {import('micromark-util-types').Create} Create\n * @typedef {import('micromark-util-types').FullNormalizedExtension} FullNormalizedExtension\n * @typedef {import('micromark-util-types').InitialConstruct} InitialConstruct\n * @typedef {import('micromark-util-types').ParseContext} ParseContext\n * @typedef {import('micromark-util-types').ParseOptions} ParseOptions\n */\n\nimport {combineExtensions} from 'micromark-util-combine-extensions'\nimport {content} from './initialize/content.js'\nimport {document} from './initialize/document.js'\nimport {flow} from './initialize/flow.js'\nimport {text, string} from './initialize/text.js'\nimport {createTokenizer} from './create-tokenizer.js'\nimport * as defaultConstructs from './constructs.js'\n\n/**\n * @param {ParseOptions | null | undefined} [options]\n * @returns {ParseContext}\n */\nexport function parse(options) {\n  const settings = options || {}\n  const constructs =\n    /** @type {FullNormalizedExtension} */\n    combineExtensions([defaultConstructs, ...(settings.extensions || [])])\n\n  /** @type {ParseContext} */\n  const parser = {\n    defined: [],\n    lazy: {},\n    constructs,\n    content: create(content),\n    document: create(document),\n    flow: create(flow),\n    string: create(string),\n    text: create(text)\n  }\n  return parser\n\n  /**\n   * @param {InitialConstruct} initial\n   */\n  function create(initial) {\n    return creator\n    /** @type {Create} */\n    function creator(from) {\n      return createTokenizer(parser, initial, from)\n    }\n  }\n}\n","'use strict'\n\nvar fromCharCode = require('../constant/from-char-code.js')\n\nfunction safeFromInt(value, base) {\n  var code = parseInt(value, base)\n\n  if (\n    // C0 except for HT, LF, FF, CR, space\n    code < 9 ||\n    code === 11 ||\n    (code > 13 && code < 32) || // Control character (DEL) of the basic block and C1 controls.\n    (code > 126 && code < 160) || // Lone high surrogates and low surrogates.\n    (code > 55295 && code < 57344) || // Noncharacters.\n    (code > 64975 && code < 65008) ||\n    (code & 65535) === 65535 ||\n    (code & 65535) === 65534 || // Out of range\n    code > 1114111\n  ) {\n    return '\\uFFFD'\n  }\n\n  return fromCharCode(code)\n}\n\nmodule.exports = safeFromInt\n","/**\n * @import {\n *   InitialConstruct,\n *   Initializer,\n *   State,\n *   TokenizeContext,\n *   Token\n * } from 'micromark-util-types'\n */\n\nimport { factorySpace } from 'micromark-factory-space';\nimport { markdownLineEnding } from 'micromark-util-character';\n/** @type {InitialConstruct} */\nexport const content = {\n  tokenize: initializeContent\n};\n\n/**\n * @this {TokenizeContext}\n *   Context.\n * @type {Initializer}\n *   Content.\n */\nfunction initializeContent(effects) {\n  const contentStart = effects.attempt(this.parser.constructs.contentInitial, afterContentStartConstruct, paragraphInitial);\n  /** @type {Token} */\n  let previous;\n  return contentStart;\n\n  /** @type {State} */\n  function afterContentStartConstruct(code) {\n    if (code === null) {\n      effects.consume(code);\n      return;\n    }\n    effects.enter(\"lineEnding\");\n    effects.consume(code);\n    effects.exit(\"lineEnding\");\n    return factorySpace(effects, contentStart, \"linePrefix\");\n  }\n\n  /** @type {State} */\n  function paragraphInitial(code) {\n    effects.enter(\"paragraph\");\n    return lineStart(code);\n  }\n\n  /** @type {State} */\n  function lineStart(code) {\n    const token = effects.enter(\"chunkText\", {\n      contentType: \"text\",\n      previous\n    });\n    if (previous) {\n      previous.next = token;\n    }\n    previous = token;\n    return data(code);\n  }\n\n  /** @type {State} */\n  function data(code) {\n    if (code === null) {\n      effects.exit(\"chunkText\");\n      effects.exit(\"paragraph\");\n      effects.consume(code);\n      return;\n    }\n    if (markdownLineEnding(code)) {\n      effects.consume(code);\n      effects.exit(\"chunkText\");\n      return lineStart;\n    }\n\n    // Data.\n    effects.consume(code);\n    return data;\n  }\n}","/**\n * @import {\n *   Construct,\n *   ContainerState,\n *   InitialConstruct,\n *   Initializer,\n *   Point,\n *   State,\n *   TokenizeContext,\n *   Tokenizer,\n *   Token\n * } from 'micromark-util-types'\n */\n\n/**\n * @typedef {[Construct, ContainerState]} StackItem\n *   Construct and its state.\n */\n\nimport { factorySpace } from 'micromark-factory-space';\nimport { markdownLineEnding } from 'micromark-util-character';\nimport { splice } from 'micromark-util-chunked';\n/** @type {InitialConstruct} */\nexport const document = {\n  tokenize: initializeDocument\n};\n\n/** @type {Construct} */\nconst containerConstruct = {\n  tokenize: tokenizeContainer\n};\n\n/**\n * @this {TokenizeContext}\n *   Self.\n * @type {Initializer}\n *   Initializer.\n */\nfunction initializeDocument(effects) {\n  const self = this;\n  /** @type {Array<StackItem>} */\n  const stack = [];\n  let continued = 0;\n  /** @type {TokenizeContext | undefined} */\n  let childFlow;\n  /** @type {Token | undefined} */\n  let childToken;\n  /** @type {number} */\n  let lineStartOffset;\n  return start;\n\n  /** @type {State} */\n  function start(code) {\n    // First we iterate through the open blocks, starting with the root\n    // document, and descending through last children down to the last open\n    // block.\n    // Each block imposes a condition that the line must satisfy if the block is\n    // to remain open.\n    // For example, a block quote requires a `>` character.\n    // A paragraph requires a non-blank line.\n    // In this phase we may match all or just some of the open blocks.\n    // But we cannot close unmatched blocks yet, because we may have a lazy\n    // continuation line.\n    if (continued < stack.length) {\n      const item = stack[continued];\n      self.containerState = item[1];\n      return effects.attempt(item[0].continuation, documentContinue, checkNewContainers)(code);\n    }\n\n    // Done.\n    return checkNewContainers(code);\n  }\n\n  /** @type {State} */\n  function documentContinue(code) {\n    continued++;\n\n    // Note: this field is called `_closeFlow` but it also closes containers.\n    // Perhaps a good idea to rename it but its already used in the wild by\n    // extensions.\n    if (self.containerState._closeFlow) {\n      self.containerState._closeFlow = undefined;\n      if (childFlow) {\n        closeFlow();\n      }\n\n      // Note: this algorithm for moving events around is similar to the\n      // algorithm when dealing with lazy lines in `writeToChild`.\n      const indexBeforeExits = self.events.length;\n      let indexBeforeFlow = indexBeforeExits;\n      /** @type {Point | undefined} */\n      let point;\n\n      // Find the flow chunk.\n      while (indexBeforeFlow--) {\n        if (self.events[indexBeforeFlow][0] === 'exit' && self.events[indexBeforeFlow][1].type === \"chunkFlow\") {\n          point = self.events[indexBeforeFlow][1].end;\n          break;\n        }\n      }\n      exitContainers(continued);\n\n      // Fix positions.\n      let index = indexBeforeExits;\n      while (index < self.events.length) {\n        self.events[index][1].end = {\n          ...point\n        };\n        index++;\n      }\n\n      // Inject the exits earlier (theyre still also at the end).\n      splice(self.events, indexBeforeFlow + 1, 0, self.events.slice(indexBeforeExits));\n\n      // Discard the duplicate exits.\n      self.events.length = index;\n      return checkNewContainers(code);\n    }\n    return start(code);\n  }\n\n  /** @type {State} */\n  function checkNewContainers(code) {\n    // Next, after consuming the continuation markers for existing blocks, we\n    // look for new block starts (e.g. `>` for a block quote).\n    // If we encounter a new block start, we close any blocks unmatched in\n    // step 1 before creating the new block as a child of the last matched\n    // block.\n    if (continued === stack.length) {\n      // No need to `check` whether theres a container, of `exitContainers`\n      // would be moot.\n      // We can instead immediately `attempt` to parse one.\n      if (!childFlow) {\n        return documentContinued(code);\n      }\n\n      // If we have concrete content, such as block HTML or fenced code,\n      // we cant have containers pierce into them, so we can immediately\n      // start.\n      if (childFlow.currentConstruct && childFlow.currentConstruct.concrete) {\n        return flowStart(code);\n      }\n\n      // If we do have flow, it could still be a blank line,\n      // but wed be interrupting it w/ a new container if theres a current\n      // construct.\n      // To do: next major: remove `_gfmTableDynamicInterruptHack` (no longer\n      // needed in micromark-extension-gfm-table@1.0.6).\n      self.interrupt = Boolean(childFlow.currentConstruct && !childFlow._gfmTableDynamicInterruptHack);\n    }\n\n    // Check if there is a new container.\n    self.containerState = {};\n    return effects.check(containerConstruct, thereIsANewContainer, thereIsNoNewContainer)(code);\n  }\n\n  /** @type {State} */\n  function thereIsANewContainer(code) {\n    if (childFlow) closeFlow();\n    exitContainers(continued);\n    return documentContinued(code);\n  }\n\n  /** @type {State} */\n  function thereIsNoNewContainer(code) {\n    self.parser.lazy[self.now().line] = continued !== stack.length;\n    lineStartOffset = self.now().offset;\n    return flowStart(code);\n  }\n\n  /** @type {State} */\n  function documentContinued(code) {\n    // Try new containers.\n    self.containerState = {};\n    return effects.attempt(containerConstruct, containerContinue, flowStart)(code);\n  }\n\n  /** @type {State} */\n  function containerContinue(code) {\n    continued++;\n    stack.push([self.currentConstruct, self.containerState]);\n    // Try another.\n    return documentContinued(code);\n  }\n\n  /** @type {State} */\n  function flowStart(code) {\n    if (code === null) {\n      if (childFlow) closeFlow();\n      exitContainers(0);\n      effects.consume(code);\n      return;\n    }\n    childFlow = childFlow || self.parser.flow(self.now());\n    effects.enter(\"chunkFlow\", {\n      _tokenizer: childFlow,\n      contentType: \"flow\",\n      previous: childToken\n    });\n    return flowContinue(code);\n  }\n\n  /** @type {State} */\n  function flowContinue(code) {\n    if (code === null) {\n      writeToChild(effects.exit(\"chunkFlow\"), true);\n      exitContainers(0);\n      effects.consume(code);\n      return;\n    }\n    if (markdownLineEnding(code)) {\n      effects.consume(code);\n      writeToChild(effects.exit(\"chunkFlow\"));\n      // Get ready for the next line.\n      continued = 0;\n      self.interrupt = undefined;\n      return start;\n    }\n    effects.consume(code);\n    return flowContinue;\n  }\n\n  /**\n   * @param {Token} token\n   *   Token.\n   * @param {boolean | undefined} [endOfFile]\n   *   Whether the token is at the end of the file (default: `false`).\n   * @returns {undefined}\n   *   Nothing.\n   */\n  function writeToChild(token, endOfFile) {\n    const stream = self.sliceStream(token);\n    if (endOfFile) stream.push(null);\n    token.previous = childToken;\n    if (childToken) childToken.next = token;\n    childToken = token;\n    childFlow.defineSkip(token.start);\n    childFlow.write(stream);\n\n    // Alright, so we just added a lazy line:\n    //\n    // ```markdown\n    // > a\n    // b.\n    //\n    // Or:\n    //\n    // > ~~~c\n    // d\n    //\n    // Or:\n    //\n    // > | e |\n    // f\n    // ```\n    //\n    // The construct in the second example (fenced code) does not accept lazy\n    // lines, so it marked itself as done at the end of its first line, and\n    // then the content construct parses `d`.\n    // Most constructs in markdown match on the first line: if the first line\n    // forms a construct, a non-lazy line cant unmake it.\n    //\n    // The construct in the third example is potentially a GFM table, and\n    // those are *weird*.\n    // It *could* be a table, from the first line, if the following line\n    // matches a condition.\n    // In this case, that second line is lazy, which unmakes the first line\n    // and turns the whole into one content block.\n    //\n    // Weve now parsed the non-lazy and the lazy line, and can figure out\n    // whether the lazy line started a new flow block.\n    // If it did, we exit the current containers between the two flow blocks.\n    if (self.parser.lazy[token.start.line]) {\n      let index = childFlow.events.length;\n      while (index--) {\n        if (\n        // The token starts before the line ending\n        childFlow.events[index][1].start.offset < lineStartOffset && (\n        // and either is not ended yet\n        !childFlow.events[index][1].end ||\n        // or ends after it.\n        childFlow.events[index][1].end.offset > lineStartOffset)) {\n          // Exit: theres still something open, which means its a lazy line\n          // part of something.\n          return;\n        }\n      }\n\n      // Note: this algorithm for moving events around is similar to the\n      // algorithm when closing flow in `documentContinue`.\n      const indexBeforeExits = self.events.length;\n      let indexBeforeFlow = indexBeforeExits;\n      /** @type {boolean | undefined} */\n      let seen;\n      /** @type {Point | undefined} */\n      let point;\n\n      // Find the previous chunk (the one before the lazy line).\n      while (indexBeforeFlow--) {\n        if (self.events[indexBeforeFlow][0] === 'exit' && self.events[indexBeforeFlow][1].type === \"chunkFlow\") {\n          if (seen) {\n            point = self.events[indexBeforeFlow][1].end;\n            break;\n          }\n          seen = true;\n        }\n      }\n      exitContainers(continued);\n\n      // Fix positions.\n      index = indexBeforeExits;\n      while (index < self.events.length) {\n        self.events[index][1].end = {\n          ...point\n        };\n        index++;\n      }\n\n      // Inject the exits earlier (theyre still also at the end).\n      splice(self.events, indexBeforeFlow + 1, 0, self.events.slice(indexBeforeExits));\n\n      // Discard the duplicate exits.\n      self.events.length = index;\n    }\n  }\n\n  /**\n   * @param {number} size\n   *   Size.\n   * @returns {undefined}\n   *   Nothing.\n   */\n  function exitContainers(size) {\n    let index = stack.length;\n\n    // Exit open containers.\n    while (index-- > size) {\n      const entry = stack[index];\n      self.containerState = entry[1];\n      entry[0].exit.call(self, effects);\n    }\n    stack.length = size;\n  }\n  function closeFlow() {\n    childFlow.write([null]);\n    childToken = undefined;\n    childFlow = undefined;\n    self.containerState._closeFlow = undefined;\n  }\n}\n\n/**\n * @this {TokenizeContext}\n *   Context.\n * @type {Tokenizer}\n *   Tokenizer.\n */\nfunction tokenizeContainer(effects, ok, nok) {\n  // Always populated by defaults.\n\n  return factorySpace(effects, effects.attempt(this.parser.constructs.document, ok, nok), \"linePrefix\", this.parser.constructs.disable.null.includes('codeIndented') ? undefined : 4);\n}","/**\n * @import {\n *   InitialConstruct,\n *   Initializer,\n *   State,\n *   TokenizeContext\n * } from 'micromark-util-types'\n */\n\nimport { blankLine, content } from 'micromark-core-commonmark';\nimport { factorySpace } from 'micromark-factory-space';\nimport { markdownLineEnding } from 'micromark-util-character';\n/** @type {InitialConstruct} */\nexport const flow = {\n  tokenize: initializeFlow\n};\n\n/**\n * @this {TokenizeContext}\n *   Self.\n * @type {Initializer}\n *   Initializer.\n */\nfunction initializeFlow(effects) {\n  const self = this;\n  const initial = effects.attempt(\n  // Try to parse a blank line.\n  blankLine, atBlankEnding,\n  // Try to parse initial flow (essentially, only code).\n  effects.attempt(this.parser.constructs.flowInitial, afterConstruct, factorySpace(effects, effects.attempt(this.parser.constructs.flow, afterConstruct, effects.attempt(content, afterConstruct)), \"linePrefix\")));\n  return initial;\n\n  /** @type {State} */\n  function atBlankEnding(code) {\n    if (code === null) {\n      effects.consume(code);\n      return;\n    }\n    effects.enter(\"lineEndingBlank\");\n    effects.consume(code);\n    effects.exit(\"lineEndingBlank\");\n    self.currentConstruct = undefined;\n    return initial;\n  }\n\n  /** @type {State} */\n  function afterConstruct(code) {\n    if (code === null) {\n      effects.consume(code);\n      return;\n    }\n    effects.enter(\"lineEnding\");\n    effects.consume(code);\n    effects.exit(\"lineEnding\");\n    self.currentConstruct = undefined;\n    return initial;\n  }\n}","/**\n * @import {\n *   Code,\n *   InitialConstruct,\n *   Initializer,\n *   Resolver,\n *   State,\n *   TokenizeContext\n * } from 'micromark-util-types'\n */\n\nexport const resolver = {\n  resolveAll: createResolver()\n};\nexport const string = initializeFactory('string');\nexport const text = initializeFactory('text');\n\n/**\n * @param {'string' | 'text'} field\n *   Field.\n * @returns {InitialConstruct}\n *   Construct.\n */\nfunction initializeFactory(field) {\n  return {\n    resolveAll: createResolver(field === 'text' ? resolveAllLineSuffixes : undefined),\n    tokenize: initializeText\n  };\n\n  /**\n   * @this {TokenizeContext}\n   *   Context.\n   * @type {Initializer}\n   */\n  function initializeText(effects) {\n    const self = this;\n    const constructs = this.parser.constructs[field];\n    const text = effects.attempt(constructs, start, notText);\n    return start;\n\n    /** @type {State} */\n    function start(code) {\n      return atBreak(code) ? text(code) : notText(code);\n    }\n\n    /** @type {State} */\n    function notText(code) {\n      if (code === null) {\n        effects.consume(code);\n        return;\n      }\n      effects.enter(\"data\");\n      effects.consume(code);\n      return data;\n    }\n\n    /** @type {State} */\n    function data(code) {\n      if (atBreak(code)) {\n        effects.exit(\"data\");\n        return text(code);\n      }\n\n      // Data.\n      effects.consume(code);\n      return data;\n    }\n\n    /**\n     * @param {Code} code\n     *   Code.\n     * @returns {boolean}\n     *   Whether the code is a break.\n     */\n    function atBreak(code) {\n      if (code === null) {\n        return true;\n      }\n      const list = constructs[code];\n      let index = -1;\n      if (list) {\n        // Always populated by defaults.\n\n        while (++index < list.length) {\n          const item = list[index];\n          if (!item.previous || item.previous.call(self, self.previous)) {\n            return true;\n          }\n        }\n      }\n      return false;\n    }\n  }\n}\n\n/**\n * @param {Resolver | undefined} [extraResolver]\n *   Resolver.\n * @returns {Resolver}\n *   Resolver.\n */\nfunction createResolver(extraResolver) {\n  return resolveAllText;\n\n  /** @type {Resolver} */\n  function resolveAllText(events, context) {\n    let index = -1;\n    /** @type {number | undefined} */\n    let enter;\n\n    // A rather boring computation (to merge adjacent `data` events) which\n    // improves mm performance by 29%.\n    while (++index <= events.length) {\n      if (enter === undefined) {\n        if (events[index] && events[index][1].type === \"data\") {\n          enter = index;\n          index++;\n        }\n      } else if (!events[index] || events[index][1].type !== \"data\") {\n        // Dont do anything if there is one data token.\n        if (index !== enter + 2) {\n          events[enter][1].end = events[index - 1][1].end;\n          events.splice(enter + 2, index - enter - 2);\n          index = enter + 2;\n        }\n        enter = undefined;\n      }\n    }\n    return extraResolver ? extraResolver(events, context) : events;\n  }\n}\n\n/**\n * A rather ugly set of instructions which again looks at chunks in the input\n * stream.\n * The reason to do this here is that it is *much* faster to parse in reverse.\n * And that we cant hook into `null` to split the line suffix before an EOF.\n * To do: figure out if we can make this into a clean utility, or even in core.\n * As it will be useful for GFMs literal autolink extension (and maybe even\n * tables?)\n *\n * @type {Resolver}\n */\nfunction resolveAllLineSuffixes(events, context) {\n  let eventIndex = 0; // Skip first.\n\n  while (++eventIndex <= events.length) {\n    if ((eventIndex === events.length || events[eventIndex][1].type === \"lineEnding\") && events[eventIndex - 1][1].type === \"data\") {\n      const data = events[eventIndex - 1][1];\n      const chunks = context.sliceStream(data);\n      let index = chunks.length;\n      let bufferIndex = -1;\n      let size = 0;\n      /** @type {boolean | undefined} */\n      let tabs;\n      while (index--) {\n        const chunk = chunks[index];\n        if (typeof chunk === 'string') {\n          bufferIndex = chunk.length;\n          while (chunk.charCodeAt(bufferIndex - 1) === 32) {\n            size++;\n            bufferIndex--;\n          }\n          if (bufferIndex) break;\n          bufferIndex = -1;\n        }\n        // Number\n        else if (chunk === -2) {\n          tabs = true;\n          size++;\n        } else if (chunk === -1) {\n          // Empty\n        } else {\n          // Replacement character, exit.\n          index++;\n          break;\n        }\n      }\n\n      // Allow final trailing whitespace.\n      if (context._contentTypeTextTrailing && eventIndex === events.length) {\n        size = 0;\n      }\n      if (size) {\n        const token = {\n          type: eventIndex === events.length || tabs || size < 2 ? \"lineSuffix\" : \"hardBreakTrailing\",\n          start: {\n            _bufferIndex: index ? bufferIndex : data.start._bufferIndex + bufferIndex,\n            _index: data.start._index + index,\n            line: data.end.line,\n            column: data.end.column - size,\n            offset: data.end.offset - size\n          },\n          end: {\n            ...data.end\n          }\n        };\n        data.end = {\n          ...token.start\n        };\n        if (data.start.offset === data.end.offset) {\n          Object.assign(data, token);\n        } else {\n          events.splice(eventIndex, 0, ['enter', token, context], ['exit', token, context]);\n          eventIndex += 2;\n        }\n      }\n      eventIndex++;\n    }\n  }\n  return events;\n}","/**\n * @import {Extension} from 'micromark-util-types'\n */\n\nimport { attention, autolink, blockQuote, characterEscape, characterReference, codeFenced, codeIndented, codeText, definition, hardBreakEscape, headingAtx, htmlFlow, htmlText, labelEnd, labelStartImage, labelStartLink, lineEnding, list, setextUnderline, thematicBreak } from 'micromark-core-commonmark';\nimport { resolver as resolveText } from './initialize/text.js';\n\n/** @satisfies {Extension['document']} */\nexport const document = {\n  [42]: list,\n  [43]: list,\n  [45]: list,\n  [48]: list,\n  [49]: list,\n  [50]: list,\n  [51]: list,\n  [52]: list,\n  [53]: list,\n  [54]: list,\n  [55]: list,\n  [56]: list,\n  [57]: list,\n  [62]: blockQuote\n};\n\n/** @satisfies {Extension['contentInitial']} */\nexport const contentInitial = {\n  [91]: definition\n};\n\n/** @satisfies {Extension['flowInitial']} */\nexport const flowInitial = {\n  [-2]: codeIndented,\n  [-1]: codeIndented,\n  [32]: codeIndented\n};\n\n/** @satisfies {Extension['flow']} */\nexport const flow = {\n  [35]: headingAtx,\n  [42]: thematicBreak,\n  [45]: [setextUnderline, thematicBreak],\n  [60]: htmlFlow,\n  [61]: setextUnderline,\n  [95]: thematicBreak,\n  [96]: codeFenced,\n  [126]: codeFenced\n};\n\n/** @satisfies {Extension['string']} */\nexport const string = {\n  [38]: characterReference,\n  [92]: characterEscape\n};\n\n/** @satisfies {Extension['text']} */\nexport const text = {\n  [-5]: lineEnding,\n  [-4]: lineEnding,\n  [-3]: lineEnding,\n  [33]: labelStartImage,\n  [38]: characterReference,\n  [42]: attention,\n  [60]: [autolink, htmlText],\n  [91]: labelStartLink,\n  [92]: [hardBreakEscape, characterEscape],\n  [93]: labelEnd,\n  [95]: attention,\n  [96]: codeText\n};\n\n/** @satisfies {Extension['insideSpan']} */\nexport const insideSpan = {\n  null: [attention, resolveText]\n};\n\n/** @satisfies {Extension['attentionMarkers']} */\nexport const attentionMarkers = {\n  null: [42, 95]\n};\n\n/** @satisfies {Extension['disable']} */\nexport const disable = {\n  null: []\n};","/**\n * @import {\n *   Chunk,\n *   Code,\n *   ConstructRecord,\n *   Construct,\n *   Effects,\n *   InitialConstruct,\n *   ParseContext,\n *   Point,\n *   State,\n *   TokenizeContext,\n *   Token\n * } from 'micromark-util-types'\n */\n\n/**\n * @callback Restore\n *   Restore the state.\n * @returns {undefined}\n *   Nothing.\n *\n * @typedef Info\n *   Info.\n * @property {Restore} restore\n *   Restore.\n * @property {number} from\n *   From.\n *\n * @callback ReturnHandle\n *   Handle a successful run.\n * @param {Construct} construct\n *   Construct.\n * @param {Info} info\n *   Info.\n * @returns {undefined}\n *   Nothing.\n */\n\nimport { markdownLineEnding } from 'micromark-util-character';\nimport { push, splice } from 'micromark-util-chunked';\nimport { resolveAll } from 'micromark-util-resolve-all';\n/**\n * Create a tokenizer.\n * Tokenizers deal with one type of data (e.g., containers, flow, text).\n * The parser is the object dealing with it all.\n * `initialize` works like other constructs, except that only its `tokenize`\n * function is used, in which case it doesnt receive an `ok` or `nok`.\n * `from` can be given to set the point before the first character, although\n * when further lines are indented, they must be set with `defineSkip`.\n *\n * @param {ParseContext} parser\n *   Parser.\n * @param {InitialConstruct} initialize\n *   Construct.\n * @param {Omit<Point, '_bufferIndex' | '_index'> | undefined} [from]\n *   Point (optional).\n * @returns {TokenizeContext}\n *   Context.\n */\nexport function createTokenizer(parser, initialize, from) {\n  /** @type {Point} */\n  let point = {\n    _bufferIndex: -1,\n    _index: 0,\n    line: from && from.line || 1,\n    column: from && from.column || 1,\n    offset: from && from.offset || 0\n  };\n  /** @type {Record<string, number>} */\n  const columnStart = {};\n  /** @type {Array<Construct>} */\n  const resolveAllConstructs = [];\n  /** @type {Array<Chunk>} */\n  let chunks = [];\n  /** @type {Array<Token>} */\n  let stack = [];\n  /** @type {boolean | undefined} */\n  let consumed = true;\n\n  /**\n   * Tools used for tokenizing.\n   *\n   * @type {Effects}\n   */\n  const effects = {\n    attempt: constructFactory(onsuccessfulconstruct),\n    check: constructFactory(onsuccessfulcheck),\n    consume,\n    enter,\n    exit,\n    interrupt: constructFactory(onsuccessfulcheck, {\n      interrupt: true\n    })\n  };\n\n  /**\n   * State and tools for resolving and serializing.\n   *\n   * @type {TokenizeContext}\n   */\n  const context = {\n    code: null,\n    containerState: {},\n    defineSkip,\n    events: [],\n    now,\n    parser,\n    previous: null,\n    sliceSerialize,\n    sliceStream,\n    write\n  };\n\n  /**\n   * The state function.\n   *\n   * @type {State | undefined}\n   */\n  let state = initialize.tokenize.call(context, effects);\n\n  /**\n   * Track which character we expect to be consumed, to catch bugs.\n   *\n   * @type {Code}\n   */\n  let expectedCode;\n  if (initialize.resolveAll) {\n    resolveAllConstructs.push(initialize);\n  }\n  return context;\n\n  /** @type {TokenizeContext['write']} */\n  function write(slice) {\n    chunks = push(chunks, slice);\n    main();\n\n    // Exit if were not done, resolve might change stuff.\n    if (chunks[chunks.length - 1] !== null) {\n      return [];\n    }\n    addResult(initialize, 0);\n\n    // Otherwise, resolve, and exit.\n    context.events = resolveAll(resolveAllConstructs, context.events, context);\n    return context.events;\n  }\n\n  //\n  // Tools.\n  //\n\n  /** @type {TokenizeContext['sliceSerialize']} */\n  function sliceSerialize(token, expandTabs) {\n    return serializeChunks(sliceStream(token), expandTabs);\n  }\n\n  /** @type {TokenizeContext['sliceStream']} */\n  function sliceStream(token) {\n    return sliceChunks(chunks, token);\n  }\n\n  /** @type {TokenizeContext['now']} */\n  function now() {\n    // This is a hot path, so we clone manually instead of `Object.assign({}, point)`\n    const {\n      _bufferIndex,\n      _index,\n      line,\n      column,\n      offset\n    } = point;\n    return {\n      _bufferIndex,\n      _index,\n      line,\n      column,\n      offset\n    };\n  }\n\n  /** @type {TokenizeContext['defineSkip']} */\n  function defineSkip(value) {\n    columnStart[value.line] = value.column;\n    accountForPotentialSkip();\n  }\n\n  //\n  // State management.\n  //\n\n  /**\n   * Main loop (note that `_index` and `_bufferIndex` in `point` are modified by\n   * `consume`).\n   * Here is where we walk through the chunks, which either include strings of\n   * several characters, or numerical character codes.\n   * The reason to do this in a loop instead of a call is so the stack can\n   * drain.\n   *\n   * @returns {undefined}\n   *   Nothing.\n   */\n  function main() {\n    /** @type {number} */\n    let chunkIndex;\n    while (point._index < chunks.length) {\n      const chunk = chunks[point._index];\n\n      // If were in a buffer chunk, loop through it.\n      if (typeof chunk === 'string') {\n        chunkIndex = point._index;\n        if (point._bufferIndex < 0) {\n          point._bufferIndex = 0;\n        }\n        while (point._index === chunkIndex && point._bufferIndex < chunk.length) {\n          go(chunk.charCodeAt(point._bufferIndex));\n        }\n      } else {\n        go(chunk);\n      }\n    }\n  }\n\n  /**\n   * Deal with one code.\n   *\n   * @param {Code} code\n   *   Code.\n   * @returns {undefined}\n   *   Nothing.\n   */\n  function go(code) {\n    consumed = undefined;\n    expectedCode = code;\n    state = state(code);\n  }\n\n  /** @type {Effects['consume']} */\n  function consume(code) {\n    if (markdownLineEnding(code)) {\n      point.line++;\n      point.column = 1;\n      point.offset += code === -3 ? 2 : 1;\n      accountForPotentialSkip();\n    } else if (code !== -1) {\n      point.column++;\n      point.offset++;\n    }\n\n    // Not in a string chunk.\n    if (point._bufferIndex < 0) {\n      point._index++;\n    } else {\n      point._bufferIndex++;\n\n      // At end of string chunk.\n      if (point._bufferIndex ===\n      // Points w/ non-negative `_bufferIndex` reference\n      // strings.\n      /** @type {string} */\n      chunks[point._index].length) {\n        point._bufferIndex = -1;\n        point._index++;\n      }\n    }\n\n    // Expose the previous character.\n    context.previous = code;\n\n    // Mark as consumed.\n    consumed = true;\n  }\n\n  /** @type {Effects['enter']} */\n  function enter(type, fields) {\n    /** @type {Token} */\n    // @ts-expect-error Patch instead of assign required fields to help GC.\n    const token = fields || {};\n    token.type = type;\n    token.start = now();\n    context.events.push(['enter', token, context]);\n    stack.push(token);\n    return token;\n  }\n\n  /** @type {Effects['exit']} */\n  function exit(type) {\n    const token = stack.pop();\n    token.end = now();\n    context.events.push(['exit', token, context]);\n    return token;\n  }\n\n  /**\n   * Use results.\n   *\n   * @type {ReturnHandle}\n   */\n  function onsuccessfulconstruct(construct, info) {\n    addResult(construct, info.from);\n  }\n\n  /**\n   * Discard results.\n   *\n   * @type {ReturnHandle}\n   */\n  function onsuccessfulcheck(_, info) {\n    info.restore();\n  }\n\n  /**\n   * Factory to attempt/check/interrupt.\n   *\n   * @param {ReturnHandle} onreturn\n   *   Callback.\n   * @param {{interrupt?: boolean | undefined} | undefined} [fields]\n   *   Fields.\n   */\n  function constructFactory(onreturn, fields) {\n    return hook;\n\n    /**\n     * Handle either an object mapping codes to constructs, a list of\n     * constructs, or a single construct.\n     *\n     * @param {Array<Construct> | ConstructRecord | Construct} constructs\n     *   Constructs.\n     * @param {State} returnState\n     *   State.\n     * @param {State | undefined} [bogusState]\n     *   State.\n     * @returns {State}\n     *   State.\n     */\n    function hook(constructs, returnState, bogusState) {\n      /** @type {ReadonlyArray<Construct>} */\n      let listOfConstructs;\n      /** @type {number} */\n      let constructIndex;\n      /** @type {Construct} */\n      let currentConstruct;\n      /** @type {Info} */\n      let info;\n      return Array.isArray(constructs) ? /* c8 ignore next 1 */\n      handleListOfConstructs(constructs) : 'tokenize' in constructs ?\n      // Looks like a construct.\n      handleListOfConstructs([(/** @type {Construct} */constructs)]) : handleMapOfConstructs(constructs);\n\n      /**\n       * Handle a list of construct.\n       *\n       * @param {ConstructRecord} map\n       *   Constructs.\n       * @returns {State}\n       *   State.\n       */\n      function handleMapOfConstructs(map) {\n        return start;\n\n        /** @type {State} */\n        function start(code) {\n          const left = code !== null && map[code];\n          const all = code !== null && map.null;\n          const list = [\n          // To do: add more extension tests.\n          /* c8 ignore next 2 */\n          ...(Array.isArray(left) ? left : left ? [left] : []), ...(Array.isArray(all) ? all : all ? [all] : [])];\n          return handleListOfConstructs(list)(code);\n        }\n      }\n\n      /**\n       * Handle a list of construct.\n       *\n       * @param {ReadonlyArray<Construct>} list\n       *   Constructs.\n       * @returns {State}\n       *   State.\n       */\n      function handleListOfConstructs(list) {\n        listOfConstructs = list;\n        constructIndex = 0;\n        if (list.length === 0) {\n          return bogusState;\n        }\n        return handleConstruct(list[constructIndex]);\n      }\n\n      /**\n       * Handle a single construct.\n       *\n       * @param {Construct} construct\n       *   Construct.\n       * @returns {State}\n       *   State.\n       */\n      function handleConstruct(construct) {\n        return start;\n\n        /** @type {State} */\n        function start(code) {\n          // To do: not needed to store if there is no bogus state, probably?\n          // Currently doesnt work because `inspect` in document does a check\n          // w/o a bogus, which doesnt make sense. But it does seem to help perf\n          // by not storing.\n          info = store();\n          currentConstruct = construct;\n          if (!construct.partial) {\n            context.currentConstruct = construct;\n          }\n\n          // Always populated by defaults.\n\n          if (construct.name && context.parser.constructs.disable.null.includes(construct.name)) {\n            return nok(code);\n          }\n          return construct.tokenize.call(\n          // If we do have fields, create an object w/ `context` as its\n          // prototype.\n          // This allows a live binding, which is needed for `interrupt`.\n          fields ? Object.assign(Object.create(context), fields) : context, effects, ok, nok)(code);\n        }\n      }\n\n      /** @type {State} */\n      function ok(code) {\n        consumed = true;\n        onreturn(currentConstruct, info);\n        return returnState;\n      }\n\n      /** @type {State} */\n      function nok(code) {\n        consumed = true;\n        info.restore();\n        if (++constructIndex < listOfConstructs.length) {\n          return handleConstruct(listOfConstructs[constructIndex]);\n        }\n        return bogusState;\n      }\n    }\n  }\n\n  /**\n   * @param {Construct} construct\n   *   Construct.\n   * @param {number} from\n   *   From.\n   * @returns {undefined}\n   *   Nothing.\n   */\n  function addResult(construct, from) {\n    if (construct.resolveAll && !resolveAllConstructs.includes(construct)) {\n      resolveAllConstructs.push(construct);\n    }\n    if (construct.resolve) {\n      splice(context.events, from, context.events.length - from, construct.resolve(context.events.slice(from), context));\n    }\n    if (construct.resolveTo) {\n      context.events = construct.resolveTo(context.events, context);\n    }\n  }\n\n  /**\n   * Store state.\n   *\n   * @returns {Info}\n   *   Info.\n   */\n  function store() {\n    const startPoint = now();\n    const startPrevious = context.previous;\n    const startCurrentConstruct = context.currentConstruct;\n    const startEventsIndex = context.events.length;\n    const startStack = Array.from(stack);\n    return {\n      from: startEventsIndex,\n      restore\n    };\n\n    /**\n     * Restore state.\n     *\n     * @returns {undefined}\n     *   Nothing.\n     */\n    function restore() {\n      point = startPoint;\n      context.previous = startPrevious;\n      context.currentConstruct = startCurrentConstruct;\n      context.events.length = startEventsIndex;\n      stack = startStack;\n      accountForPotentialSkip();\n    }\n  }\n\n  /**\n   * Move the current point a bit forward in the line when its on a column\n   * skip.\n   *\n   * @returns {undefined}\n   *   Nothing.\n   */\n  function accountForPotentialSkip() {\n    if (point.line in columnStart && point.column < 2) {\n      point.column = columnStart[point.line];\n      point.offset += columnStart[point.line] - 1;\n    }\n  }\n}\n\n/**\n * Get the chunks from a slice of chunks in the range of a token.\n *\n * @param {ReadonlyArray<Chunk>} chunks\n *   Chunks.\n * @param {Pick<Token, 'end' | 'start'>} token\n *   Token.\n * @returns {Array<Chunk>}\n *   Chunks.\n */\nfunction sliceChunks(chunks, token) {\n  const startIndex = token.start._index;\n  const startBufferIndex = token.start._bufferIndex;\n  const endIndex = token.end._index;\n  const endBufferIndex = token.end._bufferIndex;\n  /** @type {Array<Chunk>} */\n  let view;\n  if (startIndex === endIndex) {\n    // @ts-expect-error `_bufferIndex` is used on string chunks.\n    view = [chunks[startIndex].slice(startBufferIndex, endBufferIndex)];\n  } else {\n    view = chunks.slice(startIndex, endIndex);\n    if (startBufferIndex > -1) {\n      const head = view[0];\n      if (typeof head === 'string') {\n        view[0] = head.slice(startBufferIndex);\n        /* c8 ignore next 4 -- used to be used, no longer */\n      } else {\n        view.shift();\n      }\n    }\n    if (endBufferIndex > 0) {\n      // @ts-expect-error `_bufferIndex` is used on string chunks.\n      view.push(chunks[endIndex].slice(0, endBufferIndex));\n    }\n  }\n  return view;\n}\n\n/**\n * Get the string value of a slice of chunks.\n *\n * @param {ReadonlyArray<Chunk>} chunks\n *   Chunks.\n * @param {boolean | undefined} [expandTabs=false]\n *   Whether to expand tabs (default: `false`).\n * @returns {string}\n *   Result.\n */\nfunction serializeChunks(chunks, expandTabs) {\n  let index = -1;\n  /** @type {Array<string>} */\n  const result = [];\n  /** @type {boolean | undefined} */\n  let atTab;\n  while (++index < chunks.length) {\n    const chunk = chunks[index];\n    /** @type {string} */\n    let value;\n    if (typeof chunk === 'string') {\n      value = chunk;\n    } else switch (chunk) {\n      case -5:\n        {\n          value = \"\\r\";\n          break;\n        }\n      case -4:\n        {\n          value = \"\\n\";\n          break;\n        }\n      case -3:\n        {\n          value = \"\\r\" + \"\\n\";\n          break;\n        }\n      case -2:\n        {\n          value = expandTabs ? \" \" : \"\\t\";\n          break;\n        }\n      case -1:\n        {\n          if (!expandTabs && atTab) continue;\n          value = \" \";\n          break;\n        }\n      default:\n        {\n          // Currently only replacement character.\n          value = String.fromCharCode(chunk);\n        }\n    }\n    atTab = chunk === -2;\n    result.push(value);\n  }\n  return result.join('');\n}","/**\n * @import {\n *   Create,\n *   FullNormalizedExtension,\n *   InitialConstruct,\n *   ParseContext,\n *   ParseOptions\n * } from 'micromark-util-types'\n */\n\nimport { combineExtensions } from 'micromark-util-combine-extensions';\nimport { content } from './initialize/content.js';\nimport { document } from './initialize/document.js';\nimport { flow } from './initialize/flow.js';\nimport { string, text } from './initialize/text.js';\nimport * as defaultConstructs from './constructs.js';\nimport { createTokenizer } from './create-tokenizer.js';\n\n/**\n * @param {ParseOptions | null | undefined} [options]\n *   Configuration (optional).\n * @returns {ParseContext}\n *   Parser.\n */\nexport function parse(options) {\n  const settings = options || {};\n  const constructs = /** @type {FullNormalizedExtension} */\n  combineExtensions([defaultConstructs, ...(settings.extensions || [])]);\n\n  /** @type {ParseContext} */\n  const parser = {\n    constructs,\n    content: create(content),\n    defined: [],\n    document: create(document),\n    flow: create(flow),\n    lazy: {},\n    string: create(string),\n    text: create(text)\n  };\n  return parser;\n\n  /**\n   * @param {InitialConstruct} initial\n   *   Construct to start with.\n   * @returns {Create}\n   *   Create a tokenizer.\n   */\n  function create(initial) {\n    return creator;\n    /** @type {Create} */\n    function creator(from) {\n      return createTokenizer(parser, initial, from);\n    }\n  }\n}","'use strict'\n\nvar regexCheck = require('../util/regex-check.js')\n\nvar asciiDigit = regexCheck(/\\d/)\n\nmodule.exports = asciiDigit\n","'use strict'\n\nvar regexCheck = require('../util/regex-check.js')\n\nvar asciiHexDigit = regexCheck(/[\\dA-Fa-f]/)\n\nmodule.exports = asciiHexDigit\n","'use strict'\n\nfunction miniflat(value) {\n  return value === null || value === undefined\n    ? []\n    : 'length' in value\n    ? value\n    : [value]\n}\n\nmodule.exports = miniflat\n","'use strict'\n\nvar factorySpace = require('./factory-space.js')\n\nvar lineEnding = {\n  name: 'lineEnding',\n  tokenize: tokenizeLineEnding\n}\n\nfunction tokenizeLineEnding(effects, ok) {\n  return start\n\n  function start(code) {\n    effects.enter('lineEnding')\n    effects.consume(code)\n    effects.exit('lineEnding')\n    return factorySpace(effects, ok, 'linePrefix')\n  }\n}\n\nmodule.exports = lineEnding\n","'use strict'\n\nvar markdownLineEnding = require('../character/markdown-line-ending.js')\nvar chunkedSplice = require('../util/chunked-splice.js')\nvar prefixSize = require('../util/prefix-size.js')\nvar factorySpace = require('./factory-space.js')\n\nvar codeIndented = {\n  name: 'codeIndented',\n  tokenize: tokenizeCodeIndented,\n  resolve: resolveCodeIndented\n}\nvar indentedContentConstruct = {\n  tokenize: tokenizeIndentedContent,\n  partial: true\n}\n\nfunction resolveCodeIndented(events, context) {\n  var code = {\n    type: 'codeIndented',\n    start: events[0][1].start,\n    end: events[events.length - 1][1].end\n  }\n  chunkedSplice(events, 0, 0, [['enter', code, context]])\n  chunkedSplice(events, events.length, 0, [['exit', code, context]])\n  return events\n}\n\nfunction tokenizeCodeIndented(effects, ok, nok) {\n  return effects.attempt(indentedContentConstruct, afterPrefix, nok)\n\n  function afterPrefix(code) {\n    if (code === null) {\n      return ok(code)\n    }\n\n    if (markdownLineEnding(code)) {\n      return effects.attempt(indentedContentConstruct, afterPrefix, ok)(code)\n    }\n\n    effects.enter('codeFlowValue')\n    return content(code)\n  }\n\n  function content(code) {\n    if (code === null || markdownLineEnding(code)) {\n      effects.exit('codeFlowValue')\n      return afterPrefix(code)\n    }\n\n    effects.consume(code)\n    return content\n  }\n}\n\nfunction tokenizeIndentedContent(effects, ok, nok) {\n  var self = this\n  return factorySpace(effects, afterPrefix, 'linePrefix', 4 + 1)\n\n  function afterPrefix(code) {\n    if (markdownLineEnding(code)) {\n      effects.enter('lineEnding')\n      effects.consume(code)\n      effects.exit('lineEnding')\n      return factorySpace(effects, afterPrefix, 'linePrefix', 4 + 1)\n    }\n\n    return prefixSize(self.events, 'linePrefix') < 4 ? nok(code) : ok(code)\n  }\n}\n\nmodule.exports = codeIndented\n","'use strict'\n\nvar assign = require('../constant/assign.js')\nvar markdownLineEnding = require('../character/markdown-line-ending.js')\nvar chunkedPush = require('./chunked-push.js')\nvar chunkedSplice = require('./chunked-splice.js')\nvar miniflat = require('./miniflat.js')\nvar resolveAll = require('./resolve-all.js')\nvar serializeChunks = require('./serialize-chunks.js')\nvar shallow = require('./shallow.js')\nvar sliceChunks = require('./slice-chunks.js')\n\n// Create a tokenizer.\n// Tokenizers deal with one type of data (e.g., containers, flow, text).\n// The parser is the object dealing with it all.\n// `initialize` works like other constructs, except that only its `tokenize`\n// function is used, in which case it doesnt receive an `ok` or `nok`.\n// `from` can be given to set the point before the first character, although\n// when further lines are indented, they must be set with `defineSkip`.\nfunction createTokenizer(parser, initialize, from) {\n  var point = from\n    ? shallow(from)\n    : {\n        line: 1,\n        column: 1,\n        offset: 0\n      }\n  var columnStart = {}\n  var resolveAllConstructs = []\n  var chunks = []\n  var stack = []\n\n  var effects = {\n    consume: consume,\n    enter: enter,\n    exit: exit,\n    attempt: constructFactory(onsuccessfulconstruct),\n    check: constructFactory(onsuccessfulcheck),\n    interrupt: constructFactory(onsuccessfulcheck, {\n      interrupt: true\n    }),\n    lazy: constructFactory(onsuccessfulcheck, {\n      lazy: true\n    })\n  } // State and tools for resolving and serializing.\n\n  var context = {\n    previous: null,\n    events: [],\n    parser: parser,\n    sliceStream: sliceStream,\n    sliceSerialize: sliceSerialize,\n    now: now,\n    defineSkip: skip,\n    write: write\n  } // The state function.\n\n  var state = initialize.tokenize.call(context, effects) // Track which character we expect to be consumed, to catch bugs.\n\n  if (initialize.resolveAll) {\n    resolveAllConstructs.push(initialize)\n  } // Store where we are in the input stream.\n\n  point._index = 0\n  point._bufferIndex = -1\n  return context\n\n  function write(slice) {\n    chunks = chunkedPush(chunks, slice)\n    main() // Exit if were not done, resolve might change stuff.\n\n    if (chunks[chunks.length - 1] !== null) {\n      return []\n    }\n\n    addResult(initialize, 0) // Otherwise, resolve, and exit.\n\n    context.events = resolveAll(resolveAllConstructs, context.events, context)\n    return context.events\n  } //\n  // Tools.\n  //\n\n  function sliceSerialize(token) {\n    return serializeChunks(sliceStream(token))\n  }\n\n  function sliceStream(token) {\n    return sliceChunks(chunks, token)\n  }\n\n  function now() {\n    return shallow(point)\n  }\n\n  function skip(value) {\n    columnStart[value.line] = value.column\n    accountForPotentialSkip()\n  } //\n  // State management.\n  //\n  // Main loop (note that `_index` and `_bufferIndex` in `point` are modified by\n  // `consume`).\n  // Here is where we walk through the chunks, which either include strings of\n  // several characters, or numerical character codes.\n  // The reason to do this in a loop instead of a call is so the stack can\n  // drain.\n\n  function main() {\n    var chunkIndex\n    var chunk\n\n    while (point._index < chunks.length) {\n      chunk = chunks[point._index] // If were in a buffer chunk, loop through it.\n\n      if (typeof chunk === 'string') {\n        chunkIndex = point._index\n\n        if (point._bufferIndex < 0) {\n          point._bufferIndex = 0\n        }\n\n        while (\n          point._index === chunkIndex &&\n          point._bufferIndex < chunk.length\n        ) {\n          go(chunk.charCodeAt(point._bufferIndex))\n        }\n      } else {\n        go(chunk)\n      }\n    }\n  } // Deal with one code.\n\n  function go(code) {\n    state = state(code)\n  } // Move a character forward.\n\n  function consume(code) {\n    if (markdownLineEnding(code)) {\n      point.line++\n      point.column = 1\n      point.offset += code === -3 ? 2 : 1\n      accountForPotentialSkip()\n    } else if (code !== -1) {\n      point.column++\n      point.offset++\n    } // Not in a string chunk.\n\n    if (point._bufferIndex < 0) {\n      point._index++\n    } else {\n      point._bufferIndex++ // At end of string chunk.\n\n      if (point._bufferIndex === chunks[point._index].length) {\n        point._bufferIndex = -1\n        point._index++\n      }\n    } // Expose the previous character.\n\n    context.previous = code // Mark as consumed.\n  } // Start a token.\n\n  function enter(type, fields) {\n    var token = fields || {}\n    token.type = type\n    token.start = now()\n    context.events.push(['enter', token, context])\n    stack.push(token)\n    return token\n  } // Stop a token.\n\n  function exit(type) {\n    var token = stack.pop()\n    token.end = now()\n    context.events.push(['exit', token, context])\n    return token\n  } // Use results.\n\n  function onsuccessfulconstruct(construct, info) {\n    addResult(construct, info.from)\n  } // Discard results.\n\n  function onsuccessfulcheck(construct, info) {\n    info.restore()\n  } // Factory to attempt/check/interrupt.\n\n  function constructFactory(onreturn, fields) {\n    return hook // Handle either an object mapping codes to constructs, a list of\n    // constructs, or a single construct.\n\n    function hook(constructs, returnState, bogusState) {\n      var listOfConstructs\n      var constructIndex\n      var currentConstruct\n      var info\n      return constructs.tokenize || 'length' in constructs\n        ? handleListOfConstructs(miniflat(constructs))\n        : handleMapOfConstructs\n\n      function handleMapOfConstructs(code) {\n        if (code in constructs || null in constructs) {\n          return handleListOfConstructs(\n            constructs.null\n              ? /* c8 ignore next */\n                miniflat(constructs[code]).concat(miniflat(constructs.null))\n              : constructs[code]\n          )(code)\n        }\n\n        return bogusState(code)\n      }\n\n      function handleListOfConstructs(list) {\n        listOfConstructs = list\n        constructIndex = 0\n        return handleConstruct(list[constructIndex])\n      }\n\n      function handleConstruct(construct) {\n        return start\n\n        function start(code) {\n          // To do: not nede to store if there is no bogus state, probably?\n          // Currently doesnt work because `inspect` in document does a check\n          // w/o a bogus, which doesnt make sense. But it does seem to help perf\n          // by not storing.\n          info = store()\n          currentConstruct = construct\n\n          if (!construct.partial) {\n            context.currentConstruct = construct\n          }\n\n          if (\n            construct.name &&\n            context.parser.constructs.disable.null.indexOf(construct.name) > -1\n          ) {\n            return nok()\n          }\n\n          return construct.tokenize.call(\n            fields ? assign({}, context, fields) : context,\n            effects,\n            ok,\n            nok\n          )(code)\n        }\n      }\n\n      function ok(code) {\n        onreturn(currentConstruct, info)\n        return returnState\n      }\n\n      function nok(code) {\n        info.restore()\n\n        if (++constructIndex < listOfConstructs.length) {\n          return handleConstruct(listOfConstructs[constructIndex])\n        }\n\n        return bogusState\n      }\n    }\n  }\n\n  function addResult(construct, from) {\n    if (construct.resolveAll && resolveAllConstructs.indexOf(construct) < 0) {\n      resolveAllConstructs.push(construct)\n    }\n\n    if (construct.resolve) {\n      chunkedSplice(\n        context.events,\n        from,\n        context.events.length - from,\n        construct.resolve(context.events.slice(from), context)\n      )\n    }\n\n    if (construct.resolveTo) {\n      context.events = construct.resolveTo(context.events, context)\n    }\n  }\n\n  function store() {\n    var startPoint = now()\n    var startPrevious = context.previous\n    var startCurrentConstruct = context.currentConstruct\n    var startEventsIndex = context.events.length\n    var startStack = Array.from(stack)\n    return {\n      restore: restore,\n      from: startEventsIndex\n    }\n\n    function restore() {\n      point = startPoint\n      context.previous = startPrevious\n      context.currentConstruct = startCurrentConstruct\n      context.events.length = startEventsIndex\n      stack = startStack\n      accountForPotentialSkip()\n    }\n  }\n\n  function accountForPotentialSkip() {\n    if (point.line in columnStart && point.column < 2) {\n      point.column = columnStart[point.line]\n      point.offset += columnStart[point.line] - 1\n    }\n  }\n}\n\nmodule.exports = createTokenizer\n","'use strict'\n\nvar markdownLineEnding = require('../character/markdown-line-ending.js')\nvar factorySpace = require('./factory-space.js')\n\nfunction titleFactory(effects, ok, nok, type, markerType, stringType) {\n  var marker\n  return start\n\n  function start(code) {\n    effects.enter(type)\n    effects.enter(markerType)\n    effects.consume(code)\n    effects.exit(markerType)\n    marker = code === 40 ? 41 : code\n    return atFirstTitleBreak\n  }\n\n  function atFirstTitleBreak(code) {\n    if (code === marker) {\n      effects.enter(markerType)\n      effects.consume(code)\n      effects.exit(markerType)\n      effects.exit(type)\n      return ok\n    }\n\n    effects.enter(stringType)\n    return atTitleBreak(code)\n  }\n\n  function atTitleBreak(code) {\n    if (code === marker) {\n      effects.exit(stringType)\n      return atFirstTitleBreak(marker)\n    }\n\n    if (code === null) {\n      return nok(code)\n    } // Note: blank lines cant exist in content.\n\n    if (markdownLineEnding(code)) {\n      effects.enter('lineEnding')\n      effects.consume(code)\n      effects.exit('lineEnding')\n      return factorySpace(effects, atTitleBreak, 'linePrefix')\n    }\n\n    effects.enter('chunkString', {\n      contentType: 'string'\n    })\n    return title(code)\n  }\n\n  function title(code) {\n    if (code === marker || code === null || markdownLineEnding(code)) {\n      effects.exit('chunkString')\n      return atTitleBreak(code)\n    }\n\n    effects.consume(code)\n    return code === 92 ? titleEscape : title\n  }\n\n  function titleEscape(code) {\n    if (code === marker || code === 92) {\n      effects.consume(code)\n      return title\n    }\n\n    return title(code)\n  }\n}\n\nmodule.exports = titleFactory\n","'use strict'\n\nfunction markdownLineEndingOrSpace(code) {\n  return code < 0 || code === 32\n}\n\nmodule.exports = markdownLineEndingOrSpace\n","'use strict'\n\nfunction normalizeIdentifier(value) {\n  return (\n    value // Collapse Markdown whitespace.\n      .replace(/[\\t\\n\\r ]+/g, ' ') // Trim.\n      .replace(/^ | $/g, '') // Some characters are considered uppercase, but if their lowercase\n      // counterpart is uppercased will result in a different uppercase\n      // character.\n      // Hence, to get that form, we perform both lower- and uppercase.\n      // Upper case makes sure keys will not interact with default prototypal\n      // methods: no object method is uppercase.\n      .toLowerCase()\n      .toUpperCase()\n  )\n}\n\nmodule.exports = normalizeIdentifier\n"],"names":["Object","defineProperty","exports","value","markdownLineEnding","require","factorySpace","partialBlankLine","tokenize","effects","inspectResult","childFlow","childToken","self","this","stack","continued","inspectConstruct","ok","subcontinued","inspectStart","code","length","containerState","attempt","continuation","inspectContinue","inspectLess","currentConstruct","concrete","flowContinue","inspectDone","interrupt","interruptible","containerConstruct","inspectFlowEnd","_closeFlow","lazy","lazyFlowConstruct","check","inspectLazy","flowEnd","undefined","partial","start","documentContinue","documentContinued","flowStart","containerContinue","push","exitContainers","consume","parser","flow","now","enter","contentType","previous","_tokenizer","continueFlow","exit","documentAfterPeek","token","next","defineSkip","write","sliceStream","size","end","index","call","nok","constructs","document","disable","null","indexOf","search","preprocess","atCarriageReturn","column","buffer","encoding","chunks","match","startPosition","endPosition","toString","TextDecoder","decode","charCodeAt","lastIndex","exec","slice","Math","ceil","unicodePunctuationRegex","unicodePunctuation","regexCheck","module","asciiAlpha","asciiAlphanumeric","markdownLineEndingOrSpace","markdownSpace","fromCharCode","htmlBlockNames","htmlRawNames","htmlFlow","name","kind","startTag","marker","open","declarationStart","tagCloseStart","continuationDeclarationInside","tagName","commentOpenInside","cdataOpenInside","toLowerCase","basicSelfClosing","completeAttributeNameBefore","completeClosingTagAfter","completeEnd","completeAttributeName","completeAttributeNameAfter","completeAttributeValueBefore","completeAttributeValueQuoted","completeAttributeValueUnquoted","completeAttributeValueQuotedAfter","completeAfter","continuationCommentInside","continuationRawTagOpen","continuationClose","continuationCharacterDataInside","continuationAtLineEnding","nextBlankConstruct","htmlContinueStart","done","continuationRawEndTag","resolveTo","events","type","splice","asciiAtext","asciiControl","autolink","schemeOrEmailAtext","emailAtext","schemeInsideOrEmailAtext","urlInside","emailAtSignOrDot","emailLabel","emailValue","content","initial","flowInitial","afterConstruct","String","postprocess","subtokenize","thematicBreak","atBreak","sequence","context","resolve","called","resolveAll","assign","htmlText","returnState","declarationOpen","instruction","tagOpen","commentOpen","cdataOpen","declaration","commentStart","commentStartDash","comment","commentClose","atLineEnding","cdata","cdataClose","cdataEnd","instructionClose","tagClose","tagCloseBetween","tagOpenBetween","tagOpenAttributeName","tagOpenAttributeNameAfter","tagOpenAttributeValueBefore","tagOpenAttributeValueQuoted","tagOpenAttributeValueUnquoted","tagOpenAttributeValueQuotedAfter","afterPrefix","unicodeWhitespace","point","offset","_bufferIndex","object","shallow","setextUnderline","paragraph","closingSequence","closingSequenceEnd","text","definition","heading","labelStartLink","after","asciiPunctuation","characterEscape","prefixSize","codeFenced","closingFenceConstruct","closingSequenceStart","sizeOpen","initialPrefix","sequenceOpen","infoOpen","openAfter","info","infoAfter","meta","contentContinue","regex","test","chunkedSplice","list","items","sizeChunks","tail","hardBreakEscape","max","limit","Infinity","prefix","view","startIndex","_index","startBufferIndex","endIndex","endBufferIndex","remove","parameters","chunkStart","Array","from","unshift","apply","decodeEntity","asciiDigit","asciiHexDigit","_interopDefaultLegacy","e","default","decodeEntity__default","characterReference","numeric","sliceSerialize","hasOwnProperty","miniflat","extension","all","hook","left","right","existing","before","add","extensions","data","contentEnd","continuationConstruct","prefixed","own","initialSize","_container","atMarker","inside","onBlank","listItemPrefixWhitespaceConstruct","endOfPrefix","otherPrefix","initialBlankLine","furtherBlankLines","notInCurrentItem","indentConstruct","text$1","attention","blockQuote","codeIndented","codeText","headingAtx","labelEnd","labelStartImage","lineEnding","contentInitial","string","insideSpan","resolver","markerType","stringType","label","labelEscape","normalizeIdentifier","factoryDestination","factoryLabel","factoryWhitespace","factoryTitle","identifier","labelAfter","titleConstruct","defined","chunk","atTab","result","join","openingSequence","gap","tailExitIndex","headEnterIndex","literalType","literalMarkerType","rawType","balance","destinationEnclosedBefore","destinationRaw","destinationEnclosed","destinationEnclosedEscape","destinationRawEscape","initializeFactory","createResolver","field","notText","resolveAllLineSuffixes","extraResolver","bufferIndex","tabs","eventIndex","line","subcontent","stream","entered","adjust","startPositions","tokenizer","childEvents","jumps","gaps","isInFirstContentOfListItem","_gfmTasklistFirstContentOfListItem","pop","event","lineIndex","otherIndex","otherEvent","subevents","more","_movePreviousLineEndings","seen","chunkedPush","classifyCharacter","movePoint","close","_open","_close","group","use","nextEvents","fenceOpenInside","headingBreak","contentStart","labelStart","_balanced","_inactive","balanced","afterLabelEnd","resourceConstruct","fullReferenceConstruct","collapsedReferenceConstruct","media","_used","destinationAfter","between","afterLabel","lineStart","combineExtensions","createTokenizer","options","concat","create","initializer","lineStartOffset","item","checkNewContainers","closeFlow","indexBeforeExits","indexBeforeFlow","Boolean","_gfmTableDynamicInterruptHack","thereIsANewContainer","thereIsNoNewContainer","writeToChild","eof","entry","includes","blankLine","initialize","columnStart","resolveAllConstructs","consumed","accountForPotentialSkip","fields","constructFactory","construct","addResult","onsuccessfulcheck","expandTabs","serializeChunks","main","expectedCode","state","head","shift","sliceChunks","chunkIndex","go","_","restore","onreturn","bogusState","listOfConstructs","constructIndex","isArray","handleListOfConstructs","map","def","handleMapOfConstructs","handleConstruct","startPoint","startPrevious","startCurrentConstruct","startEventsIndex","startStack","store","resolveText","attentionMarkers","parse","settings","defaultConstructs","base","parseInt","_objectSpread","endOfFile","_contentTypeTextTrailing","indentedContentConstruct","atFirstTitleBreak","atTitleBreak","title","titleEscape","replace","toUpperCase"],"sourceRoot":""}